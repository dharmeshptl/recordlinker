{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    " \n",
    "from recordlinker import preprocess \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', 'info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iowa_matches = pd.read_csv('/Users/kailinlu/Desktop/QMSSWork/RecordLinking/recordlinker/recordlinker/data/iowa_matches.csv')\n",
    "iowa_nonmatches = pd.read_csv('/Users/kailinlu/Desktop/QMSSWork/RecordLinking/recordlinker/recordlinker/data/iowa_nonmatches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid1915</th>\n",
       "      <th>fname1915</th>\n",
       "      <th>lname1915</th>\n",
       "      <th>fullname1915</th>\n",
       "      <th>yob1915</th>\n",
       "      <th>hhid</th>\n",
       "      <th>fname1940</th>\n",
       "      <th>lname1940</th>\n",
       "      <th>fullname1940</th>\n",
       "      <th>yob1940</th>\n",
       "      <th>uid-hhid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uid0910071227</td>\n",
       "      <td>donald d</td>\n",
       "      <td>cutler</td>\n",
       "      <td>donald d cutler</td>\n",
       "      <td>1911</td>\n",
       "      <td>19067</td>\n",
       "      <td>donald dean</td>\n",
       "      <td>cutler</td>\n",
       "      <td>donald dean cutler</td>\n",
       "      <td>1911</td>\n",
       "      <td>uid0910071227-19067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uid0063131339</td>\n",
       "      <td>homer</td>\n",
       "      <td>taylor</td>\n",
       "      <td>homer taylor</td>\n",
       "      <td>1912</td>\n",
       "      <td>71505</td>\n",
       "      <td>homer ellis</td>\n",
       "      <td>taylor</td>\n",
       "      <td>homer ellis taylor</td>\n",
       "      <td>1912</td>\n",
       "      <td>uid0063131339-71505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uid0044088276</td>\n",
       "      <td>earl</td>\n",
       "      <td>stearnes</td>\n",
       "      <td>earl stearnes</td>\n",
       "      <td>1899</td>\n",
       "      <td>109708</td>\n",
       "      <td>earl</td>\n",
       "      <td>stearns</td>\n",
       "      <td>earl stearns</td>\n",
       "      <td>1900</td>\n",
       "      <td>uid0044088276-109708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uid0067053130</td>\n",
       "      <td>theodore</td>\n",
       "      <td>hornaday</td>\n",
       "      <td>theodore hornaday</td>\n",
       "      <td>1904</td>\n",
       "      <td>108304</td>\n",
       "      <td>theodore i</td>\n",
       "      <td>harnaday</td>\n",
       "      <td>theodore i harnaday</td>\n",
       "      <td>1904</td>\n",
       "      <td>uid0067053130-108304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uid0066046148</td>\n",
       "      <td>jack r</td>\n",
       "      <td>turner</td>\n",
       "      <td>jack r turner</td>\n",
       "      <td>1907</td>\n",
       "      <td>105092</td>\n",
       "      <td>jack r</td>\n",
       "      <td>turner</td>\n",
       "      <td>jack r turner</td>\n",
       "      <td>1907</td>\n",
       "      <td>uid0066046148-105092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         uid1915 fname1915 lname1915       fullname1915  yob1915    hhid  \\\n",
       "0  uid0910071227  donald d    cutler    donald d cutler     1911   19067   \n",
       "1  uid0063131339     homer    taylor       homer taylor     1912   71505   \n",
       "2  uid0044088276      earl  stearnes      earl stearnes     1899  109708   \n",
       "3  uid0067053130  theodore  hornaday  theodore hornaday     1904  108304   \n",
       "4  uid0066046148    jack r    turner      jack r turner     1907  105092   \n",
       "\n",
       "     fname1940 lname1940         fullname1940  yob1940              uid-hhid  \n",
       "0  donald dean    cutler   donald dean cutler     1911   uid0910071227-19067  \n",
       "1  homer ellis    taylor   homer ellis taylor     1912   uid0063131339-71505  \n",
       "2         earl   stearns         earl stearns     1900  uid0044088276-109708  \n",
       "3   theodore i  harnaday  theodore i harnaday     1904  uid0067053130-108304  \n",
       "4       jack r    turner        jack r turner     1907  uid0066046148-105092  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iowa_matches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "union_matches = pd.read_csv('/Users/kailinlu/Desktop/QMSSWork/RecordLinking/recordlinker/recordlinker/data/unionarmy_matches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recidnum</th>\n",
       "      <th>recname1</th>\n",
       "      <th>recname2</th>\n",
       "      <th>last1</th>\n",
       "      <th>first1</th>\n",
       "      <th>last2</th>\n",
       "      <th>first2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100501001</td>\n",
       "      <td>anson charles h</td>\n",
       "      <td>anson charles h</td>\n",
       "      <td>anson</td>\n",
       "      <td>charles h</td>\n",
       "      <td>anson</td>\n",
       "      <td>charles h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100501002</td>\n",
       "      <td>allsheskey theodore f</td>\n",
       "      <td>allsheskey theodore f</td>\n",
       "      <td>allsheskey</td>\n",
       "      <td>theodore f</td>\n",
       "      <td>allsheskey</td>\n",
       "      <td>theodore f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100501003</td>\n",
       "      <td>bill charles w</td>\n",
       "      <td>bill c w</td>\n",
       "      <td>bill</td>\n",
       "      <td>charles w</td>\n",
       "      <td>bill</td>\n",
       "      <td>c w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100501004</td>\n",
       "      <td>bradley george a</td>\n",
       "      <td>bradley george a</td>\n",
       "      <td>bradley</td>\n",
       "      <td>george a</td>\n",
       "      <td>bradley</td>\n",
       "      <td>george a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100501005</td>\n",
       "      <td>bunitt william n</td>\n",
       "      <td>burritt william n</td>\n",
       "      <td>bunitt</td>\n",
       "      <td>william n</td>\n",
       "      <td>burritt</td>\n",
       "      <td>william n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    recidnum               recname1               recname2       last1  \\\n",
       "0  100501001        anson charles h        anson charles h       anson   \n",
       "1  100501002  allsheskey theodore f  allsheskey theodore f  allsheskey   \n",
       "2  100501003         bill charles w               bill c w        bill   \n",
       "3  100501004       bradley george a       bradley george a     bradley   \n",
       "4  100501005       bunitt william n      burritt william n      bunitt   \n",
       "\n",
       "       first1       last2      first2  \n",
       "0   charles h       anson   charles h  \n",
       "1  theodore f  allsheskey  theodore f  \n",
       "2   charles w        bill         c w  \n",
       "3    george a     bradley    george a  \n",
       "4   william n     burritt   william n  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union_matches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Embedding Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embed Letters: \n",
      " [11  1  9 12  9 14 27 12 21  0  0  0] kailin lu\n",
      "Embed Letters Normalized: \n",
      " [0.40740741 0.03703704 0.33333333 0.44444444 0.33333333 0.51851852\n",
      " 1.         0.44444444 0.77777778 0.         0.         0.        ] kailin lu\n",
      "Embed 2-Shingles: \n",
      " [261   8 219 295 221 364 688 306   0   0   0   0] kailin lu\n",
      "Embed 2-Shingles Normalized: \n",
      " [0.35753425 0.0109589  0.3        0.40410959 0.30273973 0.49863014\n",
      " 0.94246575 0.41917808 0.         0.         0.         0.        ] kailin lu\n"
     ]
    }
   ],
   "source": [
    "from recordlinker.preprocess import embed_letters, embed_shingles, disembed_letters, disembed_shingles\n",
    "\n",
    "name = 'kailin lu'\n",
    "max_length = 12 \n",
    "\n",
    "print('Embed Letters: \\n', \n",
    "      embed_letters(name, max_length), \n",
    "      disembed_letters(embed_letters(name, max_length))) \n",
    "\n",
    "print('Embed Letters Normalized: \\n', \n",
    "      embed_letters(name, max_length, normalize=True), \n",
    "      disembed_letters(embed_letters(name, max_length, normalize=True)))\n",
    "\n",
    "print('Embed 2-Shingles: \\n', \n",
    "      embed_shingles(name, max_length), \n",
    "      disembed_shingles(embed_shingles(name, max_length))) \n",
    "\n",
    "print('Embed 2-Shingles Normalized: \\n', \n",
    "      embed_shingles(name, max_length, normalize=True), \n",
    "      disembed_shingles(embed_shingles(name, max_length, normalize=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and save autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_0 (Dense)                   (None, 256)          3328        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "enc_1 (Dense)                   (None, 128)          32896       enc_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 16)           2064        enc_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "log_sigma (Dense)               (None, 16)           2064        enc_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (32, 16)             0           mu[0][0]                         \n",
      "                                                                 log_sigma[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dec_0 (Dense)                   (32, 128)            2176        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec_1 (Dense)                   (32, 256)            33024       dec_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reconstruction (Dense)          (32, 12)             3084        dec_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 78,636\n",
      "Trainable params: 78,636\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Full Model: None\n",
      "Train on 3456 samples, validate on 864 samples\n",
      "Epoch 1/301\n",
      "3456/3456 [==============================] - 1s 155us/step - loss: 3.6645 - acc: 0.2419 - val_loss: 1.8953 - val_acc: 0.4155\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'landon', 'Pred:': 'jfnkkjfbaa  '}\n",
      "{'Orig': 'frein', 'Pred:': 'lplilecbaa  '}\n",
      "{'Orig': 'evans', 'Pred:': 'kqlilecaaa  '}\n",
      "{'Orig': 'swartzendrub', 'Pred:': 'lmllnnmjhggf'}\n",
      "{'Orig': 'dixon', 'Pred:': 'kiojhdba    '}\n",
      "Epoch 2/301\n",
      "3456/3456 [==============================] - 0s 88us/step - loss: 1.4917 - acc: 0.4601 - val_loss: 1.3131 - val_acc: 0.5012\n",
      "Epoch 3/301\n",
      "3456/3456 [==============================] - 0s 83us/step - loss: 1.1210 - acc: 0.5836 - val_loss: 1.0644 - val_acc: 0.6817\n",
      "Epoch 4/301\n",
      "3456/3456 [==============================] - 0s 85us/step - loss: 0.9571 - acc: 0.6484 - val_loss: 0.9788 - val_acc: 0.6447\n",
      "Epoch 5/301\n",
      "3456/3456 [==============================] - 0s 82us/step - loss: 0.9012 - acc: 0.6398 - val_loss: 0.9339 - val_acc: 0.6377\n",
      "Epoch 6/301\n",
      "3456/3456 [==============================] - 0s 82us/step - loss: 0.8589 - acc: 0.6560 - val_loss: 0.8969 - val_acc: 0.6644\n",
      "Epoch 7/301\n",
      "3456/3456 [==============================] - 0s 83us/step - loss: 0.8314 - acc: 0.6568 - val_loss: 0.8921 - val_acc: 0.6562\n",
      "Epoch 8/301\n",
      "3456/3456 [==============================] - 0s 81us/step - loss: 0.8140 - acc: 0.6557 - val_loss: 0.8906 - val_acc: 0.6424\n",
      "Epoch 9/301\n",
      "3456/3456 [==============================] - 0s 81us/step - loss: 0.8019 - acc: 0.6554 - val_loss: 0.8517 - val_acc: 0.6655\n",
      "Epoch 10/301\n",
      "3456/3456 [==============================] - 0s 81us/step - loss: 0.7900 - acc: 0.6531 - val_loss: 0.8429 - val_acc: 0.6655\n",
      "Epoch 11/301\n",
      "3456/3456 [==============================] - 0s 81us/step - loss: 0.7759 - acc: 0.6661 - val_loss: 0.8273 - val_acc: 0.6609\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'kinser', 'Pred:': 'jhorfpba    '}\n",
      "{'Orig': 'nothdorf', 'Pred:': 'kmqggqmjdba '}\n",
      "{'Orig': 'leary', 'Pred:': 'kgfoucc     '}\n",
      "{'Orig': 'lunde', 'Pred:': 'lumfebaa    '}\n",
      "{'Orig': 'cline', 'Pred:': 'ijineba     '}\n",
      "Epoch 12/301\n",
      "3456/3456 [==============================] - 0s 85us/step - loss: 0.7725 - acc: 0.6484 - val_loss: 0.8494 - val_acc: 0.6343\n",
      "Epoch 13/301\n",
      "3456/3456 [==============================] - 0s 80us/step - loss: 0.7648 - acc: 0.6554 - val_loss: 0.8203 - val_acc: 0.6412\n",
      "Epoch 14/301\n",
      "3456/3456 [==============================] - 0s 82us/step - loss: 0.7514 - acc: 0.6516 - val_loss: 0.8137 - val_acc: 0.6586\n",
      "Epoch 15/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.7439 - acc: 0.6623 - val_loss: 0.8436 - val_acc: 0.5787\n",
      "Epoch 16/301\n",
      "3456/3456 [==============================] - 0s 82us/step - loss: 0.7449 - acc: 0.6600 - val_loss: 0.8114 - val_acc: 0.6782\n",
      "Epoch 17/301\n",
      "3456/3456 [==============================] - 0s 80us/step - loss: 0.7362 - acc: 0.6594 - val_loss: 0.8070 - val_acc: 0.6146\n",
      "Epoch 18/301\n",
      "3456/3456 [==============================] - 0s 80us/step - loss: 0.7284 - acc: 0.6629 - val_loss: 0.7995 - val_acc: 0.6493\n",
      "Epoch 19/301\n",
      "3456/3456 [==============================] - 0s 82us/step - loss: 0.7275 - acc: 0.6539 - val_loss: 0.8261 - val_acc: 0.5787\n",
      "Epoch 20/301\n",
      "3456/3456 [==============================] - 0s 81us/step - loss: 0.7282 - acc: 0.6548 - val_loss: 0.7795 - val_acc: 0.6505\n",
      "Epoch 21/301\n",
      "3456/3456 [==============================] - 0s 100us/step - loss: 0.7262 - acc: 0.6479 - val_loss: 0.7852 - val_acc: 0.6690\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'messerknecht', 'Pred:': 'iirqermohdba'}\n",
      "{'Orig': 'hodges', 'Pred:': 'moefdqca    '}\n",
      "{'Orig': 'cotter', 'Pred:': 'kmsqdpac aa '}\n",
      "{'Orig': 'hutchinson', 'Pred:': 'jtrghgptngba'}\n",
      "{'Orig': 'marlow', 'Pred:': 'mdrjmub     '}\n",
      "Epoch 22/301\n",
      "3456/3456 [==============================] - 0s 85us/step - loss: 0.7093 - acc: 0.6594 - val_loss: 0.7831 - val_acc: 0.6655\n",
      "Epoch 23/301\n",
      "3456/3456 [==============================] - 0s 82us/step - loss: 0.7134 - acc: 0.6528 - val_loss: 0.7718 - val_acc: 0.6748\n",
      "Epoch 24/301\n",
      "3456/3456 [==============================] - 0s 86us/step - loss: 0.7068 - acc: 0.6473 - val_loss: 0.7693 - val_acc: 0.6528\n",
      "Epoch 25/301\n",
      "3456/3456 [==============================] - 0s 91us/step - loss: 0.7019 - acc: 0.6429 - val_loss: 0.7718 - val_acc: 0.6296\n",
      "Epoch 26/301\n",
      "3456/3456 [==============================] - 0s 91us/step - loss: 0.7038 - acc: 0.6519 - val_loss: 0.7749 - val_acc: 0.6262\n",
      "Epoch 27/301\n",
      "3456/3456 [==============================] - 0s 89us/step - loss: 0.6946 - acc: 0.6632 - val_loss: 0.7895 - val_acc: 0.6157\n",
      "Epoch 28/301\n",
      "3456/3456 [==============================] - 0s 89us/step - loss: 0.6944 - acc: 0.6493 - val_loss: 0.7743 - val_acc: 0.6111\n",
      "Epoch 29/301\n",
      "3456/3456 [==============================] - 0s 86us/step - loss: 0.6911 - acc: 0.6577 - val_loss: 0.7514 - val_acc: 0.6412\n",
      "Epoch 30/301\n",
      "3456/3456 [==============================] - 0s 85us/step - loss: 0.6815 - acc: 0.6586 - val_loss: 0.7339 - val_acc: 0.6366\n",
      "Epoch 31/301\n",
      "3456/3456 [==============================] - 0s 82us/step - loss: 0.6815 - acc: 0.6583 - val_loss: 0.7404 - val_acc: 0.6516\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'olsen', 'Pred:': 'lkqfnba     '}\n",
      "{'Orig': 'goodrich', 'Pred:': 'jnqfpfgdaa  '}\n",
      "{'Orig': 'hermann', 'Pred:': 'fcplemida   '}\n",
      "{'Orig': 'thompson', 'Pred:': 'ljokrtogbaa '}\n",
      "{'Orig': 'olson', 'Pred:': 'kkqooba     '}\n",
      "Epoch 32/301\n",
      "3456/3456 [==============================] - 0s 81us/step - loss: 0.6808 - acc: 0.6484 - val_loss: 0.7499 - val_acc: 0.6701\n",
      "Epoch 33/301\n",
      "3456/3456 [==============================] - 0s 80us/step - loss: 0.6694 - acc: 0.6580 - val_loss: 0.7322 - val_acc: 0.6678\n",
      "Epoch 34/301\n",
      "3456/3456 [==============================] - 0s 77us/step - loss: 0.6741 - acc: 0.6461 - val_loss: 0.7339 - val_acc: 0.6088\n",
      "Epoch 35/301\n",
      "3456/3456 [==============================] - 0s 85us/step - loss: 0.6634 - acc: 0.6609 - val_loss: 0.7257 - val_acc: 0.6829\n",
      "Epoch 36/301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3456/3456 [==============================] - 0s 89us/step - loss: 0.6694 - acc: 0.6476 - val_loss: 0.7228 - val_acc: 0.6458\n",
      "Epoch 37/301\n",
      "3456/3456 [==============================] - 0s 80us/step - loss: 0.6625 - acc: 0.6548 - val_loss: 0.7265 - val_acc: 0.6667\n",
      "Epoch 38/301\n",
      "3456/3456 [==============================] - 0s 84us/step - loss: 0.6618 - acc: 0.6513 - val_loss: 0.7169 - val_acc: 0.6458\n",
      "Epoch 39/301\n",
      "3456/3456 [==============================] - 0s 88us/step - loss: 0.6568 - acc: 0.6496 - val_loss: 0.7285 - val_acc: 0.6238\n",
      "Epoch 40/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.6592 - acc: 0.6502 - val_loss: 0.7139 - val_acc: 0.6678\n",
      "Epoch 41/301\n",
      "3456/3456 [==============================] - 0s 80us/step - loss: 0.6494 - acc: 0.6698 - val_loss: 0.7299 - val_acc: 0.6065\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'patrick', 'Pred:': 'hcsnkgb     '}\n",
      "{'Orig': 'larson', 'Pred:': 'kcupmoa     '}\n",
      "{'Orig': 'dolan', 'Pred:': 'hnpciaba    '}\n",
      "{'Orig': 'dannenfeldt', 'Pred:': 'dgrqemkmgcaa'}\n",
      "{'Orig': 'pingree', 'Pred:': 'nioeqec     '}\n",
      "Epoch 42/301\n",
      "3456/3456 [==============================] - 0s 81us/step - loss: 0.6476 - acc: 0.6542 - val_loss: 0.7147 - val_acc: 0.6296\n",
      "Epoch 43/301\n",
      "3456/3456 [==============================] - 0s 81us/step - loss: 0.6463 - acc: 0.6597 - val_loss: 0.7117 - val_acc: 0.6690\n",
      "Epoch 44/301\n",
      "3456/3456 [==============================] - 0s 82us/step - loss: 0.6445 - acc: 0.6568 - val_loss: 0.7204 - val_acc: 0.6470\n",
      "Epoch 45/301\n",
      "3456/3456 [==============================] - 0s 80us/step - loss: 0.6414 - acc: 0.6600 - val_loss: 0.7022 - val_acc: 0.6748\n",
      "Epoch 46/301\n",
      "3456/3456 [==============================] - 0s 80us/step - loss: 0.6397 - acc: 0.6620 - val_loss: 0.6919 - val_acc: 0.6377\n",
      "Epoch 47/301\n",
      "3456/3456 [==============================] - 0s 90us/step - loss: 0.6390 - acc: 0.6571 - val_loss: 0.7171 - val_acc: 0.6262\n",
      "Epoch 48/301\n",
      "3456/3456 [==============================] - 0s 79us/step - loss: 0.6382 - acc: 0.6525 - val_loss: 0.7102 - val_acc: 0.5961\n",
      "Epoch 49/301\n",
      "3456/3456 [==============================] - 0s 80us/step - loss: 0.6339 - acc: 0.6496 - val_loss: 0.7022 - val_acc: 0.6586\n",
      "Epoch 50/301\n",
      "3456/3456 [==============================] - 0s 83us/step - loss: 0.6305 - acc: 0.6432 - val_loss: 0.6863 - val_acc: 0.6667\n",
      "Epoch 51/301\n",
      "3456/3456 [==============================] - 0s 80us/step - loss: 0.6337 - acc: 0.6542 - val_loss: 0.6958 - val_acc: 0.6308\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'swanson', 'Pred:': 'rudmqoncbaa '}\n",
      "{'Orig': 'nelson', 'Pred:': 'mfnrmmb     '}\n",
      "{'Orig': 'coughlin', 'Pred:': 'fluhejflca  '}\n",
      "{'Orig': 'jansen', 'Pred:': 'icprela     '}\n",
      "{'Orig': 'baker', 'Pred:': 'ecpfmad     '}\n",
      "Epoch 52/301\n",
      "3456/3456 [==============================] - 0s 82us/step - loss: 0.6280 - acc: 0.6583 - val_loss: 0.6765 - val_acc: 0.6748\n",
      "Epoch 53/301\n",
      "3456/3456 [==============================] - 0s 81us/step - loss: 0.6247 - acc: 0.6565 - val_loss: 0.6928 - val_acc: 0.6424\n",
      "Epoch 54/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.6304 - acc: 0.6395 - val_loss: 0.6788 - val_acc: 0.6366\n",
      "Epoch 55/301\n",
      "3456/3456 [==============================] - 0s 80us/step - loss: 0.6168 - acc: 0.6652 - val_loss: 0.6746 - val_acc: 0.6806\n",
      "Epoch 56/301\n",
      "3456/3456 [==============================] - 0s 79us/step - loss: 0.6198 - acc: 0.6655 - val_loss: 0.6769 - val_acc: 0.6852\n",
      "Epoch 57/301\n",
      "3456/3456 [==============================] - 0s 81us/step - loss: 0.6201 - acc: 0.6571 - val_loss: 0.6979 - val_acc: 0.6447\n",
      "Epoch 58/301\n",
      "3456/3456 [==============================] - 0s 79us/step - loss: 0.6147 - acc: 0.6603 - val_loss: 0.6696 - val_acc: 0.6655\n",
      "Epoch 59/301\n",
      "3456/3456 [==============================] - 0s 79us/step - loss: 0.6173 - acc: 0.6525 - val_loss: 0.6701 - val_acc: 0.6586\n",
      "Epoch 60/301\n",
      "3456/3456 [==============================] - 0s 81us/step - loss: 0.6112 - acc: 0.6681 - val_loss: 0.6789 - val_acc: 0.6539\n",
      "Epoch 61/301\n",
      "3456/3456 [==============================] - 0s 79us/step - loss: 0.6121 - acc: 0.6661 - val_loss: 0.6977 - val_acc: 0.6076\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'schlueter', 'Pred:': 'lgkjugufgaa '}\n",
      "{'Orig': 'bloodgood', 'Pred:': 'dhonegkiebaa'}\n",
      "{'Orig': 'solnar', 'Pred:': 'snmndn      '}\n",
      "{'Orig': 'dorey', 'Pred:': 'hnthvaa     '}\n",
      "{'Orig': 'dan', 'Pred:': 'gcodca      '}\n",
      "Epoch 62/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.6051 - acc: 0.6748 - val_loss: 0.6722 - val_acc: 0.6505\n",
      "Epoch 63/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.6029 - acc: 0.6661 - val_loss: 0.6625 - val_acc: 0.6748\n",
      "Epoch 64/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.6048 - acc: 0.6591 - val_loss: 0.6669 - val_acc: 0.6655\n",
      "Epoch 65/301\n",
      "3456/3456 [==============================] - 0s 79us/step - loss: 0.6054 - acc: 0.6562 - val_loss: 0.6630 - val_acc: 0.6759\n",
      "Epoch 66/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.6012 - acc: 0.6577 - val_loss: 0.6646 - val_acc: 0.6389\n",
      "Epoch 67/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.6123 - acc: 0.6479 - val_loss: 0.6899 - val_acc: 0.6319\n",
      "Epoch 68/301\n",
      "3456/3456 [==============================] - 0s 75us/step - loss: 0.5999 - acc: 0.6594 - val_loss: 0.6598 - val_acc: 0.6748\n",
      "Epoch 69/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.6080 - acc: 0.6421 - val_loss: 0.6685 - val_acc: 0.6516\n",
      "Epoch 70/301\n",
      "3456/3456 [==============================] - 0s 77us/step - loss: 0.6044 - acc: 0.6510 - val_loss: 0.6581 - val_acc: 0.6562\n",
      "Epoch 71/301\n",
      "3456/3456 [==============================] - 0s 80us/step - loss: 0.5974 - acc: 0.6580 - val_loss: 0.6599 - val_acc: 0.6609\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'mcfee', 'Pred:': 'mdfeea      '}\n",
      "{'Orig': 'stump', 'Pred:': 'rsslpb      '}\n",
      "{'Orig': 'underwood', 'Pred:': 'tqffqsqjeaa '}\n",
      "{'Orig': 'o mara', 'Pred:': 'oxkdpbaa    '}\n",
      "{'Orig': 'flynn', 'Pred:': 'fkwmnb      '}\n",
      "Epoch 72/301\n",
      "3456/3456 [==============================] - 0s 80us/step - loss: 0.5949 - acc: 0.6606 - val_loss: 0.6704 - val_acc: 0.6331\n",
      "Epoch 73/301\n",
      "3456/3456 [==============================] - 0s 83us/step - loss: 0.5988 - acc: 0.6536 - val_loss: 0.6660 - val_acc: 0.6609\n",
      "Epoch 74/301\n",
      "3456/3456 [==============================] - 0s 84us/step - loss: 0.5914 - acc: 0.6612 - val_loss: 0.6890 - val_acc: 0.6377\n",
      "Epoch 75/301\n",
      "3456/3456 [==============================] - 0s 81us/step - loss: 0.5922 - acc: 0.6635 - val_loss: 0.6603 - val_acc: 0.6505\n",
      "Saved model in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/dense_letter_16/model.h5\n",
      "Saved encoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/dense_letter_16/encoder.h5\n",
      "Saved decoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/dense_letter_16/decoder.h5\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_0 (Dense)                   (None, 256)          3328        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "enc_1 (Dense)                   (None, 128)          32896       enc_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 24)           3096        enc_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "log_sigma (Dense)               (None, 24)           3096        enc_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (32, 24)             0           mu[0][0]                         \n",
      "                                                                 log_sigma[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dec_0 (Dense)                   (32, 128)            3200        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec_1 (Dense)                   (32, 256)            33024       dec_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reconstruction (Dense)          (32, 12)             3084        dec_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 81,724\n",
      "Trainable params: 81,724\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Full Model: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3456 samples, validate on 864 samples\n",
      "Epoch 1/301\n",
      "3456/3456 [==============================] - 0s 132us/step - loss: 3.6610 - acc: 0.2729 - val_loss: 1.9442 - val_acc: 0.4294\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'jacobs', 'Pred:': 'ifmmeneba   '}\n",
      "{'Orig': 'casey', 'Pred:': 'jjrgngca    '}\n",
      "{'Orig': 'haben', 'Pred:': 'kmljjfdba   '}\n",
      "{'Orig': 'mehaffey', 'Pred:': 'kkllkkjgeccc'}\n",
      "{'Orig': 'lacy', 'Pred:': 'jiincfca    '}\n",
      "Epoch 2/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 1.4818 - acc: 0.5014 - val_loss: 1.2656 - val_acc: 0.5428\n",
      "Epoch 3/301\n",
      "3456/3456 [==============================] - 0s 87us/step - loss: 1.0978 - acc: 0.5720 - val_loss: 1.0533 - val_acc: 0.6111\n",
      "Epoch 4/301\n",
      "3456/3456 [==============================] - 0s 88us/step - loss: 0.9510 - acc: 0.5952 - val_loss: 0.9633 - val_acc: 0.5914\n",
      "Epoch 5/301\n",
      "3456/3456 [==============================] - 0s 93us/step - loss: 0.8762 - acc: 0.6050 - val_loss: 0.9197 - val_acc: 0.6204\n",
      "Epoch 6/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.8274 - acc: 0.6221 - val_loss: 0.8517 - val_acc: 0.6516\n",
      "Epoch 7/301\n",
      "3456/3456 [==============================] - 0s 80us/step - loss: 0.7760 - acc: 0.6832 - val_loss: 0.8136 - val_acc: 0.6725\n",
      "Epoch 8/301\n",
      "3456/3456 [==============================] - 0s 81us/step - loss: 0.7425 - acc: 0.7060 - val_loss: 0.8190 - val_acc: 0.6597\n",
      "Epoch 9/301\n",
      "3456/3456 [==============================] - 0s 81us/step - loss: 0.7263 - acc: 0.7138 - val_loss: 0.7851 - val_acc: 0.6713\n",
      "Epoch 10/301\n",
      "3456/3456 [==============================] - 0s 80us/step - loss: 0.7113 - acc: 0.7031 - val_loss: 0.7683 - val_acc: 0.6759\n",
      "Epoch 11/301\n",
      "3456/3456 [==============================] - 0s 87us/step - loss: 0.6979 - acc: 0.7031 - val_loss: 0.7535 - val_acc: 0.6887\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'mueller', 'Pred:': 'jtellekbba  '}\n",
      "{'Orig': 'kopel', 'Pred:': 'koqejbaa    '}\n",
      "{'Orig': 'eisland', 'Pred:': 'ejsldkba    '}\n",
      "{'Orig': 'turner', 'Pred:': 'suqngoabaa  '}\n",
      "{'Orig': 'riesberg', 'Pred:': 'oifqeekfeca '}\n",
      "Epoch 12/301\n",
      "3456/3456 [==============================] - 0s 89us/step - loss: 0.6927 - acc: 0.6991 - val_loss: 0.7412 - val_acc: 0.7083\n",
      "Epoch 13/301\n",
      "3456/3456 [==============================] - 0s 87us/step - loss: 0.6784 - acc: 0.6985 - val_loss: 0.7493 - val_acc: 0.6852\n",
      "Epoch 14/301\n",
      "3456/3456 [==============================] - 0s 85us/step - loss: 0.6781 - acc: 0.6973 - val_loss: 0.7352 - val_acc: 0.7025\n",
      "Epoch 15/301\n",
      "3456/3456 [==============================] - 0s 84us/step - loss: 0.6616 - acc: 0.7023 - val_loss: 0.7207 - val_acc: 0.7141\n",
      "Epoch 16/301\n",
      "3456/3456 [==============================] - 0s 85us/step - loss: 0.6565 - acc: 0.7002 - val_loss: 0.7306 - val_acc: 0.6968\n",
      "Epoch 17/301\n",
      "3456/3456 [==============================] - 0s 87us/step - loss: 0.6523 - acc: 0.7109 - val_loss: 0.7178 - val_acc: 0.6875\n",
      "Epoch 18/301\n",
      "3456/3456 [==============================] - 0s 83us/step - loss: 0.6517 - acc: 0.7028 - val_loss: 0.7225 - val_acc: 0.6551\n",
      "Epoch 19/301\n",
      "3456/3456 [==============================] - 0s 79us/step - loss: 0.6423 - acc: 0.7020 - val_loss: 0.7119 - val_acc: 0.6539\n",
      "Epoch 20/301\n",
      "3456/3456 [==============================] - 0s 79us/step - loss: 0.6405 - acc: 0.7005 - val_loss: 0.7131 - val_acc: 0.6366\n",
      "Epoch 21/301\n",
      "3456/3456 [==============================] - 0s 80us/step - loss: 0.6357 - acc: 0.6878 - val_loss: 0.7128 - val_acc: 0.6481\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'luce', 'Pred:': 'ltgecba     '}\n",
      "{'Orig': 'cooper', 'Pred:': 'dppmgqb     '}\n",
      "{'Orig': 'fitzgerald', 'Pred:': 'fjrvjgoedca '}\n",
      "{'Orig': 'tenny', 'Pred:': 'sgomxba     '}\n",
      "{'Orig': 'johannes', 'Pred:': 'nqlclpjiba  '}\n",
      "Epoch 22/301\n",
      "3456/3456 [==============================] - 0s 79us/step - loss: 0.6387 - acc: 0.6875 - val_loss: 0.6967 - val_acc: 0.6458\n",
      "Epoch 23/301\n",
      "3456/3456 [==============================] - 0s 81us/step - loss: 0.6262 - acc: 0.6979 - val_loss: 0.6925 - val_acc: 0.6863\n",
      "Epoch 24/301\n",
      "3456/3456 [==============================] - 0s 80us/step - loss: 0.6218 - acc: 0.7028 - val_loss: 0.6980 - val_acc: 0.7280\n",
      "Epoch 25/301\n",
      "3456/3456 [==============================] - 0s 82us/step - loss: 0.6225 - acc: 0.7060 - val_loss: 0.6862 - val_acc: 0.6979\n",
      "Epoch 26/301\n",
      "3456/3456 [==============================] - 0s 79us/step - loss: 0.6143 - acc: 0.7086 - val_loss: 0.6710 - val_acc: 0.6910\n",
      "Epoch 27/301\n",
      "3456/3456 [==============================] - 0s 81us/step - loss: 0.6136 - acc: 0.7054 - val_loss: 0.6798 - val_acc: 0.6898\n",
      "Epoch 28/301\n",
      "3456/3456 [==============================] - 0s 83us/step - loss: 0.6119 - acc: 0.7080 - val_loss: 0.6850 - val_acc: 0.6806\n",
      "Epoch 29/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.6082 - acc: 0.7095 - val_loss: 0.6685 - val_acc: 0.6921\n",
      "Epoch 30/301\n",
      "3456/3456 [==============================] - 0s 79us/step - loss: 0.6065 - acc: 0.7002 - val_loss: 0.6670 - val_acc: 0.6887\n",
      "Epoch 31/301\n",
      "3456/3456 [==============================] - 0s 81us/step - loss: 0.6005 - acc: 0.7130 - val_loss: 0.6567 - val_acc: 0.7222\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'norton', 'Pred:': 'norsooba    '}\n",
      "{'Orig': 'henkels', 'Pred:': 'edlkhlqeb   '}\n",
      "{'Orig': 'buus', 'Pred:': 'dtssbcaa    '}\n",
      "{'Orig': 'mchugh', 'Pred:': 'mdjsgfb     '}\n",
      "{'Orig': 'curran', 'Pred:': 'dtrscoaa    '}\n",
      "Epoch 32/301\n",
      "3456/3456 [==============================] - 0s 79us/step - loss: 0.5921 - acc: 0.7196 - val_loss: 0.6541 - val_acc: 0.7002\n",
      "Epoch 33/301\n",
      "3456/3456 [==============================] - 0s 81us/step - loss: 0.5937 - acc: 0.7095 - val_loss: 0.6574 - val_acc: 0.7002\n",
      "Epoch 34/301\n",
      "3456/3456 [==============================] - 0s 80us/step - loss: 0.5905 - acc: 0.7115 - val_loss: 0.6600 - val_acc: 0.6725\n",
      "Epoch 35/301\n",
      "3456/3456 [==============================] - 0s 81us/step - loss: 0.5903 - acc: 0.7104 - val_loss: 0.6581 - val_acc: 0.6968\n",
      "Epoch 36/301\n",
      "3456/3456 [==============================] - 0s 81us/step - loss: 0.5903 - acc: 0.7095 - val_loss: 0.6676 - val_acc: 0.7060\n",
      "Epoch 37/301\n",
      "3456/3456 [==============================] - 0s 82us/step - loss: 0.5817 - acc: 0.7179 - val_loss: 0.6662 - val_acc: 0.5856\n",
      "Saved model in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/dense_letter_24/model.h5\n",
      "Saved encoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/dense_letter_24/encoder.h5\n",
      "Saved decoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/dense_letter_24/decoder.h5\n"
     ]
    }
   ],
   "source": [
    "ORIG_LENGTH = 12\n",
    "BATCH_SIZE = 32\n",
    "ENCODE_DIM = [256, 128] \n",
    "DECODE_DIM = [128, 256]\n",
    "LR = 1e-4\n",
    "EPOCHS=301\n",
    "LATENT_DIM = [16,24]\n",
    "\n",
    "# Embed letters \n",
    "namesA = preprocess.embed(iowa_matches['lname1915'],\n",
    "                         max_length=ORIG_LENGTH, \n",
    "                         embed_type='letters', \n",
    "                         normalize=True)\n",
    "namesB = preprocess.embed(iowa_matches['lname1940'],\n",
    "                         max_length=ORIG_LENGTH, \n",
    "                         embed_type='letters', \n",
    "                         normalize=True)\n",
    "\n",
    "for latent_dim in LATENT_DIM: \n",
    "    save_path = '/Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/dense_letter_{}/'.format(latent_dim)\n",
    "    run_id = 'dense_{}'.format(latent_dim)\n",
    "    vae = recordlinker.model.VAE(batch_size=BATCH_SIZE,\n",
    "                                 orig_dim=ORIG_LENGTH, \n",
    "                                 latent_dim=latent_dim,\n",
    "                                 encode_dim=ENCODE_DIM,\n",
    "                                 decode_dim=DECODE_DIM,\n",
    "                                 lr=LR)\n",
    "\n",
    "    model, encoder, decoder = vae.train(namesA, namesB, \n",
    "                                        epochs=EPOCHS, \n",
    "                                        run_id=run_id,\n",
    "                                        save_path=save_path,\n",
    "                                        optimizer='adam', \n",
    "                                        tensorboard=True, \n",
    "                                        earlystop=True,\n",
    "                                        earlystop_patience=10,\n",
    "                                        reconstruct=True, \n",
    "                                        reconstruct_display=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_0 (Dense)                   (None, 128)          1664        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "enc_1 (Dense)                   (None, 128)          16512       enc_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 2)            258         enc_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "log_sigma (Dense)               (None, 2)            258         enc_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (32, 2)              0           mu[0][0]                         \n",
      "                                                                 log_sigma[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dec_0 (Dense)                   (32, 128)            384         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec_1 (Dense)                   (32, 128)            16512       dec_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reconstruction (Dense)          (32, 12)             1548        dec_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 37,136\n",
      "Trainable params: 37,136\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Full Model: None\n",
      "Train on 3456 samples, validate on 864 samples\n",
      "Epoch 1/301\n",
      "3456/3456 [==============================] - 0s 130us/step - loss: 3.7287 - acc: 0.3374 - val_loss: 1.9400 - val_acc: 0.3727\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'cunningham', 'Pred:': 'llolhgeddcdcu'}\n",
      "{'Orig': 'cassidy', 'Pred:': 'kkokfdbbbabax'}\n",
      "{'Orig': 'rose', 'Pred:': 'kjojedbaaaaap'}\n",
      "{'Orig': 'haas', 'Pred:': 'kkokfdbabaaau'}\n",
      "{'Orig': 'nissen', 'Pred:': 'kkokfebbbabay'}\n",
      "Epoch 2/301\n",
      "3456/3456 [==============================] - 0s 68us/step - loss: 1.6174 - acc: 0.3565 - val_loss: 1.4499 - val_acc: 0.3542\n",
      "Epoch 3/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 1.2844 - acc: 0.4517 - val_loss: 1.2147 - val_acc: 0.4919\n",
      "Epoch 4/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 1.1244 - acc: 0.5098 - val_loss: 1.1329 - val_acc: 0.5116\n",
      "Epoch 5/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 1.0698 - acc: 0.5231 - val_loss: 1.0891 - val_acc: 0.5231\n",
      "Epoch 6/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 1.0349 - acc: 0.5284 - val_loss: 1.0659 - val_acc: 0.5046\n",
      "Epoch 7/301\n",
      "3456/3456 [==============================] - 0s 76us/step - loss: 1.0180 - acc: 0.5269 - val_loss: 1.0541 - val_acc: 0.5174\n",
      "Epoch 8/301\n",
      "3456/3456 [==============================] - 0s 94us/step - loss: 1.0005 - acc: 0.5278 - val_loss: 1.0368 - val_acc: 0.5127\n",
      "Epoch 9/301\n",
      "3456/3456 [==============================] - 0s 98us/step - loss: 0.9934 - acc: 0.5301 - val_loss: 1.0318 - val_acc: 0.5069\n",
      "Epoch 10/301\n",
      "3456/3456 [==============================] - 0s 91us/step - loss: 0.9848 - acc: 0.5327 - val_loss: 1.0130 - val_acc: 0.5174\n",
      "Epoch 11/301\n",
      "3456/3456 [==============================] - 0s 96us/step - loss: 0.9793 - acc: 0.5278 - val_loss: 1.0234 - val_acc: 0.5185\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'isaacson', 'Pred:': 'jhtnkjfbbaaah'}\n",
      "{'Orig': 'longenecker', 'Pred:': 'kmmokgdbaaaag'}\n",
      "{'Orig': 'delong', 'Pred:': 'jjqlhdbaaaaad'}\n",
      "{'Orig': 'pray', 'Pred:': 'krefbaaaaaaab'}\n",
      "{'Orig': 'rath', 'Pred:': 'hftfbaaaaaaab'}\n",
      "Epoch 12/301\n",
      "3456/3456 [==============================] - 0s 82us/step - loss: 0.9731 - acc: 0.5301 - val_loss: 1.0224 - val_acc: 0.4988\n",
      "Epoch 13/301\n",
      "3456/3456 [==============================] - 0s 79us/step - loss: 0.9729 - acc: 0.5275 - val_loss: 1.0029 - val_acc: 0.5289\n",
      "Epoch 14/301\n",
      "3456/3456 [==============================] - 0s 95us/step - loss: 0.9635 - acc: 0.5373 - val_loss: 0.9958 - val_acc: 0.5266\n",
      "Epoch 15/301\n",
      "3456/3456 [==============================] - 0s 89us/step - loss: 0.9611 - acc: 0.5307 - val_loss: 0.9920 - val_acc: 0.5243\n",
      "Epoch 16/301\n",
      "3456/3456 [==============================] - 0s 79us/step - loss: 0.9543 - acc: 0.5341 - val_loss: 0.9955 - val_acc: 0.5000\n",
      "Epoch 17/301\n",
      "3456/3456 [==============================] - 0s 76us/step - loss: 0.9514 - acc: 0.5365 - val_loss: 0.9860 - val_acc: 0.5220\n",
      "Epoch 18/301\n",
      "3456/3456 [==============================] - 0s 81us/step - loss: 0.9482 - acc: 0.5344 - val_loss: 0.9939 - val_acc: 0.5023\n",
      "Epoch 19/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.9430 - acc: 0.5312 - val_loss: 0.9759 - val_acc: 0.5243\n",
      "Epoch 20/301\n",
      "3456/3456 [==============================] - 0s 82us/step - loss: 0.9398 - acc: 0.5347 - val_loss: 0.9740 - val_acc: 0.5278\n",
      "Epoch 21/301\n",
      "3456/3456 [==============================] - 0s 80us/step - loss: 0.9394 - acc: 0.5330 - val_loss: 0.9797 - val_acc: 0.5370\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'thompson', 'Pred:': 'klmomnjecaaai'}\n",
      "{'Orig': 'moore', 'Pred:': 'mrfkfbaaaaaac'}\n",
      "{'Orig': 'knoll', 'Pred:': 'lmkmhdbaaaaad'}\n",
      "{'Orig': 'hiher', 'Pred:': 'jmjebaaaaaaab'}\n",
      "{'Orig': 'decker', 'Pred:': 'knjhcaaaaaaab'}\n",
      "Epoch 22/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.9371 - acc: 0.5307 - val_loss: 0.9760 - val_acc: 0.5255\n",
      "Epoch 23/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.9323 - acc: 0.5353 - val_loss: 0.9665 - val_acc: 0.5324\n",
      "Epoch 24/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.9306 - acc: 0.5396 - val_loss: 0.9612 - val_acc: 0.5231\n",
      "Epoch 25/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.9260 - acc: 0.5373 - val_loss: 0.9563 - val_acc: 0.5347\n",
      "Epoch 26/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.9287 - acc: 0.5344 - val_loss: 0.9562 - val_acc: 0.5278\n",
      "Epoch 27/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.9217 - acc: 0.5341 - val_loss: 0.9565 - val_acc: 0.5312\n",
      "Epoch 28/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.9233 - acc: 0.5379 - val_loss: 0.9589 - val_acc: 0.5289\n",
      "Epoch 29/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.9198 - acc: 0.5359 - val_loss: 0.9545 - val_acc: 0.5301\n",
      "Epoch 30/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.9181 - acc: 0.5341 - val_loss: 0.9529 - val_acc: 0.5336\n",
      "Epoch 31/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.9148 - acc: 0.5344 - val_loss: 0.9474 - val_acc: 0.5174\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'sutton', 'Pred:': 'kjqnjebaaaaac'}\n",
      "{'Orig': 'turbett', 'Pred:': 'klnnmlgdbaaag'}\n",
      "{'Orig': 'neil', 'Pred:': 'iknebaaab'}\n",
      "{'Orig': 'jacobson', 'Pred:': 'kkonmnjecaaah'}\n",
      "{'Orig': 'mahony', 'Pred:': 'kjqnjebaaaaac'}\n",
      "Epoch 32/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.9147 - acc: 0.5356 - val_loss: 0.9446 - val_acc: 0.5289\n",
      "Epoch 33/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.9130 - acc: 0.5376 - val_loss: 0.9508 - val_acc: 0.5359\n",
      "Epoch 34/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.9125 - acc: 0.5310 - val_loss: 0.9447 - val_acc: 0.5370\n",
      "Epoch 35/301\n",
      "3456/3456 [==============================] - 0s 76us/step - loss: 0.9070 - acc: 0.5434 - val_loss: 0.9385 - val_acc: 0.5347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/301\n",
      "3456/3456 [==============================] - 0s 77us/step - loss: 0.9072 - acc: 0.5350 - val_loss: 0.9520 - val_acc: 0.5104\n",
      "Epoch 37/301\n",
      "3456/3456 [==============================] - 0s 79us/step - loss: 0.9046 - acc: 0.5370 - val_loss: 0.9483 - val_acc: 0.5324\n",
      "Epoch 38/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.9030 - acc: 0.5391 - val_loss: 0.9372 - val_acc: 0.5301\n",
      "Epoch 39/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.9029 - acc: 0.5321 - val_loss: 0.9335 - val_acc: 0.5266\n",
      "Epoch 40/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.8996 - acc: 0.5420 - val_loss: 0.9293 - val_acc: 0.5312\n",
      "Epoch 41/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.8962 - acc: 0.5417 - val_loss: 0.9304 - val_acc: 0.5324\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'ingebritson', 'Pred:': 'lqgmnsqnfcbaj'}\n",
      "{'Orig': 'platt', 'Pred:': 'nrgoicaaaaaab'}\n",
      "{'Orig': 'sproston', 'Pred:': 'kmkmmplgdbaag'}\n",
      "{'Orig': 'platt', 'Pred:': 'nrgoicaaaaaab'}\n",
      "{'Orig': 'hopkins', 'Pred:': 'kknmkidbaaaad'}\n",
      "Epoch 42/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.8949 - acc: 0.5367 - val_loss: 0.9465 - val_acc: 0.5382\n",
      "Epoch 43/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.8962 - acc: 0.5330 - val_loss: 0.9318 - val_acc: 0.5139\n",
      "Epoch 44/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.8990 - acc: 0.5365 - val_loss: 0.9362 - val_acc: 0.5255\n",
      "Epoch 45/301\n",
      "3456/3456 [==============================] - 0s 66us/step - loss: 0.8931 - acc: 0.5327 - val_loss: 0.9421 - val_acc: 0.5220\n",
      "Saved encoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/dense_shingle_2_union_first/encoder.h5\n",
      "Saved decoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/dense_shingle_2_union_first/decoder.h5\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_0 (Dense)                   (None, 128)          1664        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "enc_1 (Dense)                   (None, 128)          16512       enc_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 4)            516         enc_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "log_sigma (Dense)               (None, 4)            516         enc_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (32, 4)              0           mu[0][0]                         \n",
      "                                                                 log_sigma[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dec_0 (Dense)                   (32, 128)            640         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec_1 (Dense)                   (32, 128)            16512       dec_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reconstruction (Dense)          (32, 12)             1548        dec_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 37,908\n",
      "Trainable params: 37,908\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Full Model: None\n",
      "Train on 3456 samples, validate on 864 samples\n",
      "Epoch 1/301\n",
      "3456/3456 [==============================] - 0s 133us/step - loss: 3.6098 - acc: 0.3487 - val_loss: 1.9747 - val_acc: 0.3727\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'kothenbentel', 'Pred:': 'lmomkifeddddx'}\n",
      "{'Orig': 'jensen', 'Pred:': 'kkpkgebaaaaat'}\n",
      "{'Orig': 'newgard', 'Pred:': 'kkpkgebaaaaau'}\n",
      "{'Orig': 'reinilze', 'Pred:': 'lmomjifdddddq'}\n",
      "{'Orig': 'morris', 'Pred:': 'kkpjfdbaaaaam'}\n",
      "Epoch 2/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 1.5572 - acc: 0.4667 - val_loss: 1.3556 - val_acc: 0.4838\n",
      "Epoch 3/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 1.1964 - acc: 0.5605 - val_loss: 1.1437 - val_acc: 0.5590\n",
      "Epoch 4/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 1.0056 - acc: 0.6557 - val_loss: 1.0020 - val_acc: 0.6979\n",
      "Epoch 5/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.9014 - acc: 0.6837 - val_loss: 0.9437 - val_acc: 0.6829\n",
      "Epoch 6/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.8553 - acc: 0.6780 - val_loss: 0.9038 - val_acc: 0.6933\n",
      "Epoch 7/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.8261 - acc: 0.6811 - val_loss: 0.8776 - val_acc: 0.6609\n",
      "Epoch 8/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.8118 - acc: 0.6739 - val_loss: 0.8814 - val_acc: 0.6528\n",
      "Epoch 9/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.8004 - acc: 0.6832 - val_loss: 0.8548 - val_acc: 0.6898\n",
      "Epoch 10/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.7848 - acc: 0.6820 - val_loss: 0.8474 - val_acc: 0.6840\n",
      "Epoch 11/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.7754 - acc: 0.6820 - val_loss: 0.8396 - val_acc: 0.6678\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'jones', 'Pred:': 'jmoecbaaaaaac'}\n",
      "{'Orig': 'harnseth', 'Pred:': 'icrnlnicbaaai'}\n",
      "{'Orig': 'turner', 'Pred:': 'ltqmfbaaaaaad'}\n",
      "{'Orig': 'diedrich', 'Pred:': 'khhfijfcbaaag'}\n",
      "{'Orig': 'estess', 'Pred:': 'jrvhkjdbaaaai'}\n",
      "Epoch 12/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.7707 - acc: 0.6797 - val_loss: 0.8274 - val_acc: 0.6632\n",
      "Epoch 13/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.7629 - acc: 0.6808 - val_loss: 0.8257 - val_acc: 0.6910\n",
      "Epoch 14/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.7576 - acc: 0.6791 - val_loss: 0.8255 - val_acc: 0.6667\n",
      "Epoch 15/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.7522 - acc: 0.6753 - val_loss: 0.8216 - val_acc: 0.6088\n",
      "Epoch 16/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.7451 - acc: 0.6797 - val_loss: 0.8145 - val_acc: 0.6667\n",
      "Epoch 17/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.7425 - acc: 0.6675 - val_loss: 0.8066 - val_acc: 0.6667\n",
      "Epoch 18/301\n",
      "3456/3456 [==============================] - 0s 69us/step - loss: 0.7390 - acc: 0.6733 - val_loss: 0.8125 - val_acc: 0.6632\n",
      "Epoch 19/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.7344 - acc: 0.6846 - val_loss: 0.8022 - val_acc: 0.6528\n",
      "Epoch 20/301\n",
      "3456/3456 [==============================] - 0s 77us/step - loss: 0.7296 - acc: 0.6681 - val_loss: 0.8013 - val_acc: 0.6701\n",
      "Epoch 21/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.7249 - acc: 0.6756 - val_loss: 0.8000 - val_acc: 0.6505\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'cogan', 'Pred:': 'jniccbaaaaaac'}\n",
      "{'Orig': 'powers', 'Pred:': 'ksuihebaaaaae'}\n",
      "{'Orig': 'james', 'Pred:': 'idnecbaaaaaac'}\n",
      "{'Orig': 'danielsen', 'Pred:': 'hcogjmidbaaag'}\n",
      "{'Orig': 'lynn', 'Pred:': 'kxxdcaaaaaaac'}\n",
      "Epoch 22/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.7284 - acc: 0.6678 - val_loss: 0.7917 - val_acc: 0.6748\n",
      "Epoch 23/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.7220 - acc: 0.6762 - val_loss: 0.7843 - val_acc: 0.6736\n",
      "Epoch 24/301\n",
      "3456/3456 [==============================] - 0s 86us/step - loss: 0.7245 - acc: 0.6638 - val_loss: 0.7823 - val_acc: 0.6609\n",
      "Epoch 25/301\n",
      "3456/3456 [==============================] - 0s 83us/step - loss: 0.7173 - acc: 0.6701 - val_loss: 0.7877 - val_acc: 0.6852\n",
      "Epoch 26/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.7143 - acc: 0.6681 - val_loss: 0.8033 - val_acc: 0.6354\n",
      "Epoch 27/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.7111 - acc: 0.6713 - val_loss: 0.7903 - val_acc: 0.6829\n",
      "Epoch 28/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.7097 - acc: 0.6797 - val_loss: 0.7769 - val_acc: 0.6632\n",
      "Epoch 29/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.7093 - acc: 0.6719 - val_loss: 0.7778 - val_acc: 0.6678\n",
      "Epoch 30/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.7057 - acc: 0.6748 - val_loss: 0.7741 - val_acc: 0.6667\n",
      "Epoch 31/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.7035 - acc: 0.6722 - val_loss: 0.7854 - val_acc: 0.6620\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'sass', 'Pred:': 'gexdbaaaaaab'}\n",
      "{'Orig': 'goodrich', 'Pred:': 'lyneljbbaaaad'}\n",
      "{'Orig': 'dailey', 'Pred:': 'icjidbaaaaaab'}\n",
      "{'Orig': 'myers', 'Pred:': 'owfodaaaaaaab'}\n",
      "{'Orig': 'nicholas', 'Pred:': 'kleijhdbbaaad'}\n",
      "Epoch 32/301\n",
      "3456/3456 [==============================] - 0s 76us/step - loss: 0.7004 - acc: 0.6759 - val_loss: 0.7672 - val_acc: 0.6794\n",
      "Epoch 33/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.7024 - acc: 0.6615 - val_loss: 0.7698 - val_acc: 0.6400\n",
      "Epoch 34/301\n",
      "3456/3456 [==============================] - ETA: 0s - loss: 0.6988 - acc: 0.673 - 0s 73us/step - loss: 0.6985 - acc: 0.6739 - val_loss: 0.7589 - val_acc: 0.6586\n",
      "Epoch 35/301\n",
      "3456/3456 [==============================] - 0s 75us/step - loss: 0.6962 - acc: 0.6693 - val_loss: 0.7543 - val_acc: 0.6782\n",
      "Epoch 36/301\n",
      "3456/3456 [==============================] - 0s 80us/step - loss: 0.6908 - acc: 0.6797 - val_loss: 0.7642 - val_acc: 0.6481\n",
      "Epoch 37/301\n",
      "3456/3456 [==============================] - 0s 75us/step - loss: 0.6930 - acc: 0.6678 - val_loss: 0.7686 - val_acc: 0.6713\n",
      "Epoch 38/301\n",
      "3456/3456 [==============================] - 0s 82us/step - loss: 0.6918 - acc: 0.6664 - val_loss: 0.7629 - val_acc: 0.6470\n",
      "Epoch 39/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.6898 - acc: 0.6736 - val_loss: 0.7715 - val_acc: 0.6748\n",
      "Epoch 40/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.6889 - acc: 0.6730 - val_loss: 0.7474 - val_acc: 0.6713\n",
      "Epoch 41/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.6840 - acc: 0.6742 - val_loss: 0.7495 - val_acc: 0.6701\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'pomroy', 'Pred:': 'nqmtkdbaaaaac'}\n",
      "{'Orig': 'noelch', 'Pred:': 'mofkdaaaaaaab'}\n",
      "{'Orig': 'mayer', 'Pred:': 'hdxgcaaaaaaab'}\n",
      "{'Orig': 'lelonek', 'Pred:': 'kgmpifcaaaaac'}\n",
      "{'Orig': 'falk', 'Pred:': 'hdlcbbaaaaaab'}\n",
      "Epoch 42/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.6812 - acc: 0.6748 - val_loss: 0.7486 - val_acc: 0.6644\n",
      "Epoch 43/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.6824 - acc: 0.6719 - val_loss: 0.7418 - val_acc: 0.6725\n",
      "Epoch 44/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.6801 - acc: 0.6745 - val_loss: 0.7439 - val_acc: 0.6562\n",
      "Epoch 45/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.6779 - acc: 0.6765 - val_loss: 0.7429 - val_acc: 0.6782\n",
      "Epoch 46/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.6800 - acc: 0.6704 - val_loss: 0.7386 - val_acc: 0.6678\n",
      "Epoch 47/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.6762 - acc: 0.6710 - val_loss: 0.7433 - val_acc: 0.6562\n",
      "Epoch 48/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.6803 - acc: 0.6733 - val_loss: 0.7479 - val_acc: 0.6713\n",
      "Epoch 49/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.6728 - acc: 0.6832 - val_loss: 0.7431 - val_acc: 0.6655\n",
      "Epoch 50/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.6729 - acc: 0.6693 - val_loss: 0.7278 - val_acc: 0.6748\n",
      "Epoch 51/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.6724 - acc: 0.6722 - val_loss: 0.7313 - val_acc: 0.6759\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'speth', 'Pred:': 'opesdaaaaaaab'}\n",
      "{'Orig': 'taylor', 'Pred:': 'jfwpgdbaaaaac'}\n",
      "{'Orig': 'beattie', 'Pred:': 'mghukffbaaaad'}\n",
      "{'Orig': 'clayton', 'Pred:': 'mmgrnigcbaaad'}\n",
      "{'Orig': 'ploman', 'Pred:': 'lmnmcaaaaaab'}\n",
      "Epoch 52/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.6683 - acc: 0.6701 - val_loss: 0.7415 - val_acc: 0.6539\n",
      "Epoch 53/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.6662 - acc: 0.6756 - val_loss: 0.7326 - val_acc: 0.6748\n",
      "Epoch 54/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.6634 - acc: 0.6736 - val_loss: 0.7345 - val_acc: 0.6308\n",
      "Epoch 55/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.6628 - acc: 0.6756 - val_loss: 0.7379 - val_acc: 0.6562\n",
      "Saved encoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/dense_shingle_4_union_first/encoder.h5\n",
      "Saved decoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/dense_shingle_4_union_first/decoder.h5\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_0 (Dense)                   (None, 128)          1664        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "enc_1 (Dense)                   (None, 128)          16512       enc_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 8)            1032        enc_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "log_sigma (Dense)               (None, 8)            1032        enc_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (32, 8)              0           mu[0][0]                         \n",
      "                                                                 log_sigma[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dec_0 (Dense)                   (32, 128)            1152        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec_1 (Dense)                   (32, 128)            16512       dec_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reconstruction (Dense)          (32, 12)             1548        dec_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 39,452\n",
      "Trainable params: 39,452\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Full Model: None\n",
      "Train on 3456 samples, validate on 864 samples\n",
      "Epoch 1/301\n",
      "3456/3456 [==============================] - 0s 135us/step - loss: 3.6391 - acc: 0.3194 - val_loss: 1.9429 - val_acc: 0.3762\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'dierschinger', 'Pred:': 'mmnmkigfeeeev'}\n",
      "{'Orig': 'horrigan', 'Pred:': 'kjpjgecbaaaaz'}\n",
      "{'Orig': 'lang', 'Pred:': 'iiriecbaaaaak'}\n",
      "{'Orig': 'daniels', 'Pred:': 'kjqjgfcbbabbk'}\n",
      "{'Orig': 'stucker', 'Pred:': 'kkpkfecbaaaaw'}\n",
      "Epoch 2/301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3456/3456 [==============================] - 0s 73us/step - loss: 1.5221 - acc: 0.4997 - val_loss: 1.3354 - val_acc: 0.5000\n",
      "Epoch 3/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 1.1713 - acc: 0.5744 - val_loss: 1.1343 - val_acc: 0.5544\n",
      "Epoch 4/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 1.0099 - acc: 0.6036 - val_loss: 0.9633 - val_acc: 0.6736\n",
      "Epoch 5/301\n",
      "3456/3456 [==============================] - 0s 82us/step - loss: 0.8763 - acc: 0.6861 - val_loss: 0.9009 - val_acc: 0.6852\n",
      "Epoch 6/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.8321 - acc: 0.6881 - val_loss: 0.8770 - val_acc: 0.6725\n",
      "Epoch 7/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.8037 - acc: 0.6884 - val_loss: 0.8531 - val_acc: 0.6840\n",
      "Epoch 8/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.7795 - acc: 0.6861 - val_loss: 0.8348 - val_acc: 0.6933\n",
      "Epoch 9/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.7679 - acc: 0.6817 - val_loss: 0.8303 - val_acc: 0.6481\n",
      "Epoch 10/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.7589 - acc: 0.6849 - val_loss: 0.8244 - val_acc: 0.6771\n",
      "Epoch 11/301\n",
      "3456/3456 [==============================] - 0s 69us/step - loss: 0.7512 - acc: 0.6861 - val_loss: 0.8086 - val_acc: 0.6551\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'kothenbentel', 'Pred:': 'jntgjkfcbaaaj'}\n",
      "{'Orig': 'stoffers', 'Pred:': 'nsqwmedbbaaam'}\n",
      "{'Orig': 'mairet', 'Pred:': 'kdkqebaaaaaad'}\n",
      "{'Orig': 'glackemeyer', 'Pred:': 'kkffkngebaaak'}\n",
      "{'Orig': 'morr', 'Pred:': 'ioydcbaaaaaad'}\n",
      "Epoch 12/301\n",
      "3456/3456 [==============================] - 0s 75us/step - loss: 0.7426 - acc: 0.6843 - val_loss: 0.8096 - val_acc: 0.6667\n",
      "Epoch 13/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.7363 - acc: 0.6861 - val_loss: 0.8031 - val_acc: 0.6748\n",
      "Epoch 14/301\n",
      "3456/3456 [==============================] - 0s 75us/step - loss: 0.7296 - acc: 0.6806 - val_loss: 0.7964 - val_acc: 0.6562\n",
      "Epoch 15/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.7231 - acc: 0.6800 - val_loss: 0.7917 - val_acc: 0.6586\n",
      "Epoch 16/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.7171 - acc: 0.6863 - val_loss: 0.7846 - val_acc: 0.6829\n",
      "Epoch 17/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.7138 - acc: 0.6907 - val_loss: 0.7738 - val_acc: 0.6910\n",
      "Epoch 18/301\n",
      "3456/3456 [==============================] - 0s 77us/step - loss: 0.7128 - acc: 0.6832 - val_loss: 0.7822 - val_acc: 0.6944\n",
      "Epoch 19/301\n",
      "3456/3456 [==============================] - 0s 75us/step - loss: 0.7110 - acc: 0.6887 - val_loss: 0.7731 - val_acc: 0.6817\n",
      "Epoch 20/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.7049 - acc: 0.6823 - val_loss: 0.7689 - val_acc: 0.6701\n",
      "Epoch 21/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.7022 - acc: 0.6832 - val_loss: 0.7682 - val_acc: 0.6377\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'mulford', 'Pred:': 'lslgllgebaaah'}\n",
      "{'Orig': 'daniels', 'Pred:': 'hcqfgibaaaaad'}\n",
      "{'Orig': 'mayer', 'Pred:': 'hdxecbaaaaaab'}\n",
      "{'Orig': 'hughes', 'Pred:': 'ltifebaaaaaac'}\n",
      "{'Orig': 'inman', 'Pred:': 'jmnccbaaaaaab'}\n",
      "Epoch 22/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.6975 - acc: 0.6782 - val_loss: 0.7631 - val_acc: 0.6806\n",
      "Epoch 23/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.6960 - acc: 0.6826 - val_loss: 0.7584 - val_acc: 0.6840\n",
      "Epoch 24/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.6922 - acc: 0.6907 - val_loss: 0.7645 - val_acc: 0.6331\n",
      "Epoch 25/301\n",
      "3456/3456 [==============================] - 0s 79us/step - loss: 0.6913 - acc: 0.6843 - val_loss: 0.7514 - val_acc: 0.6620\n",
      "Epoch 26/301\n",
      "3456/3456 [==============================] - 0s 75us/step - loss: 0.6886 - acc: 0.6892 - val_loss: 0.7488 - val_acc: 0.6771\n",
      "Epoch 27/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.6871 - acc: 0.6858 - val_loss: 0.7459 - val_acc: 0.6956\n",
      "Epoch 28/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.6863 - acc: 0.6782 - val_loss: 0.7598 - val_acc: 0.6470\n",
      "Epoch 29/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.6816 - acc: 0.6884 - val_loss: 0.7752 - val_acc: 0.6597\n",
      "Epoch 30/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.6828 - acc: 0.6881 - val_loss: 0.7491 - val_acc: 0.6806\n",
      "Epoch 31/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.6836 - acc: 0.6832 - val_loss: 0.7558 - val_acc: 0.6285\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'moeller', 'Pred:': 'nohwmdcaaaaae'}\n",
      "{'Orig': 'lafler', 'Pred:': 'jdgjebaaaaaab'}\n",
      "{'Orig': 'nielsen', 'Pred:': 'kkfmlhcbaaaad'}\n",
      "{'Orig': 'harms', 'Pred:': 'hdtjcbaaaab'}\n",
      "{'Orig': 'rose', 'Pred:': 'iqscbaaaaab'}\n",
      "Epoch 32/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.6761 - acc: 0.6892 - val_loss: 0.7527 - val_acc: 0.6620\n",
      "Saved encoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/dense_shingle_8_union_first/encoder.h5\n",
      "Saved decoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/dense_shingle_8_union_first/decoder.h5\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_0 (Dense)                   (None, 128)          1664        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "enc_1 (Dense)                   (None, 128)          16512       enc_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 16)           2064        enc_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "log_sigma (Dense)               (None, 16)           2064        enc_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (32, 16)             0           mu[0][0]                         \n",
      "                                                                 log_sigma[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dec_0 (Dense)                   (32, 128)            2176        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec_1 (Dense)                   (32, 128)            16512       dec_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reconstruction (Dense)          (32, 12)             1548        dec_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 42,540\n",
      "Trainable params: 42,540\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Full Model: None\n",
      "Train on 3456 samples, validate on 864 samples\n",
      "Epoch 1/301\n",
      "3456/3456 [==============================] - 0s 129us/step - loss: 3.5484 - acc: 0.3857 - val_loss: 1.9697 - val_acc: 0.5289\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'long', 'Pred:': 'knniedbaaaaaf'}\n",
      "{'Orig': 'nabholz', 'Pred:': 'ljnmkjfcccccd'}\n",
      "{'Orig': 'haan', 'Pred:': 'luhigebaaaaah'}\n",
      "{'Orig': 'hickerson', 'Pred:': 'mllnmljggggfb'}\n",
      "{'Orig': 'pluckhahn', 'Pred:': 'kipkhgcbbaaav'}\n",
      "Epoch 2/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 1.4693 - acc: 0.6386 - val_loss: 1.2313 - val_acc: 0.6806\n",
      "Epoch 3/301\n",
      "3456/3456 [==============================] - 0s 75us/step - loss: 1.0512 - acc: 0.7251 - val_loss: 1.0347 - val_acc: 0.7106\n",
      "Epoch 4/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.8976 - acc: 0.7399 - val_loss: 0.9176 - val_acc: 0.7373\n",
      "Epoch 5/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.8125 - acc: 0.7546 - val_loss: 0.8648 - val_acc: 0.7037\n",
      "Epoch 6/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.7698 - acc: 0.7494 - val_loss: 0.8302 - val_acc: 0.7014\n",
      "Epoch 7/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.7311 - acc: 0.7523 - val_loss: 0.7816 - val_acc: 0.7153\n",
      "Epoch 8/301\n",
      "3456/3456 [==============================] - 0s 68us/step - loss: 0.7070 - acc: 0.7407 - val_loss: 0.7639 - val_acc: 0.7303\n",
      "Epoch 9/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.6898 - acc: 0.7399 - val_loss: 0.7586 - val_acc: 0.7025\n",
      "Epoch 10/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.6799 - acc: 0.7303 - val_loss: 0.7430 - val_acc: 0.7315\n",
      "Epoch 11/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.6673 - acc: 0.7384 - val_loss: 0.7310 - val_acc: 0.6991\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'gwan', 'Pred:': 'hueddbaaaaaac'}\n",
      "{'Orig': 'chandler', 'Pred:': 'dgeohkbaaaaad'}\n",
      "{'Orig': 'polk', 'Pred:': 'oomddaaaaaaac'}\n",
      "{'Orig': 'defley', 'Pred:': 'fehlecaaaaaab'}\n",
      "{'Orig': 'haupert', 'Pred:': 'dduoikdaaaaad'}\n",
      "Epoch 12/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.6562 - acc: 0.7390 - val_loss: 0.7279 - val_acc: 0.7269\n",
      "Epoch 13/301\n",
      "3456/3456 [==============================] - 0s 75us/step - loss: 0.6469 - acc: 0.7373 - val_loss: 0.7168 - val_acc: 0.6991\n",
      "Epoch 14/301\n",
      "3456/3456 [==============================] - 0s 76us/step - loss: 0.6373 - acc: 0.7376 - val_loss: 0.7130 - val_acc: 0.7141\n",
      "Epoch 15/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.6320 - acc: 0.7396 - val_loss: 0.7063 - val_acc: 0.6944\n",
      "Epoch 16/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.6270 - acc: 0.7347 - val_loss: 0.7043 - val_acc: 0.6794\n",
      "Epoch 17/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.6223 - acc: 0.7367 - val_loss: 0.6976 - val_acc: 0.6863\n",
      "Epoch 18/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.6225 - acc: 0.7419 - val_loss: 0.6939 - val_acc: 0.6956\n",
      "Epoch 19/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.6139 - acc: 0.7352 - val_loss: 0.6863 - val_acc: 0.7083\n",
      "Epoch 20/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.6084 - acc: 0.7378 - val_loss: 0.6939 - val_acc: 0.7164\n",
      "Epoch 21/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.6069 - acc: 0.7358 - val_loss: 0.7009 - val_acc: 0.7118\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'martin', 'Pred:': 'ndrsgabaaaaac'}\n",
      "{'Orig': 'speth', 'Pred:': 'rpfsdaaaaaaac'}\n",
      "{'Orig': 'novak', 'Pred:': 'motdcaaaaab'}\n",
      "{'Orig': 'markland', 'Pred:': 'ocsmmddaaaaad'}\n",
      "{'Orig': 'cumming', 'Pred:': 'duxkghbaaaaae'}\n",
      "Epoch 22/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.6015 - acc: 0.7378 - val_loss: 0.6672 - val_acc: 0.7257\n",
      "Epoch 23/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.5957 - acc: 0.7396 - val_loss: 0.6647 - val_acc: 0.7072\n",
      "Epoch 24/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.5978 - acc: 0.7297 - val_loss: 0.6669 - val_acc: 0.7095\n",
      "Epoch 25/301\n",
      "3456/3456 [==============================] - 0s 75us/step - loss: 0.5908 - acc: 0.7442 - val_loss: 0.6599 - val_acc: 0.7211\n",
      "Epoch 26/301\n",
      "3456/3456 [==============================] - 0s 75us/step - loss: 0.5861 - acc: 0.7381 - val_loss: 0.6576 - val_acc: 0.7083\n",
      "Epoch 27/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.5845 - acc: 0.7419 - val_loss: 0.6593 - val_acc: 0.6944\n",
      "Epoch 28/301\n",
      "3456/3456 [==============================] - 0s 75us/step - loss: 0.5902 - acc: 0.7297 - val_loss: 0.6465 - val_acc: 0.7292\n",
      "Epoch 29/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.5797 - acc: 0.7396 - val_loss: 0.6546 - val_acc: 0.7037\n",
      "Epoch 30/301\n",
      "3456/3456 [==============================] - 0s 75us/step - loss: 0.5773 - acc: 0.7462 - val_loss: 0.6456 - val_acc: 0.7014\n",
      "Epoch 31/301\n",
      "3456/3456 [==============================] - 0s 76us/step - loss: 0.5703 - acc: 0.7448 - val_loss: 0.6347 - val_acc: 0.7257\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'cundiff', 'Pred:': 'csnekucbaaaae'}\n",
      "{'Orig': 'nelson', 'Pred:': 'ofmqjcbaaaaac'}\n",
      "{'Orig': 'parkhouse', 'Pred:': 'mdsmnntkeaaag'}\n",
      "{'Orig': 'hinrichs', 'Pred:': 'igotifdaaaaad'}\n",
      "{'Orig': 'hagen', 'Pred:': 'hcgecaaaa'}\n",
      "Epoch 32/301\n",
      "3456/3456 [==============================] - 0s 75us/step - loss: 0.5714 - acc: 0.7428 - val_loss: 0.6515 - val_acc: 0.6435\n",
      "Epoch 33/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.5676 - acc: 0.7433 - val_loss: 0.6540 - val_acc: 0.6771\n",
      "Epoch 34/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.5658 - acc: 0.7474 - val_loss: 0.6379 - val_acc: 0.7315\n",
      "Epoch 35/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.5640 - acc: 0.7289 - val_loss: 0.6384 - val_acc: 0.7292\n",
      "Epoch 36/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.5618 - acc: 0.7422 - val_loss: 0.6351 - val_acc: 0.7014\n",
      "Saved encoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/dense_shingle_16_union_first/encoder.h5\n",
      "Saved decoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/dense_shingle_16_union_first/decoder.h5\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_0 (Dense)                   (None, 128)          1664        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "enc_1 (Dense)                   (None, 128)          16512       enc_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 24)           3096        enc_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "log_sigma (Dense)               (None, 24)           3096        enc_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (32, 24)             0           mu[0][0]                         \n",
      "                                                                 log_sigma[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dec_0 (Dense)                   (32, 128)            3200        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec_1 (Dense)                   (32, 128)            16512       dec_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reconstruction (Dense)          (32, 12)             1548        dec_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 45,628\n",
      "Trainable params: 45,628\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Full Model: None\n",
      "Train on 3456 samples, validate on 864 samples\n",
      "Epoch 1/301\n",
      "3456/3456 [==============================] - 0s 140us/step - loss: 3.6035 - acc: 0.4256 - val_loss: 1.9848 - val_acc: 0.5255\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'koos', 'Pred:': 'mujecbaaaaaab'}\n",
      "{'Orig': 'swaigart', 'Pred:': 'nugigedbbaaat'}\n",
      "{'Orig': 'snyder', 'Pred:': 'kkrfdbaaaaaab'}\n",
      "{'Orig': 'isaacson', 'Pred:': 'khrgggcbaaaap'}\n",
      "{'Orig': 'manson', 'Pred:': 'jgsmigcbaaaal'}\n",
      "Epoch 2/301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3456/3456 [==============================] - 0s 81us/step - loss: 1.4628 - acc: 0.6568 - val_loss: 1.2591 - val_acc: 0.6852\n",
      "Epoch 3/301\n",
      "3456/3456 [==============================] - 0s 85us/step - loss: 1.0369 - acc: 0.7364 - val_loss: 0.9941 - val_acc: 0.7535\n",
      "Epoch 4/301\n",
      "3456/3456 [==============================] - 0s 83us/step - loss: 0.8569 - acc: 0.7786 - val_loss: 0.8856 - val_acc: 0.7477\n",
      "Epoch 5/301\n",
      "3456/3456 [==============================] - 0s 84us/step - loss: 0.7700 - acc: 0.7775 - val_loss: 0.8210 - val_acc: 0.7419\n",
      "Epoch 6/301\n",
      "3456/3456 [==============================] - 0s 88us/step - loss: 0.7146 - acc: 0.7847 - val_loss: 0.7732 - val_acc: 0.7326\n",
      "Epoch 7/301\n",
      "3456/3456 [==============================] - 0s 91us/step - loss: 0.6808 - acc: 0.7862 - val_loss: 0.7546 - val_acc: 0.7072\n",
      "Epoch 8/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.6592 - acc: 0.7665 - val_loss: 0.7567 - val_acc: 0.6829\n",
      "Epoch 9/301\n",
      "3456/3456 [==============================] - 0s 75us/step - loss: 0.6390 - acc: 0.7818 - val_loss: 0.7066 - val_acc: 0.7535\n",
      "Epoch 10/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.6205 - acc: 0.7821 - val_loss: 0.6836 - val_acc: 0.7616\n",
      "Epoch 11/301\n",
      "3456/3456 [==============================] - 0s 83us/step - loss: 0.6079 - acc: 0.7798 - val_loss: 0.6853 - val_acc: 0.7095\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'mcclain', 'Pred:': 'iwfhddbbaaaae'}\n",
      "{'Orig': 'menkel', 'Pred:': 'leohdbaaaaaab'}\n",
      "{'Orig': 'messink', 'Pred:': 'iezpkhcaaaaac'}\n",
      "{'Orig': 'muto', 'Pred:': 'lttcbbaaaaaab'}\n",
      "{'Orig': 'lund', 'Pred:': 'ktncbbaaaaaab'}\n",
      "Epoch 12/301\n",
      "3456/3456 [==============================] - 0s 83us/step - loss: 0.5978 - acc: 0.7841 - val_loss: 0.6710 - val_acc: 0.7465\n",
      "Epoch 13/301\n",
      "3456/3456 [==============================] - 0s 89us/step - loss: 0.5896 - acc: 0.7795 - val_loss: 0.6766 - val_acc: 0.7674\n",
      "Epoch 14/301\n",
      "3456/3456 [==============================] - 0s 80us/step - loss: 0.5796 - acc: 0.7824 - val_loss: 0.6573 - val_acc: 0.7662\n",
      "Epoch 15/301\n",
      "3456/3456 [==============================] - 0s 82us/step - loss: 0.5750 - acc: 0.7807 - val_loss: 0.6514 - val_acc: 0.7396\n",
      "Epoch 16/301\n",
      "3456/3456 [==============================] - 0s 75us/step - loss: 0.5697 - acc: 0.7839 - val_loss: 0.6397 - val_acc: 0.7280\n",
      "Epoch 17/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.5641 - acc: 0.7812 - val_loss: 0.6331 - val_acc: 0.7743\n",
      "Epoch 18/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.5601 - acc: 0.7810 - val_loss: 0.6266 - val_acc: 0.7731\n",
      "Epoch 19/301\n",
      "3456/3456 [==============================] - 0s 77us/step - loss: 0.5560 - acc: 0.7830 - val_loss: 0.6250 - val_acc: 0.7650\n",
      "Epoch 20/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.5500 - acc: 0.7789 - val_loss: 0.6281 - val_acc: 0.7604\n",
      "Epoch 21/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.5461 - acc: 0.7827 - val_loss: 0.6184 - val_acc: 0.7801\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'carter', 'Pred:': 'edrsecaaaaaab'}\n",
      "{'Orig': 'lynch', 'Pred:': 'lxlebaaaaaaac'}\n",
      "{'Orig': 'stutsman', 'Pred:': 'qtstthdbaaaaf'}\n",
      "{'Orig': 'lunde', 'Pred:': 'lulecaaaaaaac'}\n",
      "{'Orig': 'emery', 'Pred:': 'flfqcbaaaaaab'}\n",
      "Epoch 22/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.5451 - acc: 0.7772 - val_loss: 0.6185 - val_acc: 0.7905\n",
      "Epoch 23/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.5426 - acc: 0.7642 - val_loss: 0.6171 - val_acc: 0.7384\n",
      "Epoch 24/301\n",
      "3456/3456 [==============================] - 0s 85us/step - loss: 0.5324 - acc: 0.7891 - val_loss: 0.6266 - val_acc: 0.7593\n",
      "Epoch 25/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.5367 - acc: 0.7755 - val_loss: 0.6150 - val_acc: 0.7512\n",
      "Epoch 26/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.5329 - acc: 0.7807 - val_loss: 0.6079 - val_acc: 0.7569\n",
      "Epoch 27/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.5267 - acc: 0.7824 - val_loss: 0.6293 - val_acc: 0.6701\n",
      "Epoch 28/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.5285 - acc: 0.7720 - val_loss: 0.6075 - val_acc: 0.7731\n",
      "Epoch 29/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.5230 - acc: 0.7795 - val_loss: 0.6054 - val_acc: 0.7801\n",
      "Epoch 30/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.5243 - acc: 0.7818 - val_loss: 0.5979 - val_acc: 0.7222\n",
      "Epoch 31/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.5169 - acc: 0.7749 - val_loss: 0.6023 - val_acc: 0.7269\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'caviness', 'Pred:': 'hdvlgnldcaaae'}\n",
      "{'Orig': 'belding', 'Pred:': 'cekekmaaaaaac'}\n",
      "{'Orig': 'stepanek', 'Pred:': 'prenggiecbaag'}\n",
      "{'Orig': 'hunt', 'Pred:': 'hrnccbaaaaaab'}\n",
      "{'Orig': 'loving', 'Pred:': 'mmvhncaaaaaab'}\n",
      "Epoch 32/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.5180 - acc: 0.7749 - val_loss: 0.5925 - val_acc: 0.7766\n",
      "Epoch 33/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.5094 - acc: 0.7917 - val_loss: 0.5914 - val_acc: 0.7604\n",
      "Epoch 34/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.5117 - acc: 0.7853 - val_loss: 0.6099 - val_acc: 0.7384\n",
      "Epoch 35/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.5115 - acc: 0.7830 - val_loss: 0.5975 - val_acc: 0.7245\n",
      "Epoch 36/301\n",
      "3456/3456 [==============================] - 0s 75us/step - loss: 0.5091 - acc: 0.7691 - val_loss: 0.5854 - val_acc: 0.7674\n",
      "Epoch 37/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.5076 - acc: 0.7769 - val_loss: 0.5897 - val_acc: 0.7859\n",
      "Epoch 38/301\n",
      "3456/3456 [==============================] - 0s 76us/step - loss: 0.5030 - acc: 0.7862 - val_loss: 0.5792 - val_acc: 0.7535\n",
      "Epoch 39/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.5039 - acc: 0.7786 - val_loss: 0.5825 - val_acc: 0.7141\n",
      "Epoch 40/301\n",
      "3456/3456 [==============================] - 0s 69us/step - loss: 0.4960 - acc: 0.7844 - val_loss: 0.5893 - val_acc: 0.7512\n",
      "Epoch 41/301\n",
      "3456/3456 [==============================] - 0s 68us/step - loss: 0.5001 - acc: 0.7856 - val_loss: 0.5699 - val_acc: 0.7708\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'jensen', 'Pred:': 'ienrebaaaaa'}\n",
      "{'Orig': 'dougherty', 'Pred:': 'jpshckqheaaae'}\n",
      "{'Orig': 'mackey', 'Pred:': 'lceiebaaaaaab'}\n",
      "{'Orig': 'duff', 'Pred:': 'euycbaaaa'}\n",
      "{'Orig': 'lingard', 'Pred:': 'hhlfejebaaaac'}\n",
      "Epoch 42/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.4938 - acc: 0.7818 - val_loss: 0.5788 - val_acc: 0.7292\n",
      "Epoch 43/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.4996 - acc: 0.7891 - val_loss: 0.5748 - val_acc: 0.7488\n",
      "Epoch 44/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.4946 - acc: 0.7865 - val_loss: 0.5636 - val_acc: 0.7407\n",
      "Epoch 45/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.4908 - acc: 0.7836 - val_loss: 0.5667 - val_acc: 0.7627\n",
      "Epoch 46/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.4957 - acc: 0.7801 - val_loss: 0.5823 - val_acc: 0.7454\n",
      "Epoch 47/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.4854 - acc: 0.7905 - val_loss: 0.5626 - val_acc: 0.7847\n",
      "Epoch 48/301\n",
      "3456/3456 [==============================] - 0s 76us/step - loss: 0.4873 - acc: 0.7969 - val_loss: 0.5681 - val_acc: 0.7222\n",
      "Epoch 49/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.4872 - acc: 0.7841 - val_loss: 0.5803 - val_acc: 0.7512\n",
      "Epoch 50/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.4855 - acc: 0.7844 - val_loss: 0.5691 - val_acc: 0.7269\n",
      "Epoch 51/301\n",
      "3456/3456 [==============================] - 0s 76us/step - loss: 0.4893 - acc: 0.7792 - val_loss: 0.5615 - val_acc: 0.7627\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'boals', 'Pred:': 'dmdicbaaaaab'}\n",
      "{'Orig': 'clark', 'Pred:': 'dkdocbaaaaa'}\n",
      "{'Orig': 'meyer', 'Pred:': 'lfxdbaaaa'}\n",
      "{'Orig': 'rivers', 'Pred:': 'rhvdnbaaaaab'}\n",
      "{'Orig': 'dailey', 'Pred:': 'eciiebaaa'}\n",
      "Epoch 52/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.4793 - acc: 0.7972 - val_loss: 0.5657 - val_acc: 0.7280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.4803 - acc: 0.7839 - val_loss: 0.5683 - val_acc: 0.7072\n",
      "Epoch 54/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.4759 - acc: 0.7957 - val_loss: 0.5565 - val_acc: 0.7512\n",
      "Epoch 55/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.4854 - acc: 0.7847 - val_loss: 0.5765 - val_acc: 0.7083\n",
      "Epoch 56/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.4773 - acc: 0.7758 - val_loss: 0.5649 - val_acc: 0.7569\n",
      "Epoch 57/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.4762 - acc: 0.7867 - val_loss: 0.5489 - val_acc: 0.7546\n",
      "Epoch 58/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.4778 - acc: 0.7810 - val_loss: 0.5617 - val_acc: 0.7812\n",
      "Epoch 59/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.4732 - acc: 0.7882 - val_loss: 0.5500 - val_acc: 0.7593\n",
      "Epoch 60/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.4696 - acc: 0.7920 - val_loss: 0.5515 - val_acc: 0.7558\n",
      "Epoch 61/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.4723 - acc: 0.7815 - val_loss: 0.5704 - val_acc: 0.7037\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'murphy', 'Pred:': 'lrtngaaaaab'}\n",
      "{'Orig': 'menkel', 'Pred:': 'ldnidaaaa'}\n",
      "{'Orig': 'stubbs', 'Pred:': 'rruxdaaaaaab'}\n",
      "{'Orig': 'dodd', 'Pred:': 'djybbaaaa'}\n",
      "{'Orig': 'cunningham', 'Pred:': 'erzlhodbaaaac'}\n",
      "Epoch 62/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.4739 - acc: 0.7763 - val_loss: 0.5512 - val_acc: 0.7535\n",
      "Saved encoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/dense_shingle_24_union_first/encoder.h5\n",
      "Saved decoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/dense_shingle_24_union_first/decoder.h5\n"
     ]
    }
   ],
   "source": [
    "ORIG_LENGTH = 12\n",
    "BATCH_SIZE = 32\n",
    "ENCODE_DIM = [128, 128] \n",
    "DECODE_DIM = [128, 128]\n",
    "LR = 5e-4\n",
    "EPOCHS=301\n",
    "EMBED_TYPE = 'shingles'\n",
    "# Embed letters \n",
    "namesA = preprocess.embed(iowa_matches['lname1915'],\n",
    "                         max_length=ORIG_LENGTH, \n",
    "                         embed_type=EMBED_TYPE, \n",
    "                         normalize=True)\n",
    "namesB = preprocess.embed(iowa_matches['lname1940'],\n",
    "                         max_length=ORIG_LENGTH, \n",
    "                         embed_type=EMBED_TYPE, \n",
    "                         normalize=True)\n",
    "\n",
    "LATENT_DIM = [2,4,8,16,24]\n",
    "for latent_dim in LATENT_DIM: \n",
    "    save_path = '/Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/dense_shingle_{}_union_first/'.format(latent_dim)\n",
    "    run_id = 'dense_{}'.format(latent_dim)\n",
    "    vae = recordlinker.model.VAE(batch_size=BATCH_SIZE,\n",
    "                                 orig_dim=ORIG_LENGTH, \n",
    "                                 latent_dim=latent_dim,\n",
    "                                 encode_dim=ENCODE_DIM,\n",
    "                                 decode_dim=DECODE_DIM,\n",
    "                                 lr=LR)\n",
    "\n",
    "    model, encoder, decoder = vae.train(namesA, namesB, \n",
    "                                        epochs=EPOCHS, \n",
    "                                        run_id=run_id,\n",
    "                                        save_path=save_path,\n",
    "                                        optimizer='adam', \n",
    "                                        tensorboard=True, \n",
    "                                        earlystop=True,\n",
    "                                        earlystop_patience=15,\n",
    "                                        reconstruct=True, \n",
    "                                        reconstruct_type='s',\n",
    "                                        reconstruct_display=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 12, 28)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_0 (LSTM)                    (None, 12, 128)      80384       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "enc_1 (LSTM)                    (None, 12, 64)       49408       enc_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 768)          0           enc_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 4)            3076        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "log_sigma (Dense)               (None, 4)            3076        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 4)            0           mu[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 4)            0           log_sigma[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z (Lambda)                      (32, 4)              0           leaky_re_lu_1[0][0]              \n",
      "                                                                 leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (32, 12, 4)          0           z[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "dec_0 (LSTM)                    (32, 12, 64)         17664       repeat_vector_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (32, 12, 28)         1820        dec_0[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 155,428\n",
      "Trainable params: 155,428\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 3456 samples, validate on 864 samples\n",
      "Epoch 1/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 24.5703 - acc: 0.4650 - val_loss: 20.7147 - val_acc: 0.4906\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'davis', 'Pred:': 'ee'}\n",
      "{'Orig': 'metzger', 'Pred:': 'eee'}\n",
      "{'Orig': 'duff', 'Pred:': 'ee'}\n",
      "{'Orig': 'crouch', 'Pred:': 'eee'}\n",
      "{'Orig': 'rivett', 'Pred:': 'eee'}\n",
      "Epoch 2/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 20.1612 - acc: 0.5172 - val_loss: 19.6886 - val_acc: 0.5240\n",
      "Epoch 3/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 19.5164 - acc: 0.5279 - val_loss: 19.2960 - val_acc: 0.5336\n",
      "Epoch 4/350\n",
      "3456/3456 [==============================] - 3s 917us/step - loss: 19.2047 - acc: 0.5324 - val_loss: 19.2443 - val_acc: 0.5337\n",
      "Epoch 5/350\n",
      "3456/3456 [==============================] - 3s 890us/step - loss: 19.0630 - acc: 0.5339 - val_loss: 19.0423 - val_acc: 0.5334\n",
      "Epoch 6/350\n",
      "3456/3456 [==============================] - 3s 954us/step - loss: 19.0001 - acc: 0.5336 - val_loss: 19.0139 - val_acc: 0.5332\n",
      "Epoch 7/350\n",
      "3456/3456 [==============================] - 3s 951us/step - loss: 18.8646 - acc: 0.5348 - val_loss: 19.0387 - val_acc: 0.5320\n",
      "Epoch 8/350\n",
      "3456/3456 [==============================] - 3s 916us/step - loss: 18.6149 - acc: 0.5386 - val_loss: 18.5193 - val_acc: 0.5395\n",
      "Epoch 9/350\n",
      "3456/3456 [==============================] - 3s 902us/step - loss: 18.2860 - acc: 0.5443 - val_loss: 18.2935 - val_acc: 0.5441\n",
      "Epoch 10/350\n",
      "3456/3456 [==============================] - 3s 888us/step - loss: 18.0383 - acc: 0.5512 - val_loss: 18.0925 - val_acc: 0.5518\n",
      "Epoch 11/350\n",
      "3456/3456 [==============================] - 3s 900us/step - loss: 17.9110 - acc: 0.5557 - val_loss: 18.0099 - val_acc: 0.5543\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'selman', 'Pred:': 'ooooon'}\n",
      "{'Orig': 'hird', 'Pred:': 'oees'}\n",
      "{'Orig': 'hussman', 'Pred:': 'mooooon'}\n",
      "{'Orig': 'coon', 'Pred:': 'ooot'}\n",
      "{'Orig': 'mcchright', 'Pred:': 'moaaaooon'}\n",
      "Epoch 12/350\n",
      "3456/3456 [==============================] - 3s 968us/step - loss: 17.7781 - acc: 0.5598 - val_loss: 17.8597 - val_acc: 0.5634\n",
      "Epoch 13/350\n",
      "3456/3456 [==============================] - 3s 920us/step - loss: 17.6678 - acc: 0.5632 - val_loss: 17.7838 - val_acc: 0.5618\n",
      "Epoch 14/350\n",
      "3456/3456 [==============================] - 3s 893us/step - loss: 17.5734 - acc: 0.5663 - val_loss: 17.7900 - val_acc: 0.5632\n",
      "Epoch 15/350\n",
      "3456/3456 [==============================] - 3s 956us/step - loss: 17.4948 - acc: 0.5656 - val_loss: 17.6499 - val_acc: 0.5631\n",
      "Epoch 16/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 17.3897 - acc: 0.5689 - val_loss: 17.4954 - val_acc: 0.5692\n",
      "Epoch 17/350\n",
      "3456/3456 [==============================] - 3s 1ms/step - loss: 17.2899 - acc: 0.5703 - val_loss: 17.4308 - val_acc: 0.5664\n",
      "Epoch 18/350\n",
      "3456/3456 [==============================] - 3s 994us/step - loss: 17.2702 - acc: 0.5696 - val_loss: 17.4577 - val_acc: 0.5639\n",
      "Epoch 19/350\n",
      "3456/3456 [==============================] - 3s 898us/step - loss: 17.2040 - acc: 0.5703 - val_loss: 17.3628 - val_acc: 0.5698\n",
      "Epoch 20/350\n",
      "3456/3456 [==============================] - 3s 914us/step - loss: 17.0909 - acc: 0.5714 - val_loss: 17.3098 - val_acc: 0.5661\n",
      "Epoch 21/350\n",
      "3456/3456 [==============================] - 3s 928us/step - loss: 17.0306 - acc: 0.5719 - val_loss: 17.1720 - val_acc: 0.5712\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'olson', 'Pred:': 'oooon'}\n",
      "{'Orig': 'trpkosh', 'Pred:': 'moenenn'}\n",
      "{'Orig': 'cunningham', 'Pred:': 'maannssaon'}\n",
      "{'Orig': 'halverstatt', 'Pred:': 'maannnrraan'}\n",
      "{'Orig': 'dodge', 'Pred:': 'ooeee'}\n",
      "Epoch 22/350\n",
      "3456/3456 [==============================] - 3s 926us/step - loss: 16.9053 - acc: 0.5746 - val_loss: 17.0166 - val_acc: 0.5745\n",
      "Epoch 23/350\n",
      "3456/3456 [==============================] - 3s 913us/step - loss: 16.7921 - acc: 0.5794 - val_loss: 17.0405 - val_acc: 0.5752\n",
      "Epoch 24/350\n",
      "3456/3456 [==============================] - 3s 903us/step - loss: 16.7538 - acc: 0.5806 - val_loss: 16.9107 - val_acc: 0.5816\n",
      "Epoch 25/350\n",
      "3456/3456 [==============================] - 3s 882us/step - loss: 16.6355 - acc: 0.5860 - val_loss: 16.7916 - val_acc: 0.5833\n",
      "Epoch 26/350\n",
      "3456/3456 [==============================] - 3s 881us/step - loss: 16.5280 - acc: 0.5897 - val_loss: 16.7519 - val_acc: 0.5869\n",
      "Epoch 27/350\n",
      "3456/3456 [==============================] - 3s 927us/step - loss: 16.4842 - acc: 0.5912 - val_loss: 16.7295 - val_acc: 0.5857\n",
      "Epoch 28/350\n",
      "3456/3456 [==============================] - 3s 1ms/step - loss: 16.3290 - acc: 0.5962 - val_loss: 16.5436 - val_acc: 0.5916\n",
      "Epoch 29/350\n",
      "3456/3456 [==============================] - 3s 1ms/step - loss: 16.2541 - acc: 0.5983 - val_loss: 16.4694 - val_acc: 0.5995\n",
      "Epoch 30/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 16.1721 - acc: 0.6027 - val_loss: 16.3816 - val_acc: 0.6019\n",
      "Epoch 31/350\n",
      "3456/3456 [==============================] - 3s 978us/step - loss: 16.1036 - acc: 0.6054 - val_loss: 16.2883 - val_acc: 0.6041\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'maher', 'Pred:': 'moler'}\n",
      "{'Orig': 'moler', 'Pred:': 'moler'}\n",
      "{'Orig': 'staufenbeil', 'Pred:': 'mennnnnnaeer'}\n",
      "{'Orig': 'lambert', 'Pred:': 'marlens'}\n",
      "{'Orig': 'nelson', 'Pred:': 'marson'}\n",
      "Epoch 32/350\n",
      "3456/3456 [==============================] - 3s 986us/step - loss: 15.9801 - acc: 0.6087 - val_loss: 16.2729 - val_acc: 0.6019\n",
      "Epoch 33/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 15.9051 - acc: 0.6097 - val_loss: 16.1126 - val_acc: 0.6059\n",
      "Epoch 34/350\n",
      "3456/3456 [==============================] - 3s 904us/step - loss: 15.7982 - acc: 0.6138 - val_loss: 16.0037 - val_acc: 0.6101\n",
      "Epoch 35/350\n",
      "3456/3456 [==============================] - 3s 888us/step - loss: 15.7368 - acc: 0.6145 - val_loss: 16.0814 - val_acc: 0.6040\n",
      "Epoch 36/350\n",
      "3456/3456 [==============================] - 3s 892us/step - loss: 15.6511 - acc: 0.6163 - val_loss: 15.9744 - val_acc: 0.6088\n",
      "Epoch 37/350\n",
      "3456/3456 [==============================] - 3s 879us/step - loss: 15.6212 - acc: 0.6155 - val_loss: 15.8737 - val_acc: 0.6085\n",
      "Epoch 38/350\n",
      "3456/3456 [==============================] - 3s 883us/step - loss: 15.5014 - acc: 0.6193 - val_loss: 15.8365 - val_acc: 0.6092\n",
      "Epoch 39/350\n",
      "3456/3456 [==============================] - 3s 899us/step - loss: 15.4378 - acc: 0.6208 - val_loss: 15.7861 - val_acc: 0.6139\n",
      "Epoch 40/350\n",
      "3456/3456 [==============================] - 3s 939us/step - loss: 15.3856 - acc: 0.6209 - val_loss: 15.7292 - val_acc: 0.6127\n",
      "Epoch 41/350\n",
      "3456/3456 [==============================] - 3s 986us/step - loss: 15.3177 - acc: 0.6214 - val_loss: 15.7407 - val_acc: 0.6120\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'cook', 'Pred:': 'mont'}\n",
      "{'Orig': 'mccalley', 'Pred:': 'mennnler'}\n",
      "{'Orig': 'drummond', 'Pred:': 'mereerrd'}\n",
      "{'Orig': 'hesche', 'Pred:': 'morlee'}\n",
      "{'Orig': 'hoffmann', 'Pred:': 'marsman'}\n",
      "Epoch 42/350\n",
      "3456/3456 [==============================] - 3s 1ms/step - loss: 15.2871 - acc: 0.6223 - val_loss: 15.6288 - val_acc: 0.6150\n",
      "Epoch 43/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 15.1666 - acc: 0.6248 - val_loss: 15.6729 - val_acc: 0.6137\n",
      "Epoch 44/350\n",
      "3456/3456 [==============================] - 3s 918us/step - loss: 15.1351 - acc: 0.6261 - val_loss: 15.6366 - val_acc: 0.6141\n",
      "Epoch 45/350\n",
      "3456/3456 [==============================] - 3s 885us/step - loss: 15.0983 - acc: 0.6262 - val_loss: 15.6186 - val_acc: 0.6136\n",
      "Epoch 46/350\n",
      "3456/3456 [==============================] - 3s 896us/step - loss: 15.0382 - acc: 0.6276 - val_loss: 15.4965 - val_acc: 0.6185\n",
      "Epoch 47/350\n",
      "3456/3456 [==============================] - 3s 937us/step - loss: 15.0041 - acc: 0.6277 - val_loss: 15.5921 - val_acc: 0.6164\n",
      "Epoch 48/350\n",
      "3456/3456 [==============================] - 3s 977us/step - loss: 14.9466 - acc: 0.6292 - val_loss: 15.4414 - val_acc: 0.6134\n",
      "Epoch 49/350\n",
      "3456/3456 [==============================] - 3s 939us/step - loss: 14.9190 - acc: 0.6295 - val_loss: 15.5371 - val_acc: 0.6151\n",
      "Epoch 50/350\n",
      "3456/3456 [==============================] - 3s 897us/step - loss: 14.8575 - acc: 0.6314 - val_loss: 15.4100 - val_acc: 0.6195\n",
      "Epoch 51/350\n",
      "3456/3456 [==============================] - 3s 899us/step - loss: 14.8250 - acc: 0.6312 - val_loss: 15.4857 - val_acc: 0.6176\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'maccabee', 'Pred:': 'meneeale'}\n",
      "{'Orig': 'norton', 'Pred:': 'marton'}\n",
      "{'Orig': 'olliver', 'Pred:': 'marlle'}\n",
      "{'Orig': 'donnelly', 'Pred:': 'mennell'}\n",
      "{'Orig': 'decker', 'Pred:': 'manler'}\n",
      "Epoch 52/350\n",
      "3456/3456 [==============================] - 3s 913us/step - loss: 14.7426 - acc: 0.6342 - val_loss: 15.4538 - val_acc: 0.6204\n",
      "Epoch 53/350\n",
      "3456/3456 [==============================] - 3s 948us/step - loss: 14.7006 - acc: 0.6374 - val_loss: 15.2461 - val_acc: 0.6294\n",
      "Epoch 54/350\n",
      "3456/3456 [==============================] - 3s 940us/step - loss: 14.5232 - acc: 0.6430 - val_loss: 15.2887 - val_acc: 0.6264\n",
      "Epoch 55/350\n",
      "3456/3456 [==============================] - 3s 910us/step - loss: 14.4080 - acc: 0.6458 - val_loss: 15.0108 - val_acc: 0.6320\n",
      "Epoch 56/350\n",
      "3456/3456 [==============================] - 3s 978us/step - loss: 14.2887 - acc: 0.6466 - val_loss: 15.0246 - val_acc: 0.6366\n",
      "Epoch 57/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 14.2867 - acc: 0.6463 - val_loss: 14.8967 - val_acc: 0.6390\n",
      "Epoch 58/350\n",
      "3456/3456 [==============================] - 3s 893us/step - loss: 14.1400 - acc: 0.6502 - val_loss: 14.8684 - val_acc: 0.6387\n",
      "Epoch 59/350\n",
      "3456/3456 [==============================] - 3s 972us/step - loss: 14.1200 - acc: 0.6495 - val_loss: 14.8296 - val_acc: 0.6381\n",
      "Epoch 60/350\n",
      "3456/3456 [==============================] - 3s 969us/step - loss: 14.0155 - acc: 0.6531 - val_loss: 14.8187 - val_acc: 0.6387\n",
      "Epoch 61/350\n",
      "3456/3456 [==============================] - 3s 886us/step - loss: 14.0004 - acc: 0.6519 - val_loss: 14.7136 - val_acc: 0.6456\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'kothenbentel', 'Pred:': 'meeeeennieel'}\n",
      "{'Orig': 'clark', 'Pred:': 'mannk'}\n",
      "{'Orig': 'odendahl', 'Pred:': 'mannnnel'}\n",
      "{'Orig': 'mingus', 'Pred:': 'mannis'}\n",
      "{'Orig': 'noethe', 'Pred:': 'mernne'}\n",
      "Epoch 62/350\n",
      "3456/3456 [==============================] - 3s 987us/step - loss: 13.9028 - acc: 0.6558 - val_loss: 14.7311 - val_acc: 0.6443\n",
      "Epoch 63/350\n",
      "3456/3456 [==============================] - 3s 962us/step - loss: 13.8216 - acc: 0.6565 - val_loss: 14.8187 - val_acc: 0.6387\n",
      "Epoch 64/350\n",
      "3456/3456 [==============================] - 3s 893us/step - loss: 13.7977 - acc: 0.6558 - val_loss: 14.6991 - val_acc: 0.6393\n",
      "Epoch 65/350\n",
      "3456/3456 [==============================] - 3s 982us/step - loss: 13.7796 - acc: 0.6563 - val_loss: 14.6186 - val_acc: 0.6413\n",
      "Epoch 66/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 13.6758 - acc: 0.6605 - val_loss: 14.6226 - val_acc: 0.6429\n",
      "Epoch 67/350\n",
      "3456/3456 [==============================] - 3s 954us/step - loss: 13.7457 - acc: 0.6569 - val_loss: 14.6615 - val_acc: 0.6397\n",
      "Epoch 68/350\n",
      "3456/3456 [==============================] - 3s 1ms/step - loss: 13.6172 - acc: 0.6612 - val_loss: 14.5708 - val_acc: 0.6459\n",
      "Epoch 69/350\n",
      "3456/3456 [==============================] - 3s 895us/step - loss: 13.5475 - acc: 0.6627 - val_loss: 14.5272 - val_acc: 0.6485\n",
      "Epoch 70/350\n",
      "3456/3456 [==============================] - 3s 896us/step - loss: 13.5439 - acc: 0.6630 - val_loss: 14.5316 - val_acc: 0.6458\n",
      "Epoch 71/350\n",
      "3456/3456 [==============================] - 3s 941us/step - loss: 13.4834 - acc: 0.6649 - val_loss: 14.6982 - val_acc: 0.6441\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'kivlin', 'Pred:': 'malling'}\n",
      "{'Orig': 'miller', 'Pred:': 'maller'}\n",
      "{'Orig': 'myers', 'Pred:': 'seers'}\n",
      "{'Orig': 'deardoff', 'Pred:': 'mereeerd'}\n",
      "{'Orig': 'husted', 'Pred:': 'mererd'}\n",
      "Epoch 72/350\n",
      "3456/3456 [==============================] - 3s 891us/step - loss: 13.4881 - acc: 0.6632 - val_loss: 14.4248 - val_acc: 0.6497\n",
      "Epoch 73/350\n",
      "3456/3456 [==============================] - 3s 912us/step - loss: 13.4320 - acc: 0.6663 - val_loss: 14.4838 - val_acc: 0.6469\n",
      "Epoch 74/350\n",
      "3456/3456 [==============================] - 3s 1ms/step - loss: 13.3426 - acc: 0.6675 - val_loss: 14.4398 - val_acc: 0.6516\n",
      "Epoch 75/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 13.3765 - acc: 0.6667 - val_loss: 14.5291 - val_acc: 0.6478\n",
      "Epoch 76/350\n",
      "3456/3456 [==============================] - 3s 987us/step - loss: 13.2727 - acc: 0.6698 - val_loss: 14.4112 - val_acc: 0.6495\n",
      "Epoch 77/350\n",
      "3456/3456 [==============================] - 3s 952us/step - loss: 13.2392 - acc: 0.6700 - val_loss: 14.4497 - val_acc: 0.6466\n",
      "Epoch 78/350\n",
      "3456/3456 [==============================] - 3s 990us/step - loss: 13.2679 - acc: 0.6693 - val_loss: 14.4073 - val_acc: 0.6509\n",
      "Epoch 79/350\n",
      "3456/3456 [==============================] - 3s 947us/step - loss: 13.1317 - acc: 0.6741 - val_loss: 14.3131 - val_acc: 0.6531\n",
      "Epoch 80/350\n",
      "3456/3456 [==============================] - 3s 935us/step - loss: 13.1397 - acc: 0.6720 - val_loss: 14.4020 - val_acc: 0.6514\n",
      "Epoch 81/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 13.1172 - acc: 0.6720 - val_loss: 14.4152 - val_acc: 0.6494\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'griesse', 'Pred:': 'seeetse'}\n",
      "{'Orig': 'dengler', 'Pred:': 'manple'}\n",
      "{'Orig': 'schellhorn', 'Pred:': 'mallellest'}\n",
      "{'Orig': 'stillwell', 'Pred:': 'macnnnell'}\n",
      "{'Orig': 'martin', 'Pred:': 'merten'}\n",
      "Epoch 82/350\n",
      "3456/3456 [==============================] - 3s 921us/step - loss: 13.0775 - acc: 0.6733 - val_loss: 14.4113 - val_acc: 0.6505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/350\n",
      "3456/3456 [==============================] - 3s 893us/step - loss: 13.0203 - acc: 0.6740 - val_loss: 14.3116 - val_acc: 0.6552\n",
      "Epoch 84/350\n",
      "3456/3456 [==============================] - 3s 956us/step - loss: 13.0143 - acc: 0.6733 - val_loss: 14.3460 - val_acc: 0.6504\n",
      "Epoch 85/350\n",
      "3456/3456 [==============================] - 3s 996us/step - loss: 12.9665 - acc: 0.6744 - val_loss: 14.2759 - val_acc: 0.6519\n",
      "Epoch 86/350\n",
      "3456/3456 [==============================] - 3s 970us/step - loss: 12.9079 - acc: 0.6756 - val_loss: 14.2616 - val_acc: 0.6541\n",
      "Epoch 87/350\n",
      "3456/3456 [==============================] - 3s 960us/step - loss: 12.9068 - acc: 0.6748 - val_loss: 14.4360 - val_acc: 0.6473\n",
      "Epoch 88/350\n",
      "3456/3456 [==============================] - 3s 940us/step - loss: 12.8692 - acc: 0.6769 - val_loss: 14.2529 - val_acc: 0.6536\n",
      "Epoch 89/350\n",
      "3456/3456 [==============================] - 3s 914us/step - loss: 12.7886 - acc: 0.6800 - val_loss: 14.2469 - val_acc: 0.6540\n",
      "Epoch 90/350\n",
      "3456/3456 [==============================] - 3s 967us/step - loss: 12.7937 - acc: 0.6792 - val_loss: 14.1945 - val_acc: 0.6588\n",
      "Epoch 91/350\n",
      "3456/3456 [==============================] - 3s 1ms/step - loss: 12.7603 - acc: 0.6797 - val_loss: 14.2207 - val_acc: 0.6546\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'dougherty', 'Pred:': 'mereearey'}\n",
      "{'Orig': 'schaeffer', 'Pred:': 'maneehee'}\n",
      "{'Orig': 'strueber', 'Pred:': 'seeersey'}\n",
      "{'Orig': 'swartzendrub', 'Pred:': 'sstttennnbub'}\n",
      "{'Orig': 'stampher', 'Pred:': 'meeenler'}\n",
      "Epoch 92/350\n",
      "3456/3456 [==============================] - 3s 917us/step - loss: 12.7146 - acc: 0.6794 - val_loss: 14.1200 - val_acc: 0.6577\n",
      "Epoch 93/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 12.6716 - acc: 0.6818 - val_loss: 14.1358 - val_acc: 0.6565\n",
      "Epoch 94/350\n",
      "3456/3456 [==============================] - 3s 941us/step - loss: 12.6517 - acc: 0.6821 - val_loss: 14.1064 - val_acc: 0.6588\n",
      "Epoch 95/350\n",
      "3456/3456 [==============================] - 3s 881us/step - loss: 12.6306 - acc: 0.6814 - val_loss: 14.1786 - val_acc: 0.6570\n",
      "Epoch 96/350\n",
      "3456/3456 [==============================] - 3s 900us/step - loss: 12.6207 - acc: 0.6810 - val_loss: 14.0782 - val_acc: 0.6570\n",
      "Epoch 97/350\n",
      "3456/3456 [==============================] - 3s 900us/step - loss: 12.5597 - acc: 0.6828 - val_loss: 14.0790 - val_acc: 0.6557\n",
      "Epoch 98/350\n",
      "3456/3456 [==============================] - 3s 890us/step - loss: 12.5312 - acc: 0.6824 - val_loss: 14.0368 - val_acc: 0.6604\n",
      "Epoch 99/350\n",
      "3456/3456 [==============================] - 3s 917us/step - loss: 12.6735 - acc: 0.6771 - val_loss: 14.0611 - val_acc: 0.6594\n",
      "Epoch 100/350\n",
      "3456/3456 [==============================] - 3s 916us/step - loss: 12.4366 - acc: 0.6850 - val_loss: 13.9856 - val_acc: 0.6583\n",
      "Epoch 101/350\n",
      "3456/3456 [==============================] - 3s 897us/step - loss: 12.3872 - acc: 0.6869 - val_loss: 14.1412 - val_acc: 0.6551\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'housley', 'Pred:': 'mornle'}\n",
      "{'Orig': 'hines', 'Pred:': 'manes'}\n",
      "{'Orig': 'eckardt', 'Pred:': 'mallart'}\n",
      "{'Orig': 'rettenmaier', 'Pred:': 'stetenaaeer'}\n",
      "{'Orig': 'kracht', 'Pred:': 'merrtt'}\n",
      "Epoch 102/350\n",
      "3456/3456 [==============================] - 3s 904us/step - loss: 12.3997 - acc: 0.6850 - val_loss: 13.9431 - val_acc: 0.6614\n",
      "Epoch 103/350\n",
      "3456/3456 [==============================] - 3s 893us/step - loss: 12.3353 - acc: 0.6886 - val_loss: 14.1278 - val_acc: 0.6520\n",
      "Epoch 104/350\n",
      "3456/3456 [==============================] - 3s 888us/step - loss: 12.3946 - acc: 0.6861 - val_loss: 13.9186 - val_acc: 0.6615\n",
      "Epoch 105/350\n",
      "3456/3456 [==============================] - 3s 970us/step - loss: 12.2809 - acc: 0.6892 - val_loss: 13.9731 - val_acc: 0.6629\n",
      "Epoch 106/350\n",
      "3456/3456 [==============================] - 3s 922us/step - loss: 12.2212 - acc: 0.6918 - val_loss: 13.9661 - val_acc: 0.6618\n",
      "Epoch 107/350\n",
      "3456/3456 [==============================] - 3s 933us/step - loss: 12.2100 - acc: 0.6912 - val_loss: 13.9944 - val_acc: 0.6634\n",
      "Epoch 108/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 12.2336 - acc: 0.6908 - val_loss: 14.1620 - val_acc: 0.6544\n",
      "Epoch 109/350\n",
      "3456/3456 [==============================] - 3s 948us/step - loss: 12.2126 - acc: 0.6906 - val_loss: 13.9406 - val_acc: 0.6606\n",
      "Saved encoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/lstm_letter_4_iowa_last_smaller_decoder/encoder.h5\n",
      "Saved decoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/lstm_letter_4_iowa_last_smaller_decoder/decoder.h5\n"
     ]
    }
   ],
   "source": [
    "# Train \n",
    "# One hot encoding of names\n",
    "ORIG_LENGTH = 12\n",
    "classes = 28\n",
    "LR = 5e-4\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 350\n",
    "namesA = preprocess.embed(iowa_matches['lname1915'],\n",
    "                         max_length=ORIG_LENGTH, \n",
    "                         embed_type='letters', \n",
    "                         normalize=False, \n",
    "                         categorical=True)\n",
    "\n",
    "namesB = preprocess.embed(iowa_matches['lname1940'],\n",
    "                         max_length=ORIG_LENGTH, \n",
    "                         embed_type='letters',\n",
    "                         normalize=False, \n",
    "                         categorical=True)\n",
    "\n",
    "\n",
    "LATENT_DIM = [4]\n",
    "for latent_dim in LATENT_DIM: \n",
    "    save_path = '/Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/lstm_letter_{}_iowa_last_smaller_decoder/'.format(latent_dim)\n",
    "    run_id = 'lstm_{}'.format(latent_dim)\n",
    "    lstm_vae = recordlinker.model.LSTMVAE(batch_size=BATCH_SIZE, \n",
    "                                          timesteps=ORIG_LENGTH, \n",
    "                                          orig_dim=classes,\n",
    "                                          latent_dim=latent_dim,\n",
    "                                          encode_dim=[128,64], \n",
    "                                          decode_dim=[64],\n",
    "                                          lr=LR) \n",
    "    model_lstm, model_encoder, model_decoder = lstm_vae.train(namesA, namesB, \n",
    "                                                              epochs=EPOCHS, \n",
    "                                                              run_id=run_id, \n",
    "                                                              save_path=save_path, \n",
    "                                                              earlystop=True,\n",
    "                                                              earlystop_patience=6,\n",
    "                                                              tensorboard=True, \n",
    "                                                              reconstruct=True, \n",
    "                                                              reconstruct_display=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
