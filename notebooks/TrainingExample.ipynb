{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    " \n",
    "import recordlinker\n",
    "from recordlinker import preprocess \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', 'info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iowa_matches = pd.read_csv('/Users/kailinlu/Desktop/QMSSWork/RecordLinking/recordlinker/recordlinker/data/iowa_matches.csv')\n",
    "iowa_nonmatches = pd.read_csv('/Users/kailinlu/Desktop/QMSSWork/RecordLinking/recordlinker/recordlinker/data/iowa_nonmatches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid1915</th>\n",
       "      <th>fname1915</th>\n",
       "      <th>lname1915</th>\n",
       "      <th>fullname1915</th>\n",
       "      <th>yob1915</th>\n",
       "      <th>hhid</th>\n",
       "      <th>fname1940</th>\n",
       "      <th>lname1940</th>\n",
       "      <th>fullname1940</th>\n",
       "      <th>yob1940</th>\n",
       "      <th>uid-hhid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uid0910071227</td>\n",
       "      <td>donald d</td>\n",
       "      <td>cutler</td>\n",
       "      <td>donald d cutler</td>\n",
       "      <td>1911</td>\n",
       "      <td>19067</td>\n",
       "      <td>donald dean</td>\n",
       "      <td>cutler</td>\n",
       "      <td>donald dean cutler</td>\n",
       "      <td>1911</td>\n",
       "      <td>uid0910071227-19067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uid0063131339</td>\n",
       "      <td>homer</td>\n",
       "      <td>taylor</td>\n",
       "      <td>homer taylor</td>\n",
       "      <td>1912</td>\n",
       "      <td>71505</td>\n",
       "      <td>homer ellis</td>\n",
       "      <td>taylor</td>\n",
       "      <td>homer ellis taylor</td>\n",
       "      <td>1912</td>\n",
       "      <td>uid0063131339-71505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uid0044088276</td>\n",
       "      <td>earl</td>\n",
       "      <td>stearnes</td>\n",
       "      <td>earl stearnes</td>\n",
       "      <td>1899</td>\n",
       "      <td>109708</td>\n",
       "      <td>earl</td>\n",
       "      <td>stearns</td>\n",
       "      <td>earl stearns</td>\n",
       "      <td>1900</td>\n",
       "      <td>uid0044088276-109708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uid0067053130</td>\n",
       "      <td>theodore</td>\n",
       "      <td>hornaday</td>\n",
       "      <td>theodore hornaday</td>\n",
       "      <td>1904</td>\n",
       "      <td>108304</td>\n",
       "      <td>theodore i</td>\n",
       "      <td>harnaday</td>\n",
       "      <td>theodore i harnaday</td>\n",
       "      <td>1904</td>\n",
       "      <td>uid0067053130-108304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uid0066046148</td>\n",
       "      <td>jack r</td>\n",
       "      <td>turner</td>\n",
       "      <td>jack r turner</td>\n",
       "      <td>1907</td>\n",
       "      <td>105092</td>\n",
       "      <td>jack r</td>\n",
       "      <td>turner</td>\n",
       "      <td>jack r turner</td>\n",
       "      <td>1907</td>\n",
       "      <td>uid0066046148-105092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         uid1915 fname1915 lname1915       fullname1915  yob1915    hhid  \\\n",
       "0  uid0910071227  donald d    cutler    donald d cutler     1911   19067   \n",
       "1  uid0063131339     homer    taylor       homer taylor     1912   71505   \n",
       "2  uid0044088276      earl  stearnes      earl stearnes     1899  109708   \n",
       "3  uid0067053130  theodore  hornaday  theodore hornaday     1904  108304   \n",
       "4  uid0066046148    jack r    turner      jack r turner     1907  105092   \n",
       "\n",
       "     fname1940 lname1940         fullname1940  yob1940              uid-hhid  \n",
       "0  donald dean    cutler   donald dean cutler     1911   uid0910071227-19067  \n",
       "1  homer ellis    taylor   homer ellis taylor     1912   uid0063131339-71505  \n",
       "2         earl   stearns         earl stearns     1900  uid0044088276-109708  \n",
       "3   theodore i  harnaday  theodore i harnaday     1904  uid0067053130-108304  \n",
       "4       jack r    turner        jack r turner     1907  uid0066046148-105092  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iowa_matches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "union_matches = pd.read_csv('/Users/kailinlu/Desktop/QMSSWork/RecordLinking/recordlinker/recordlinker/data/unionarmy_matches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recidnum</th>\n",
       "      <th>recname1</th>\n",
       "      <th>recname2</th>\n",
       "      <th>last1</th>\n",
       "      <th>first1</th>\n",
       "      <th>last2</th>\n",
       "      <th>first2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100501001</td>\n",
       "      <td>anson charles h</td>\n",
       "      <td>anson charles h</td>\n",
       "      <td>anson</td>\n",
       "      <td>charles h</td>\n",
       "      <td>anson</td>\n",
       "      <td>charles h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100501002</td>\n",
       "      <td>allsheskey theodore f</td>\n",
       "      <td>allsheskey theodore f</td>\n",
       "      <td>allsheskey</td>\n",
       "      <td>theodore f</td>\n",
       "      <td>allsheskey</td>\n",
       "      <td>theodore f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100501003</td>\n",
       "      <td>bill charles w</td>\n",
       "      <td>bill c w</td>\n",
       "      <td>bill</td>\n",
       "      <td>charles w</td>\n",
       "      <td>bill</td>\n",
       "      <td>c w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100501004</td>\n",
       "      <td>bradley george a</td>\n",
       "      <td>bradley george a</td>\n",
       "      <td>bradley</td>\n",
       "      <td>george a</td>\n",
       "      <td>bradley</td>\n",
       "      <td>george a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100501005</td>\n",
       "      <td>bunitt william n</td>\n",
       "      <td>burritt william n</td>\n",
       "      <td>bunitt</td>\n",
       "      <td>william n</td>\n",
       "      <td>burritt</td>\n",
       "      <td>william n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    recidnum               recname1               recname2       last1  \\\n",
       "0  100501001        anson charles h        anson charles h       anson   \n",
       "1  100501002  allsheskey theodore f  allsheskey theodore f  allsheskey   \n",
       "2  100501003         bill charles w               bill c w        bill   \n",
       "3  100501004       bradley george a       bradley george a     bradley   \n",
       "4  100501005       bunitt william n      burritt william n      bunitt   \n",
       "\n",
       "       first1       last2      first2  \n",
       "0   charles h       anson   charles h  \n",
       "1  theodore f  allsheskey  theodore f  \n",
       "2   charles w        bill         c w  \n",
       "3    george a     bradley    george a  \n",
       "4   william n     burritt   william n  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union_matches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Embedding Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embed Letters: \n",
      " [11  1  9 12  9 14 27 12 21  0  0  0] kailin lu\n",
      "Embed Letters Normalized: \n",
      " [0.40740741 0.03703704 0.33333333 0.44444444 0.33333333 0.51851852\n",
      " 1.         0.44444444 0.77777778 0.         0.         0.        ] kailin lu\n",
      "Embed 2-Shingles: \n",
      " [261   8 219 295 221 364 688 306   0   0   0   0] kailin lu\n",
      "Embed 2-Shingles Normalized: \n",
      " [0.35753425 0.0109589  0.3        0.40410959 0.30273973 0.49863014\n",
      " 0.94246575 0.41917808 0.         0.         0.         0.        ] kailin lu\n"
     ]
    }
   ],
   "source": [
    "from recordlinker.preprocess import embed_letters, embed_shingles, disembed_letters, disembed_shingles\n",
    "\n",
    "name = 'kailin lu'\n",
    "max_length = 12 \n",
    "\n",
    "print('Embed Letters: \\n', \n",
    "      embed_letters(name, max_length), \n",
    "      disembed_letters(embed_letters(name, max_length))) \n",
    "\n",
    "print('Embed Letters Normalized: \\n', \n",
    "      embed_letters(name, max_length, normalize=True), \n",
    "      disembed_letters(embed_letters(name, max_length, normalize=True)))\n",
    "\n",
    "print('Embed 2-Shingles: \\n', \n",
    "      embed_shingles(name, max_length), \n",
    "      disembed_shingles(embed_shingles(name, max_length))) \n",
    "\n",
    "print('Embed 2-Shingles Normalized: \\n', \n",
    "      embed_shingles(name, max_length, normalize=True), \n",
    "      disembed_shingles(embed_shingles(name, max_length, normalize=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embed Letters: \n",
      " [11  1  9 12  9 14  0  0  0  0  0  0] kailin\n",
      "Embed Letters Normalized: \n",
      " [0.40740741 0.03703704 0.33333333 0.44444444 0.33333333 0.51851852\n",
      " 0.         0.         0.         0.         0.         0.        ] kailin\n",
      "Embed 2-Shingles: \n",
      " [261   8 219 295 221   0   0   0   0   0   0   0] kailin\n",
      "Embed 2-Shingles Normalized: \n",
      " [0.35753425 0.0109589  0.3        0.40410959 0.30273973 0.\n",
      " 0.         0.         0.         0.         0.         0.        ] kailin\n"
     ]
    }
   ],
   "source": [
    "name = 'kailin'\n",
    "max_length = 12\n",
    "\n",
    "print('Embed Letters: \\n', \n",
    "      embed_letters(name, max_length), \n",
    "      disembed_letters(embed_letters(name, max_length))) \n",
    "\n",
    "print('Embed Letters Normalized: \\n', \n",
    "      embed_letters(name, max_length, normalize=True), \n",
    "      disembed_letters(embed_letters(name, max_length, normalize=True)))\n",
    "\n",
    "print('Embed 2-Shingles: \\n', \n",
    "      embed_shingles(name, max_length), \n",
    "      disembed_shingles(embed_shingles(name, max_length))) \n",
    "\n",
    "print('Embed 2-Shingles Normalized: \\n', \n",
    "      embed_shingles(name, max_length, normalize=True), \n",
    "      disembed_shingles(embed_shingles(name, max_length, normalize=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and save autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_0 (Dense)                   (None, 256)          3328        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "enc_1 (Dense)                   (None, 128)          32896       enc_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 48)           6192        enc_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "log_sigma (Dense)               (None, 48)           6192        enc_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (32, 48)             0           mu[0][0]                         \n",
      "                                                                 log_sigma[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dec_0 (Dense)                   (32, 128)            6272        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec_1 (Dense)                   (32, 256)            33024       dec_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reconstruction (Dense)          (32, 12)             3084        dec_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 90,988\n",
      "Trainable params: 90,988\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Full Model: None\n",
      "Train on 3456 samples, validate on 864 samples\n",
      "Epoch 1/301\n",
      "3456/3456 [==============================] - 0s 134us/step - loss: 3.8048 - acc: 0.2925 - val_loss: 1.9613 - val_acc: 0.4931\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'thatcher', 'Pred:': 'jmingihecbba'}\n",
      "{'Orig': 'stone', 'Pred:': 'kqjjgbba    '}\n",
      "{'Orig': 'thompson', 'Pred:': 'nipimqlgdbab'}\n",
      "{'Orig': 'estess', 'Pred:': 'njqglmeba   '}\n",
      "{'Orig': 'coon', 'Pred:': 'gkjndcba    '}\n",
      "Epoch 2/301\n",
      "3456/3456 [==============================] - 0s 82us/step - loss: 1.4609 - acc: 0.5408 - val_loss: 1.2272 - val_acc: 0.6192\n",
      "Epoch 3/301\n",
      "3456/3456 [==============================] - 0s 81us/step - loss: 1.0314 - acc: 0.6658 - val_loss: 1.0256 - val_acc: 0.6597\n",
      "Epoch 4/301\n",
      "3456/3456 [==============================] - 0s 80us/step - loss: 0.8852 - acc: 0.6927 - val_loss: 0.9025 - val_acc: 0.6956\n",
      "Epoch 5/301\n",
      "3456/3456 [==============================] - 0s 84us/step - loss: 0.8095 - acc: 0.7049 - val_loss: 0.8573 - val_acc: 0.7049\n",
      "Epoch 6/301\n",
      "3456/3456 [==============================] - 0s 82us/step - loss: 0.7657 - acc: 0.7164 - val_loss: 0.8096 - val_acc: 0.7025\n",
      "Epoch 7/301\n",
      "3456/3456 [==============================] - 0s 81us/step - loss: 0.7418 - acc: 0.7164 - val_loss: 0.8132 - val_acc: 0.7002\n",
      "Epoch 8/301\n",
      "3456/3456 [==============================] - 0s 80us/step - loss: 0.7106 - acc: 0.7156 - val_loss: 0.7590 - val_acc: 0.7477\n",
      "Epoch 9/301\n",
      "3456/3456 [==============================] - 0s 80us/step - loss: 0.6871 - acc: 0.7381 - val_loss: 0.7502 - val_acc: 0.6817\n",
      "Epoch 10/301\n",
      "3456/3456 [==============================] - 0s 80us/step - loss: 0.6698 - acc: 0.7323 - val_loss: 0.7408 - val_acc: 0.6979\n",
      "Epoch 11/301\n",
      "3456/3456 [==============================] - 0s 79us/step - loss: 0.6532 - acc: 0.7416 - val_loss: 0.7164 - val_acc: 0.7477\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'tutt', 'Pred:': 'rtrrebaaaa  '}\n",
      "{'Orig': 'korsan', 'Pred:': 'jnrqdkbb a  '}\n",
      "{'Orig': 'siegel', 'Pred:': 'rifgghbb    '}\n",
      "{'Orig': 'nehas', 'Pred:': 'nfhdqbba    '}\n",
      "{'Orig': 'bogg', 'Pred:': 'cmggcbaa    '}\n",
      "Epoch 12/301\n",
      "3456/3456 [==============================] - 0s 77us/step - loss: 0.6485 - acc: 0.7297 - val_loss: 0.7106 - val_acc: 0.7384\n",
      "Epoch 13/301\n",
      "3456/3456 [==============================] - 0s 86us/step - loss: 0.6342 - acc: 0.7425 - val_loss: 0.6928 - val_acc: 0.7176\n",
      "Epoch 14/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.6260 - acc: 0.7425 - val_loss: 0.7039 - val_acc: 0.7419\n",
      "Epoch 15/301\n",
      "3456/3456 [==============================] - 0s 81us/step - loss: 0.6186 - acc: 0.7364 - val_loss: 0.6953 - val_acc: 0.7176\n",
      "Epoch 16/301\n",
      "3456/3456 [==============================] - 0s 79us/step - loss: 0.6101 - acc: 0.7396 - val_loss: 0.6782 - val_acc: 0.7002\n",
      "Epoch 17/301\n",
      "3456/3456 [==============================] - 0s 81us/step - loss: 0.6025 - acc: 0.7347 - val_loss: 0.6773 - val_acc: 0.7106\n",
      "Epoch 18/301\n",
      "3456/3456 [==============================] - 0s 77us/step - loss: 0.5986 - acc: 0.7350 - val_loss: 0.6645 - val_acc: 0.7338\n",
      "Epoch 19/301\n",
      "3456/3456 [==============================] - 0s 83us/step - loss: 0.5941 - acc: 0.7448 - val_loss: 0.6627 - val_acc: 0.7361\n",
      "Epoch 20/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.5850 - acc: 0.7338 - val_loss: 0.6643 - val_acc: 0.7176\n",
      "Epoch 21/301\n",
      "3456/3456 [==============================] - 0s 83us/step - loss: 0.5828 - acc: 0.7431 - val_loss: 0.6508 - val_acc: 0.7245\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'hutchinson', 'Pred:': 'irsijgntngba'}\n",
      "{'Orig': 'thompson', 'Pred:': 'sfplpsogcaa '}\n",
      "{'Orig': 'strasser', 'Pred:': 'rrsdprgjbaa '}\n",
      "{'Orig': 'liebal', 'Pred:': 'lhgdcjaa    '}\n",
      "{'Orig': 'harnseth', 'Pred:': 'gcsmshrcb   '}\n",
      "Epoch 22/301\n",
      "3456/3456 [==============================] - 0s 81us/step - loss: 0.5784 - acc: 0.7413 - val_loss: 0.6519 - val_acc: 0.7373\n",
      "Epoch 23/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.5738 - acc: 0.7402 - val_loss: 0.6428 - val_acc: 0.7292\n",
      "Epoch 24/301\n",
      "3456/3456 [==============================] - 0s 77us/step - loss: 0.5691 - acc: 0.7254 - val_loss: 0.6553 - val_acc: 0.7292\n",
      "Epoch 25/301\n",
      "3456/3456 [==============================] - 0s 82us/step - loss: 0.5669 - acc: 0.7416 - val_loss: 0.6470 - val_acc: 0.6944\n",
      "Epoch 26/301\n",
      "3456/3456 [==============================] - 0s 77us/step - loss: 0.5669 - acc: 0.7257 - val_loss: 0.6638 - val_acc: 0.6782\n",
      "Epoch 27/301\n",
      "3456/3456 [==============================] - 0s 79us/step - loss: 0.5615 - acc: 0.7309 - val_loss: 0.6188 - val_acc: 0.7245\n",
      "Epoch 28/301\n",
      "3456/3456 [==============================] - 0s 81us/step - loss: 0.5548 - acc: 0.7419 - val_loss: 0.6292 - val_acc: 0.7361\n",
      "Epoch 29/301\n",
      "3456/3456 [==============================] - 0s 77us/step - loss: 0.5577 - acc: 0.7234 - val_loss: 0.6428 - val_acc: 0.6944\n",
      "Epoch 30/301\n",
      "3456/3456 [==============================] - 0s 80us/step - loss: 0.5517 - acc: 0.7315 - val_loss: 0.6320 - val_acc: 0.7303\n",
      "Epoch 31/301\n",
      "3456/3456 [==============================] - 0s 77us/step - loss: 0.5440 - acc: 0.7512 - val_loss: 0.6120 - val_acc: 0.7431\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'lacy', 'Pred:': 'lefsdbb     '}\n",
      "{'Orig': 'edgley', 'Pred:': 'ffhkftba    '}\n",
      "{'Orig': 'engel', 'Pred:': 'foggiba     '}\n",
      "{'Orig': 'kenner', 'Pred:': 'kfnnepba    '}\n",
      "{'Orig': 'steiner', 'Pred:': 'sufjlhpaa   '}\n",
      "Epoch 32/301\n",
      "3456/3456 [==============================] - 0s 79us/step - loss: 0.5444 - acc: 0.7419 - val_loss: 0.6541 - val_acc: 0.6944\n",
      "Epoch 33/301\n",
      "3456/3456 [==============================] - 0s 80us/step - loss: 0.5448 - acc: 0.7326 - val_loss: 0.6079 - val_acc: 0.7361\n",
      "Epoch 34/301\n",
      "3456/3456 [==============================] - 0s 77us/step - loss: 0.5403 - acc: 0.7509 - val_loss: 0.6169 - val_acc: 0.6910\n",
      "Epoch 35/301\n",
      "3456/3456 [==============================] - 0s 77us/step - loss: 0.5390 - acc: 0.7329 - val_loss: 0.6252 - val_acc: 0.6481\n",
      "Epoch 36/301\n",
      "3456/3456 [==============================] - 0s 77us/step - loss: 0.5314 - acc: 0.7543 - val_loss: 0.6003 - val_acc: 0.7025\n",
      "Epoch 37/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.5356 - acc: 0.7422 - val_loss: 0.5998 - val_acc: 0.7407\n",
      "Epoch 38/301\n",
      "3456/3456 [==============================] - 0s 77us/step - loss: 0.5374 - acc: 0.7335 - val_loss: 0.6174 - val_acc: 0.6910\n",
      "Epoch 39/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.5330 - acc: 0.7361 - val_loss: 0.6105 - val_acc: 0.7130\n",
      "Epoch 40/301\n",
      "3456/3456 [==============================] - 0s 77us/step - loss: 0.5299 - acc: 0.7335 - val_loss: 0.6030 - val_acc: 0.7037\n",
      "Epoch 41/301\n",
      "3456/3456 [==============================] - 0s 79us/step - loss: 0.5289 - acc: 0.7393 - val_loss: 0.6218 - val_acc: 0.6933\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'snider', 'Pred:': 'soifdqbb    '}\n",
      "{'Orig': 'mayer', 'Pred:': 'lcxhlbaa    '}\n",
      "{'Orig': 'chalder', 'Pred:': 'eheldgoaa   '}\n",
      "{'Orig': 'stagg', 'Pred:': 'sudhdbaa    '}\n",
      "{'Orig': 'cox', 'Pred:': 'dnwdaaaa    '}\n",
      "Epoch 42/301\n",
      "3456/3456 [==============================] - 0s 85us/step - loss: 0.5267 - acc: 0.7428 - val_loss: 0.5966 - val_acc: 0.7326\n",
      "Epoch 43/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.5222 - acc: 0.7361 - val_loss: 0.5872 - val_acc: 0.7384\n",
      "Epoch 44/301\n",
      "3456/3456 [==============================] - 0s 76us/step - loss: 0.5197 - acc: 0.7514 - val_loss: 0.6025 - val_acc: 0.7002\n",
      "Epoch 45/301\n",
      "3456/3456 [==============================] - 0s 79us/step - loss: 0.5211 - acc: 0.7465 - val_loss: 0.5951 - val_acc: 0.6991\n",
      "Epoch 46/301\n",
      "3456/3456 [==============================] - 0s 77us/step - loss: 0.5193 - acc: 0.7459 - val_loss: 0.5813 - val_acc: 0.7627\n",
      "Epoch 47/301\n",
      "3456/3456 [==============================] - 0s 77us/step - loss: 0.5169 - acc: 0.7454 - val_loss: 0.5901 - val_acc: 0.6829\n",
      "Epoch 48/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.5176 - acc: 0.7347 - val_loss: 0.6074 - val_acc: 0.6690\n",
      "Epoch 49/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.5150 - acc: 0.7393 - val_loss: 0.6160 - val_acc: 0.6586\n",
      "Epoch 50/301\n",
      "3456/3456 [==============================] - 0s 77us/step - loss: 0.5158 - acc: 0.7373 - val_loss: 0.6048 - val_acc: 0.7072\n",
      "Epoch 51/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.5096 - acc: 0.7402 - val_loss: 0.5791 - val_acc: 0.7315\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'powers', 'Pred:': 'qougosaa    '}\n",
      "{'Orig': 'disher', 'Pred:': 'eirhfqaa    '}\n",
      "{'Orig': 'culver', 'Pred:': 'dultfraa    '}\n",
      "{'Orig': 'haegle', 'Pred:': 'hcegldaa    '}\n",
      "{'Orig': 'kipper', 'Pred:': 'kipoeraa    '}\n",
      "Epoch 52/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.5103 - acc: 0.7459 - val_loss: 0.5795 - val_acc: 0.7396\n",
      "Epoch 53/301\n",
      "3456/3456 [==============================] - 0s 77us/step - loss: 0.5098 - acc: 0.7428 - val_loss: 0.5928 - val_acc: 0.7431\n",
      "Epoch 54/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.5081 - acc: 0.7280 - val_loss: 0.5967 - val_acc: 0.7083\n",
      "Epoch 55/301\n",
      "3456/3456 [==============================] - 0s 81us/step - loss: 0.5085 - acc: 0.7407 - val_loss: 0.5721 - val_acc: 0.7442\n",
      "Epoch 56/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.5065 - acc: 0.7352 - val_loss: 0.5815 - val_acc: 0.7211\n",
      "Epoch 57/301\n",
      "3456/3456 [==============================] - 0s 79us/step - loss: 0.5063 - acc: 0.7323 - val_loss: 0.5961 - val_acc: 0.6470\n",
      "Epoch 58/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.5053 - acc: 0.7433 - val_loss: 0.5823 - val_acc: 0.7407\n",
      "Epoch 59/301\n",
      "3456/3456 [==============================] - 0s 77us/step - loss: 0.4976 - acc: 0.7532 - val_loss: 0.5726 - val_acc: 0.7014\n",
      "Epoch 60/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.4974 - acc: 0.7367 - val_loss: 0.5654 - val_acc: 0.7604\n",
      "Epoch 61/301\n",
      "3456/3456 [==============================] - 0s 77us/step - loss: 0.4982 - acc: 0.7503 - val_loss: 0.5747 - val_acc: 0.6609\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'langland', 'Pred:': 'lcoglclba   '}\n",
      "{'Orig': 'jansen', 'Pred:': 'jcprglba    '}\n",
      "{'Orig': 'harkema', 'Pred:': 'hbskfkba    '}\n",
      "{'Orig': 'mossengren', 'Pred:': 'lprshmgqllhb'}\n",
      "{'Orig': 'dostart', 'Pred:': 'dltsdqpa    '}\n",
      "Epoch 62/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.5010 - acc: 0.7266 - val_loss: 0.5715 - val_acc: 0.7361\n",
      "Epoch 63/301\n",
      "3456/3456 [==============================] - 0s 77us/step - loss: 0.4946 - acc: 0.7491 - val_loss: 0.5729 - val_acc: 0.6956\n",
      "Epoch 64/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.4961 - acc: 0.7396 - val_loss: 0.5831 - val_acc: 0.6562\n",
      "Epoch 65/301\n",
      "3456/3456 [==============================] - 0s 77us/step - loss: 0.4911 - acc: 0.7480 - val_loss: 0.5660 - val_acc: 0.7037\n",
      "Saved encoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/dense_letter_48_iowa_last/encoder.h5\n",
      "Saved decoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/dense_letter_48_iowa_last/decoder.h5\n"
     ]
    }
   ],
   "source": [
    "ORIG_LENGTH = 12\n",
    "BATCH_SIZE = 32\n",
    "ENCODE_DIM = [256, 128] \n",
    "DECODE_DIM = [128, 256]\n",
    "LR = 1e-4\n",
    "EPOCHS=301\n",
    "LATENT_DIM = [48]\n",
    "\n",
    "# Embed letters \n",
    "namesA = preprocess.embed(iowa_matches['lname1915'],\n",
    "                         max_length=ORIG_LENGTH, \n",
    "                         embed_type='letters', \n",
    "                         normalize=True)\n",
    "namesB = preprocess.embed(iowa_matches['lname1940'],\n",
    "                         max_length=ORIG_LENGTH, \n",
    "                         embed_type='letters', \n",
    "                         normalize=True)\n",
    "\n",
    "for latent_dim in LATENT_DIM: \n",
    "    save_path = '/Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/dense_letter_{}_iowa_last/'.format(latent_dim)\n",
    "    run_id = 'dense_{}'.format(latent_dim)\n",
    "    vae = recordlinker.model.VAE(batch_size=BATCH_SIZE,\n",
    "                                 orig_dim=ORIG_LENGTH, \n",
    "                                 latent_dim=latent_dim,\n",
    "                                 encode_dim=ENCODE_DIM,\n",
    "                                 decode_dim=DECODE_DIM,\n",
    "                                 lr=LR)\n",
    "\n",
    "    model, encoder, decoder = vae.train(namesA, namesB, \n",
    "                                        epochs=EPOCHS, \n",
    "                                        run_id=run_id,\n",
    "                                        save_path=save_path,\n",
    "                                        optimizer='adam', \n",
    "                                        tensorboard=True, \n",
    "                                        earlystop=True,\n",
    "                                        earlystop_patience=10,\n",
    "                                        reconstruct=True, \n",
    "                                        reconstruct_display=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_0 (Dense)                   (None, 128)          1664        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "enc_1 (Dense)                   (None, 128)          16512       enc_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 2)            258         enc_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "log_sigma (Dense)               (None, 2)            258         enc_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (32, 2)              0           mu[0][0]                         \n",
      "                                                                 log_sigma[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dec_0 (Dense)                   (32, 128)            384         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec_1 (Dense)                   (32, 128)            16512       dec_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reconstruction (Dense)          (32, 12)             1548        dec_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 37,136\n",
      "Trainable params: 37,136\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Full Model: None\n",
      "Train on 3456 samples, validate on 864 samples\n",
      "Epoch 1/301\n",
      "3456/3456 [==============================] - 0s 130us/step - loss: 3.7287 - acc: 0.3374 - val_loss: 1.9400 - val_acc: 0.3727\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'cunningham', 'Pred:': 'llolhgeddcdcu'}\n",
      "{'Orig': 'cassidy', 'Pred:': 'kkokfdbbbabax'}\n",
      "{'Orig': 'rose', 'Pred:': 'kjojedbaaaaap'}\n",
      "{'Orig': 'haas', 'Pred:': 'kkokfdbabaaau'}\n",
      "{'Orig': 'nissen', 'Pred:': 'kkokfebbbabay'}\n",
      "Epoch 2/301\n",
      "3456/3456 [==============================] - 0s 68us/step - loss: 1.6174 - acc: 0.3565 - val_loss: 1.4499 - val_acc: 0.3542\n",
      "Epoch 3/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 1.2844 - acc: 0.4517 - val_loss: 1.2147 - val_acc: 0.4919\n",
      "Epoch 4/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 1.1244 - acc: 0.5098 - val_loss: 1.1329 - val_acc: 0.5116\n",
      "Epoch 5/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 1.0698 - acc: 0.5231 - val_loss: 1.0891 - val_acc: 0.5231\n",
      "Epoch 6/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 1.0349 - acc: 0.5284 - val_loss: 1.0659 - val_acc: 0.5046\n",
      "Epoch 7/301\n",
      "3456/3456 [==============================] - 0s 76us/step - loss: 1.0180 - acc: 0.5269 - val_loss: 1.0541 - val_acc: 0.5174\n",
      "Epoch 8/301\n",
      "3456/3456 [==============================] - 0s 94us/step - loss: 1.0005 - acc: 0.5278 - val_loss: 1.0368 - val_acc: 0.5127\n",
      "Epoch 9/301\n",
      "3456/3456 [==============================] - 0s 98us/step - loss: 0.9934 - acc: 0.5301 - val_loss: 1.0318 - val_acc: 0.5069\n",
      "Epoch 10/301\n",
      "3456/3456 [==============================] - 0s 91us/step - loss: 0.9848 - acc: 0.5327 - val_loss: 1.0130 - val_acc: 0.5174\n",
      "Epoch 11/301\n",
      "3456/3456 [==============================] - 0s 96us/step - loss: 0.9793 - acc: 0.5278 - val_loss: 1.0234 - val_acc: 0.5185\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'isaacson', 'Pred:': 'jhtnkjfbbaaah'}\n",
      "{'Orig': 'longenecker', 'Pred:': 'kmmokgdbaaaag'}\n",
      "{'Orig': 'delong', 'Pred:': 'jjqlhdbaaaaad'}\n",
      "{'Orig': 'pray', 'Pred:': 'krefbaaaaaaab'}\n",
      "{'Orig': 'rath', 'Pred:': 'hftfbaaaaaaab'}\n",
      "Epoch 12/301\n",
      "3456/3456 [==============================] - 0s 82us/step - loss: 0.9731 - acc: 0.5301 - val_loss: 1.0224 - val_acc: 0.4988\n",
      "Epoch 13/301\n",
      "3456/3456 [==============================] - 0s 79us/step - loss: 0.9729 - acc: 0.5275 - val_loss: 1.0029 - val_acc: 0.5289\n",
      "Epoch 14/301\n",
      "3456/3456 [==============================] - 0s 95us/step - loss: 0.9635 - acc: 0.5373 - val_loss: 0.9958 - val_acc: 0.5266\n",
      "Epoch 15/301\n",
      "3456/3456 [==============================] - 0s 89us/step - loss: 0.9611 - acc: 0.5307 - val_loss: 0.9920 - val_acc: 0.5243\n",
      "Epoch 16/301\n",
      "3456/3456 [==============================] - 0s 79us/step - loss: 0.9543 - acc: 0.5341 - val_loss: 0.9955 - val_acc: 0.5000\n",
      "Epoch 17/301\n",
      "3456/3456 [==============================] - 0s 76us/step - loss: 0.9514 - acc: 0.5365 - val_loss: 0.9860 - val_acc: 0.5220\n",
      "Epoch 18/301\n",
      "3456/3456 [==============================] - 0s 81us/step - loss: 0.9482 - acc: 0.5344 - val_loss: 0.9939 - val_acc: 0.5023\n",
      "Epoch 19/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.9430 - acc: 0.5312 - val_loss: 0.9759 - val_acc: 0.5243\n",
      "Epoch 20/301\n",
      "3456/3456 [==============================] - 0s 82us/step - loss: 0.9398 - acc: 0.5347 - val_loss: 0.9740 - val_acc: 0.5278\n",
      "Epoch 21/301\n",
      "3456/3456 [==============================] - 0s 80us/step - loss: 0.9394 - acc: 0.5330 - val_loss: 0.9797 - val_acc: 0.5370\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'thompson', 'Pred:': 'klmomnjecaaai'}\n",
      "{'Orig': 'moore', 'Pred:': 'mrfkfbaaaaaac'}\n",
      "{'Orig': 'knoll', 'Pred:': 'lmkmhdbaaaaad'}\n",
      "{'Orig': 'hiher', 'Pred:': 'jmjebaaaaaaab'}\n",
      "{'Orig': 'decker', 'Pred:': 'knjhcaaaaaaab'}\n",
      "Epoch 22/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.9371 - acc: 0.5307 - val_loss: 0.9760 - val_acc: 0.5255\n",
      "Epoch 23/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.9323 - acc: 0.5353 - val_loss: 0.9665 - val_acc: 0.5324\n",
      "Epoch 24/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.9306 - acc: 0.5396 - val_loss: 0.9612 - val_acc: 0.5231\n",
      "Epoch 25/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.9260 - acc: 0.5373 - val_loss: 0.9563 - val_acc: 0.5347\n",
      "Epoch 26/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.9287 - acc: 0.5344 - val_loss: 0.9562 - val_acc: 0.5278\n",
      "Epoch 27/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.9217 - acc: 0.5341 - val_loss: 0.9565 - val_acc: 0.5312\n",
      "Epoch 28/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.9233 - acc: 0.5379 - val_loss: 0.9589 - val_acc: 0.5289\n",
      "Epoch 29/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.9198 - acc: 0.5359 - val_loss: 0.9545 - val_acc: 0.5301\n",
      "Epoch 30/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.9181 - acc: 0.5341 - val_loss: 0.9529 - val_acc: 0.5336\n",
      "Epoch 31/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.9148 - acc: 0.5344 - val_loss: 0.9474 - val_acc: 0.5174\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'sutton', 'Pred:': 'kjqnjebaaaaac'}\n",
      "{'Orig': 'turbett', 'Pred:': 'klnnmlgdbaaag'}\n",
      "{'Orig': 'neil', 'Pred:': 'iknebaaab'}\n",
      "{'Orig': 'jacobson', 'Pred:': 'kkonmnjecaaah'}\n",
      "{'Orig': 'mahony', 'Pred:': 'kjqnjebaaaaac'}\n",
      "Epoch 32/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.9147 - acc: 0.5356 - val_loss: 0.9446 - val_acc: 0.5289\n",
      "Epoch 33/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.9130 - acc: 0.5376 - val_loss: 0.9508 - val_acc: 0.5359\n",
      "Epoch 34/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.9125 - acc: 0.5310 - val_loss: 0.9447 - val_acc: 0.5370\n",
      "Epoch 35/301\n",
      "3456/3456 [==============================] - 0s 76us/step - loss: 0.9070 - acc: 0.5434 - val_loss: 0.9385 - val_acc: 0.5347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/301\n",
      "3456/3456 [==============================] - 0s 77us/step - loss: 0.9072 - acc: 0.5350 - val_loss: 0.9520 - val_acc: 0.5104\n",
      "Epoch 37/301\n",
      "3456/3456 [==============================] - 0s 79us/step - loss: 0.9046 - acc: 0.5370 - val_loss: 0.9483 - val_acc: 0.5324\n",
      "Epoch 38/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.9030 - acc: 0.5391 - val_loss: 0.9372 - val_acc: 0.5301\n",
      "Epoch 39/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.9029 - acc: 0.5321 - val_loss: 0.9335 - val_acc: 0.5266\n",
      "Epoch 40/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.8996 - acc: 0.5420 - val_loss: 0.9293 - val_acc: 0.5312\n",
      "Epoch 41/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.8962 - acc: 0.5417 - val_loss: 0.9304 - val_acc: 0.5324\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'ingebritson', 'Pred:': 'lqgmnsqnfcbaj'}\n",
      "{'Orig': 'platt', 'Pred:': 'nrgoicaaaaaab'}\n",
      "{'Orig': 'sproston', 'Pred:': 'kmkmmplgdbaag'}\n",
      "{'Orig': 'platt', 'Pred:': 'nrgoicaaaaaab'}\n",
      "{'Orig': 'hopkins', 'Pred:': 'kknmkidbaaaad'}\n",
      "Epoch 42/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.8949 - acc: 0.5367 - val_loss: 0.9465 - val_acc: 0.5382\n",
      "Epoch 43/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.8962 - acc: 0.5330 - val_loss: 0.9318 - val_acc: 0.5139\n",
      "Epoch 44/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.8990 - acc: 0.5365 - val_loss: 0.9362 - val_acc: 0.5255\n",
      "Epoch 45/301\n",
      "3456/3456 [==============================] - 0s 66us/step - loss: 0.8931 - acc: 0.5327 - val_loss: 0.9421 - val_acc: 0.5220\n",
      "Saved encoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/dense_shingle_2_union_first/encoder.h5\n",
      "Saved decoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/dense_shingle_2_union_first/decoder.h5\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_0 (Dense)                   (None, 128)          1664        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "enc_1 (Dense)                   (None, 128)          16512       enc_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 4)            516         enc_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "log_sigma (Dense)               (None, 4)            516         enc_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (32, 4)              0           mu[0][0]                         \n",
      "                                                                 log_sigma[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dec_0 (Dense)                   (32, 128)            640         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec_1 (Dense)                   (32, 128)            16512       dec_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reconstruction (Dense)          (32, 12)             1548        dec_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 37,908\n",
      "Trainable params: 37,908\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Full Model: None\n",
      "Train on 3456 samples, validate on 864 samples\n",
      "Epoch 1/301\n",
      "3456/3456 [==============================] - 0s 133us/step - loss: 3.6098 - acc: 0.3487 - val_loss: 1.9747 - val_acc: 0.3727\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'kothenbentel', 'Pred:': 'lmomkifeddddx'}\n",
      "{'Orig': 'jensen', 'Pred:': 'kkpkgebaaaaat'}\n",
      "{'Orig': 'newgard', 'Pred:': 'kkpkgebaaaaau'}\n",
      "{'Orig': 'reinilze', 'Pred:': 'lmomjifdddddq'}\n",
      "{'Orig': 'morris', 'Pred:': 'kkpjfdbaaaaam'}\n",
      "Epoch 2/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 1.5572 - acc: 0.4667 - val_loss: 1.3556 - val_acc: 0.4838\n",
      "Epoch 3/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 1.1964 - acc: 0.5605 - val_loss: 1.1437 - val_acc: 0.5590\n",
      "Epoch 4/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 1.0056 - acc: 0.6557 - val_loss: 1.0020 - val_acc: 0.6979\n",
      "Epoch 5/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.9014 - acc: 0.6837 - val_loss: 0.9437 - val_acc: 0.6829\n",
      "Epoch 6/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.8553 - acc: 0.6780 - val_loss: 0.9038 - val_acc: 0.6933\n",
      "Epoch 7/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.8261 - acc: 0.6811 - val_loss: 0.8776 - val_acc: 0.6609\n",
      "Epoch 8/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.8118 - acc: 0.6739 - val_loss: 0.8814 - val_acc: 0.6528\n",
      "Epoch 9/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.8004 - acc: 0.6832 - val_loss: 0.8548 - val_acc: 0.6898\n",
      "Epoch 10/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.7848 - acc: 0.6820 - val_loss: 0.8474 - val_acc: 0.6840\n",
      "Epoch 11/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.7754 - acc: 0.6820 - val_loss: 0.8396 - val_acc: 0.6678\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'jones', 'Pred:': 'jmoecbaaaaaac'}\n",
      "{'Orig': 'harnseth', 'Pred:': 'icrnlnicbaaai'}\n",
      "{'Orig': 'turner', 'Pred:': 'ltqmfbaaaaaad'}\n",
      "{'Orig': 'diedrich', 'Pred:': 'khhfijfcbaaag'}\n",
      "{'Orig': 'estess', 'Pred:': 'jrvhkjdbaaaai'}\n",
      "Epoch 12/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.7707 - acc: 0.6797 - val_loss: 0.8274 - val_acc: 0.6632\n",
      "Epoch 13/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.7629 - acc: 0.6808 - val_loss: 0.8257 - val_acc: 0.6910\n",
      "Epoch 14/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.7576 - acc: 0.6791 - val_loss: 0.8255 - val_acc: 0.6667\n",
      "Epoch 15/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.7522 - acc: 0.6753 - val_loss: 0.8216 - val_acc: 0.6088\n",
      "Epoch 16/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.7451 - acc: 0.6797 - val_loss: 0.8145 - val_acc: 0.6667\n",
      "Epoch 17/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.7425 - acc: 0.6675 - val_loss: 0.8066 - val_acc: 0.6667\n",
      "Epoch 18/301\n",
      "3456/3456 [==============================] - 0s 69us/step - loss: 0.7390 - acc: 0.6733 - val_loss: 0.8125 - val_acc: 0.6632\n",
      "Epoch 19/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.7344 - acc: 0.6846 - val_loss: 0.8022 - val_acc: 0.6528\n",
      "Epoch 20/301\n",
      "3456/3456 [==============================] - 0s 77us/step - loss: 0.7296 - acc: 0.6681 - val_loss: 0.8013 - val_acc: 0.6701\n",
      "Epoch 21/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.7249 - acc: 0.6756 - val_loss: 0.8000 - val_acc: 0.6505\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'cogan', 'Pred:': 'jniccbaaaaaac'}\n",
      "{'Orig': 'powers', 'Pred:': 'ksuihebaaaaae'}\n",
      "{'Orig': 'james', 'Pred:': 'idnecbaaaaaac'}\n",
      "{'Orig': 'danielsen', 'Pred:': 'hcogjmidbaaag'}\n",
      "{'Orig': 'lynn', 'Pred:': 'kxxdcaaaaaaac'}\n",
      "Epoch 22/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.7284 - acc: 0.6678 - val_loss: 0.7917 - val_acc: 0.6748\n",
      "Epoch 23/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.7220 - acc: 0.6762 - val_loss: 0.7843 - val_acc: 0.6736\n",
      "Epoch 24/301\n",
      "3456/3456 [==============================] - 0s 86us/step - loss: 0.7245 - acc: 0.6638 - val_loss: 0.7823 - val_acc: 0.6609\n",
      "Epoch 25/301\n",
      "3456/3456 [==============================] - 0s 83us/step - loss: 0.7173 - acc: 0.6701 - val_loss: 0.7877 - val_acc: 0.6852\n",
      "Epoch 26/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.7143 - acc: 0.6681 - val_loss: 0.8033 - val_acc: 0.6354\n",
      "Epoch 27/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.7111 - acc: 0.6713 - val_loss: 0.7903 - val_acc: 0.6829\n",
      "Epoch 28/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.7097 - acc: 0.6797 - val_loss: 0.7769 - val_acc: 0.6632\n",
      "Epoch 29/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.7093 - acc: 0.6719 - val_loss: 0.7778 - val_acc: 0.6678\n",
      "Epoch 30/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.7057 - acc: 0.6748 - val_loss: 0.7741 - val_acc: 0.6667\n",
      "Epoch 31/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.7035 - acc: 0.6722 - val_loss: 0.7854 - val_acc: 0.6620\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'sass', 'Pred:': 'gexdbaaaaaab'}\n",
      "{'Orig': 'goodrich', 'Pred:': 'lyneljbbaaaad'}\n",
      "{'Orig': 'dailey', 'Pred:': 'icjidbaaaaaab'}\n",
      "{'Orig': 'myers', 'Pred:': 'owfodaaaaaaab'}\n",
      "{'Orig': 'nicholas', 'Pred:': 'kleijhdbbaaad'}\n",
      "Epoch 32/301\n",
      "3456/3456 [==============================] - 0s 76us/step - loss: 0.7004 - acc: 0.6759 - val_loss: 0.7672 - val_acc: 0.6794\n",
      "Epoch 33/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.7024 - acc: 0.6615 - val_loss: 0.7698 - val_acc: 0.6400\n",
      "Epoch 34/301\n",
      "3456/3456 [==============================] - ETA: 0s - loss: 0.6988 - acc: 0.673 - 0s 73us/step - loss: 0.6985 - acc: 0.6739 - val_loss: 0.7589 - val_acc: 0.6586\n",
      "Epoch 35/301\n",
      "3456/3456 [==============================] - 0s 75us/step - loss: 0.6962 - acc: 0.6693 - val_loss: 0.7543 - val_acc: 0.6782\n",
      "Epoch 36/301\n",
      "3456/3456 [==============================] - 0s 80us/step - loss: 0.6908 - acc: 0.6797 - val_loss: 0.7642 - val_acc: 0.6481\n",
      "Epoch 37/301\n",
      "3456/3456 [==============================] - 0s 75us/step - loss: 0.6930 - acc: 0.6678 - val_loss: 0.7686 - val_acc: 0.6713\n",
      "Epoch 38/301\n",
      "3456/3456 [==============================] - 0s 82us/step - loss: 0.6918 - acc: 0.6664 - val_loss: 0.7629 - val_acc: 0.6470\n",
      "Epoch 39/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.6898 - acc: 0.6736 - val_loss: 0.7715 - val_acc: 0.6748\n",
      "Epoch 40/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.6889 - acc: 0.6730 - val_loss: 0.7474 - val_acc: 0.6713\n",
      "Epoch 41/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.6840 - acc: 0.6742 - val_loss: 0.7495 - val_acc: 0.6701\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'pomroy', 'Pred:': 'nqmtkdbaaaaac'}\n",
      "{'Orig': 'noelch', 'Pred:': 'mofkdaaaaaaab'}\n",
      "{'Orig': 'mayer', 'Pred:': 'hdxgcaaaaaaab'}\n",
      "{'Orig': 'lelonek', 'Pred:': 'kgmpifcaaaaac'}\n",
      "{'Orig': 'falk', 'Pred:': 'hdlcbbaaaaaab'}\n",
      "Epoch 42/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.6812 - acc: 0.6748 - val_loss: 0.7486 - val_acc: 0.6644\n",
      "Epoch 43/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.6824 - acc: 0.6719 - val_loss: 0.7418 - val_acc: 0.6725\n",
      "Epoch 44/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.6801 - acc: 0.6745 - val_loss: 0.7439 - val_acc: 0.6562\n",
      "Epoch 45/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.6779 - acc: 0.6765 - val_loss: 0.7429 - val_acc: 0.6782\n",
      "Epoch 46/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.6800 - acc: 0.6704 - val_loss: 0.7386 - val_acc: 0.6678\n",
      "Epoch 47/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.6762 - acc: 0.6710 - val_loss: 0.7433 - val_acc: 0.6562\n",
      "Epoch 48/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.6803 - acc: 0.6733 - val_loss: 0.7479 - val_acc: 0.6713\n",
      "Epoch 49/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.6728 - acc: 0.6832 - val_loss: 0.7431 - val_acc: 0.6655\n",
      "Epoch 50/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.6729 - acc: 0.6693 - val_loss: 0.7278 - val_acc: 0.6748\n",
      "Epoch 51/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.6724 - acc: 0.6722 - val_loss: 0.7313 - val_acc: 0.6759\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'speth', 'Pred:': 'opesdaaaaaaab'}\n",
      "{'Orig': 'taylor', 'Pred:': 'jfwpgdbaaaaac'}\n",
      "{'Orig': 'beattie', 'Pred:': 'mghukffbaaaad'}\n",
      "{'Orig': 'clayton', 'Pred:': 'mmgrnigcbaaad'}\n",
      "{'Orig': 'ploman', 'Pred:': 'lmnmcaaaaaab'}\n",
      "Epoch 52/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.6683 - acc: 0.6701 - val_loss: 0.7415 - val_acc: 0.6539\n",
      "Epoch 53/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.6662 - acc: 0.6756 - val_loss: 0.7326 - val_acc: 0.6748\n",
      "Epoch 54/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.6634 - acc: 0.6736 - val_loss: 0.7345 - val_acc: 0.6308\n",
      "Epoch 55/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.6628 - acc: 0.6756 - val_loss: 0.7379 - val_acc: 0.6562\n",
      "Saved encoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/dense_shingle_4_union_first/encoder.h5\n",
      "Saved decoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/dense_shingle_4_union_first/decoder.h5\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_0 (Dense)                   (None, 128)          1664        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "enc_1 (Dense)                   (None, 128)          16512       enc_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 8)            1032        enc_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "log_sigma (Dense)               (None, 8)            1032        enc_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (32, 8)              0           mu[0][0]                         \n",
      "                                                                 log_sigma[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dec_0 (Dense)                   (32, 128)            1152        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec_1 (Dense)                   (32, 128)            16512       dec_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reconstruction (Dense)          (32, 12)             1548        dec_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 39,452\n",
      "Trainable params: 39,452\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Full Model: None\n",
      "Train on 3456 samples, validate on 864 samples\n",
      "Epoch 1/301\n",
      "3456/3456 [==============================] - 0s 135us/step - loss: 3.6391 - acc: 0.3194 - val_loss: 1.9429 - val_acc: 0.3762\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'dierschinger', 'Pred:': 'mmnmkigfeeeev'}\n",
      "{'Orig': 'horrigan', 'Pred:': 'kjpjgecbaaaaz'}\n",
      "{'Orig': 'lang', 'Pred:': 'iiriecbaaaaak'}\n",
      "{'Orig': 'daniels', 'Pred:': 'kjqjgfcbbabbk'}\n",
      "{'Orig': 'stucker', 'Pred:': 'kkpkfecbaaaaw'}\n",
      "Epoch 2/301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3456/3456 [==============================] - 0s 73us/step - loss: 1.5221 - acc: 0.4997 - val_loss: 1.3354 - val_acc: 0.5000\n",
      "Epoch 3/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 1.1713 - acc: 0.5744 - val_loss: 1.1343 - val_acc: 0.5544\n",
      "Epoch 4/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 1.0099 - acc: 0.6036 - val_loss: 0.9633 - val_acc: 0.6736\n",
      "Epoch 5/301\n",
      "3456/3456 [==============================] - 0s 82us/step - loss: 0.8763 - acc: 0.6861 - val_loss: 0.9009 - val_acc: 0.6852\n",
      "Epoch 6/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.8321 - acc: 0.6881 - val_loss: 0.8770 - val_acc: 0.6725\n",
      "Epoch 7/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.8037 - acc: 0.6884 - val_loss: 0.8531 - val_acc: 0.6840\n",
      "Epoch 8/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.7795 - acc: 0.6861 - val_loss: 0.8348 - val_acc: 0.6933\n",
      "Epoch 9/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.7679 - acc: 0.6817 - val_loss: 0.8303 - val_acc: 0.6481\n",
      "Epoch 10/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.7589 - acc: 0.6849 - val_loss: 0.8244 - val_acc: 0.6771\n",
      "Epoch 11/301\n",
      "3456/3456 [==============================] - 0s 69us/step - loss: 0.7512 - acc: 0.6861 - val_loss: 0.8086 - val_acc: 0.6551\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'kothenbentel', 'Pred:': 'jntgjkfcbaaaj'}\n",
      "{'Orig': 'stoffers', 'Pred:': 'nsqwmedbbaaam'}\n",
      "{'Orig': 'mairet', 'Pred:': 'kdkqebaaaaaad'}\n",
      "{'Orig': 'glackemeyer', 'Pred:': 'kkffkngebaaak'}\n",
      "{'Orig': 'morr', 'Pred:': 'ioydcbaaaaaad'}\n",
      "Epoch 12/301\n",
      "3456/3456 [==============================] - 0s 75us/step - loss: 0.7426 - acc: 0.6843 - val_loss: 0.8096 - val_acc: 0.6667\n",
      "Epoch 13/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.7363 - acc: 0.6861 - val_loss: 0.8031 - val_acc: 0.6748\n",
      "Epoch 14/301\n",
      "3456/3456 [==============================] - 0s 75us/step - loss: 0.7296 - acc: 0.6806 - val_loss: 0.7964 - val_acc: 0.6562\n",
      "Epoch 15/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.7231 - acc: 0.6800 - val_loss: 0.7917 - val_acc: 0.6586\n",
      "Epoch 16/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.7171 - acc: 0.6863 - val_loss: 0.7846 - val_acc: 0.6829\n",
      "Epoch 17/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.7138 - acc: 0.6907 - val_loss: 0.7738 - val_acc: 0.6910\n",
      "Epoch 18/301\n",
      "3456/3456 [==============================] - 0s 77us/step - loss: 0.7128 - acc: 0.6832 - val_loss: 0.7822 - val_acc: 0.6944\n",
      "Epoch 19/301\n",
      "3456/3456 [==============================] - 0s 75us/step - loss: 0.7110 - acc: 0.6887 - val_loss: 0.7731 - val_acc: 0.6817\n",
      "Epoch 20/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.7049 - acc: 0.6823 - val_loss: 0.7689 - val_acc: 0.6701\n",
      "Epoch 21/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.7022 - acc: 0.6832 - val_loss: 0.7682 - val_acc: 0.6377\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'mulford', 'Pred:': 'lslgllgebaaah'}\n",
      "{'Orig': 'daniels', 'Pred:': 'hcqfgibaaaaad'}\n",
      "{'Orig': 'mayer', 'Pred:': 'hdxecbaaaaaab'}\n",
      "{'Orig': 'hughes', 'Pred:': 'ltifebaaaaaac'}\n",
      "{'Orig': 'inman', 'Pred:': 'jmnccbaaaaaab'}\n",
      "Epoch 22/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.6975 - acc: 0.6782 - val_loss: 0.7631 - val_acc: 0.6806\n",
      "Epoch 23/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.6960 - acc: 0.6826 - val_loss: 0.7584 - val_acc: 0.6840\n",
      "Epoch 24/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.6922 - acc: 0.6907 - val_loss: 0.7645 - val_acc: 0.6331\n",
      "Epoch 25/301\n",
      "3456/3456 [==============================] - 0s 79us/step - loss: 0.6913 - acc: 0.6843 - val_loss: 0.7514 - val_acc: 0.6620\n",
      "Epoch 26/301\n",
      "3456/3456 [==============================] - 0s 75us/step - loss: 0.6886 - acc: 0.6892 - val_loss: 0.7488 - val_acc: 0.6771\n",
      "Epoch 27/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.6871 - acc: 0.6858 - val_loss: 0.7459 - val_acc: 0.6956\n",
      "Epoch 28/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.6863 - acc: 0.6782 - val_loss: 0.7598 - val_acc: 0.6470\n",
      "Epoch 29/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.6816 - acc: 0.6884 - val_loss: 0.7752 - val_acc: 0.6597\n",
      "Epoch 30/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.6828 - acc: 0.6881 - val_loss: 0.7491 - val_acc: 0.6806\n",
      "Epoch 31/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.6836 - acc: 0.6832 - val_loss: 0.7558 - val_acc: 0.6285\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'moeller', 'Pred:': 'nohwmdcaaaaae'}\n",
      "{'Orig': 'lafler', 'Pred:': 'jdgjebaaaaaab'}\n",
      "{'Orig': 'nielsen', 'Pred:': 'kkfmlhcbaaaad'}\n",
      "{'Orig': 'harms', 'Pred:': 'hdtjcbaaaab'}\n",
      "{'Orig': 'rose', 'Pred:': 'iqscbaaaaab'}\n",
      "Epoch 32/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.6761 - acc: 0.6892 - val_loss: 0.7527 - val_acc: 0.6620\n",
      "Saved encoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/dense_shingle_8_union_first/encoder.h5\n",
      "Saved decoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/dense_shingle_8_union_first/decoder.h5\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_0 (Dense)                   (None, 128)          1664        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "enc_1 (Dense)                   (None, 128)          16512       enc_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 16)           2064        enc_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "log_sigma (Dense)               (None, 16)           2064        enc_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (32, 16)             0           mu[0][0]                         \n",
      "                                                                 log_sigma[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dec_0 (Dense)                   (32, 128)            2176        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec_1 (Dense)                   (32, 128)            16512       dec_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reconstruction (Dense)          (32, 12)             1548        dec_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 42,540\n",
      "Trainable params: 42,540\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Full Model: None\n",
      "Train on 3456 samples, validate on 864 samples\n",
      "Epoch 1/301\n",
      "3456/3456 [==============================] - 0s 129us/step - loss: 3.5484 - acc: 0.3857 - val_loss: 1.9697 - val_acc: 0.5289\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'long', 'Pred:': 'knniedbaaaaaf'}\n",
      "{'Orig': 'nabholz', 'Pred:': 'ljnmkjfcccccd'}\n",
      "{'Orig': 'haan', 'Pred:': 'luhigebaaaaah'}\n",
      "{'Orig': 'hickerson', 'Pred:': 'mllnmljggggfb'}\n",
      "{'Orig': 'pluckhahn', 'Pred:': 'kipkhgcbbaaav'}\n",
      "Epoch 2/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 1.4693 - acc: 0.6386 - val_loss: 1.2313 - val_acc: 0.6806\n",
      "Epoch 3/301\n",
      "3456/3456 [==============================] - 0s 75us/step - loss: 1.0512 - acc: 0.7251 - val_loss: 1.0347 - val_acc: 0.7106\n",
      "Epoch 4/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.8976 - acc: 0.7399 - val_loss: 0.9176 - val_acc: 0.7373\n",
      "Epoch 5/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.8125 - acc: 0.7546 - val_loss: 0.8648 - val_acc: 0.7037\n",
      "Epoch 6/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.7698 - acc: 0.7494 - val_loss: 0.8302 - val_acc: 0.7014\n",
      "Epoch 7/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.7311 - acc: 0.7523 - val_loss: 0.7816 - val_acc: 0.7153\n",
      "Epoch 8/301\n",
      "3456/3456 [==============================] - 0s 68us/step - loss: 0.7070 - acc: 0.7407 - val_loss: 0.7639 - val_acc: 0.7303\n",
      "Epoch 9/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.6898 - acc: 0.7399 - val_loss: 0.7586 - val_acc: 0.7025\n",
      "Epoch 10/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.6799 - acc: 0.7303 - val_loss: 0.7430 - val_acc: 0.7315\n",
      "Epoch 11/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.6673 - acc: 0.7384 - val_loss: 0.7310 - val_acc: 0.6991\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'gwan', 'Pred:': 'hueddbaaaaaac'}\n",
      "{'Orig': 'chandler', 'Pred:': 'dgeohkbaaaaad'}\n",
      "{'Orig': 'polk', 'Pred:': 'oomddaaaaaaac'}\n",
      "{'Orig': 'defley', 'Pred:': 'fehlecaaaaaab'}\n",
      "{'Orig': 'haupert', 'Pred:': 'dduoikdaaaaad'}\n",
      "Epoch 12/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.6562 - acc: 0.7390 - val_loss: 0.7279 - val_acc: 0.7269\n",
      "Epoch 13/301\n",
      "3456/3456 [==============================] - 0s 75us/step - loss: 0.6469 - acc: 0.7373 - val_loss: 0.7168 - val_acc: 0.6991\n",
      "Epoch 14/301\n",
      "3456/3456 [==============================] - 0s 76us/step - loss: 0.6373 - acc: 0.7376 - val_loss: 0.7130 - val_acc: 0.7141\n",
      "Epoch 15/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.6320 - acc: 0.7396 - val_loss: 0.7063 - val_acc: 0.6944\n",
      "Epoch 16/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.6270 - acc: 0.7347 - val_loss: 0.7043 - val_acc: 0.6794\n",
      "Epoch 17/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.6223 - acc: 0.7367 - val_loss: 0.6976 - val_acc: 0.6863\n",
      "Epoch 18/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.6225 - acc: 0.7419 - val_loss: 0.6939 - val_acc: 0.6956\n",
      "Epoch 19/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.6139 - acc: 0.7352 - val_loss: 0.6863 - val_acc: 0.7083\n",
      "Epoch 20/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.6084 - acc: 0.7378 - val_loss: 0.6939 - val_acc: 0.7164\n",
      "Epoch 21/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.6069 - acc: 0.7358 - val_loss: 0.7009 - val_acc: 0.7118\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'martin', 'Pred:': 'ndrsgabaaaaac'}\n",
      "{'Orig': 'speth', 'Pred:': 'rpfsdaaaaaaac'}\n",
      "{'Orig': 'novak', 'Pred:': 'motdcaaaaab'}\n",
      "{'Orig': 'markland', 'Pred:': 'ocsmmddaaaaad'}\n",
      "{'Orig': 'cumming', 'Pred:': 'duxkghbaaaaae'}\n",
      "Epoch 22/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.6015 - acc: 0.7378 - val_loss: 0.6672 - val_acc: 0.7257\n",
      "Epoch 23/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.5957 - acc: 0.7396 - val_loss: 0.6647 - val_acc: 0.7072\n",
      "Epoch 24/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.5978 - acc: 0.7297 - val_loss: 0.6669 - val_acc: 0.7095\n",
      "Epoch 25/301\n",
      "3456/3456 [==============================] - 0s 75us/step - loss: 0.5908 - acc: 0.7442 - val_loss: 0.6599 - val_acc: 0.7211\n",
      "Epoch 26/301\n",
      "3456/3456 [==============================] - 0s 75us/step - loss: 0.5861 - acc: 0.7381 - val_loss: 0.6576 - val_acc: 0.7083\n",
      "Epoch 27/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.5845 - acc: 0.7419 - val_loss: 0.6593 - val_acc: 0.6944\n",
      "Epoch 28/301\n",
      "3456/3456 [==============================] - 0s 75us/step - loss: 0.5902 - acc: 0.7297 - val_loss: 0.6465 - val_acc: 0.7292\n",
      "Epoch 29/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.5797 - acc: 0.7396 - val_loss: 0.6546 - val_acc: 0.7037\n",
      "Epoch 30/301\n",
      "3456/3456 [==============================] - 0s 75us/step - loss: 0.5773 - acc: 0.7462 - val_loss: 0.6456 - val_acc: 0.7014\n",
      "Epoch 31/301\n",
      "3456/3456 [==============================] - 0s 76us/step - loss: 0.5703 - acc: 0.7448 - val_loss: 0.6347 - val_acc: 0.7257\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'cundiff', 'Pred:': 'csnekucbaaaae'}\n",
      "{'Orig': 'nelson', 'Pred:': 'ofmqjcbaaaaac'}\n",
      "{'Orig': 'parkhouse', 'Pred:': 'mdsmnntkeaaag'}\n",
      "{'Orig': 'hinrichs', 'Pred:': 'igotifdaaaaad'}\n",
      "{'Orig': 'hagen', 'Pred:': 'hcgecaaaa'}\n",
      "Epoch 32/301\n",
      "3456/3456 [==============================] - 0s 75us/step - loss: 0.5714 - acc: 0.7428 - val_loss: 0.6515 - val_acc: 0.6435\n",
      "Epoch 33/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.5676 - acc: 0.7433 - val_loss: 0.6540 - val_acc: 0.6771\n",
      "Epoch 34/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.5658 - acc: 0.7474 - val_loss: 0.6379 - val_acc: 0.7315\n",
      "Epoch 35/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.5640 - acc: 0.7289 - val_loss: 0.6384 - val_acc: 0.7292\n",
      "Epoch 36/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.5618 - acc: 0.7422 - val_loss: 0.6351 - val_acc: 0.7014\n",
      "Saved encoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/dense_shingle_16_union_first/encoder.h5\n",
      "Saved decoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/dense_shingle_16_union_first/decoder.h5\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_0 (Dense)                   (None, 128)          1664        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "enc_1 (Dense)                   (None, 128)          16512       enc_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 24)           3096        enc_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "log_sigma (Dense)               (None, 24)           3096        enc_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (32, 24)             0           mu[0][0]                         \n",
      "                                                                 log_sigma[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dec_0 (Dense)                   (32, 128)            3200        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dec_1 (Dense)                   (32, 128)            16512       dec_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reconstruction (Dense)          (32, 12)             1548        dec_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 45,628\n",
      "Trainable params: 45,628\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Full Model: None\n",
      "Train on 3456 samples, validate on 864 samples\n",
      "Epoch 1/301\n",
      "3456/3456 [==============================] - 0s 140us/step - loss: 3.6035 - acc: 0.4256 - val_loss: 1.9848 - val_acc: 0.5255\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'koos', 'Pred:': 'mujecbaaaaaab'}\n",
      "{'Orig': 'swaigart', 'Pred:': 'nugigedbbaaat'}\n",
      "{'Orig': 'snyder', 'Pred:': 'kkrfdbaaaaaab'}\n",
      "{'Orig': 'isaacson', 'Pred:': 'khrgggcbaaaap'}\n",
      "{'Orig': 'manson', 'Pred:': 'jgsmigcbaaaal'}\n",
      "Epoch 2/301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3456/3456 [==============================] - 0s 81us/step - loss: 1.4628 - acc: 0.6568 - val_loss: 1.2591 - val_acc: 0.6852\n",
      "Epoch 3/301\n",
      "3456/3456 [==============================] - 0s 85us/step - loss: 1.0369 - acc: 0.7364 - val_loss: 0.9941 - val_acc: 0.7535\n",
      "Epoch 4/301\n",
      "3456/3456 [==============================] - 0s 83us/step - loss: 0.8569 - acc: 0.7786 - val_loss: 0.8856 - val_acc: 0.7477\n",
      "Epoch 5/301\n",
      "3456/3456 [==============================] - 0s 84us/step - loss: 0.7700 - acc: 0.7775 - val_loss: 0.8210 - val_acc: 0.7419\n",
      "Epoch 6/301\n",
      "3456/3456 [==============================] - 0s 88us/step - loss: 0.7146 - acc: 0.7847 - val_loss: 0.7732 - val_acc: 0.7326\n",
      "Epoch 7/301\n",
      "3456/3456 [==============================] - 0s 91us/step - loss: 0.6808 - acc: 0.7862 - val_loss: 0.7546 - val_acc: 0.7072\n",
      "Epoch 8/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.6592 - acc: 0.7665 - val_loss: 0.7567 - val_acc: 0.6829\n",
      "Epoch 9/301\n",
      "3456/3456 [==============================] - 0s 75us/step - loss: 0.6390 - acc: 0.7818 - val_loss: 0.7066 - val_acc: 0.7535\n",
      "Epoch 10/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.6205 - acc: 0.7821 - val_loss: 0.6836 - val_acc: 0.7616\n",
      "Epoch 11/301\n",
      "3456/3456 [==============================] - 0s 83us/step - loss: 0.6079 - acc: 0.7798 - val_loss: 0.6853 - val_acc: 0.7095\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'mcclain', 'Pred:': 'iwfhddbbaaaae'}\n",
      "{'Orig': 'menkel', 'Pred:': 'leohdbaaaaaab'}\n",
      "{'Orig': 'messink', 'Pred:': 'iezpkhcaaaaac'}\n",
      "{'Orig': 'muto', 'Pred:': 'lttcbbaaaaaab'}\n",
      "{'Orig': 'lund', 'Pred:': 'ktncbbaaaaaab'}\n",
      "Epoch 12/301\n",
      "3456/3456 [==============================] - 0s 83us/step - loss: 0.5978 - acc: 0.7841 - val_loss: 0.6710 - val_acc: 0.7465\n",
      "Epoch 13/301\n",
      "3456/3456 [==============================] - 0s 89us/step - loss: 0.5896 - acc: 0.7795 - val_loss: 0.6766 - val_acc: 0.7674\n",
      "Epoch 14/301\n",
      "3456/3456 [==============================] - 0s 80us/step - loss: 0.5796 - acc: 0.7824 - val_loss: 0.6573 - val_acc: 0.7662\n",
      "Epoch 15/301\n",
      "3456/3456 [==============================] - 0s 82us/step - loss: 0.5750 - acc: 0.7807 - val_loss: 0.6514 - val_acc: 0.7396\n",
      "Epoch 16/301\n",
      "3456/3456 [==============================] - 0s 75us/step - loss: 0.5697 - acc: 0.7839 - val_loss: 0.6397 - val_acc: 0.7280\n",
      "Epoch 17/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.5641 - acc: 0.7812 - val_loss: 0.6331 - val_acc: 0.7743\n",
      "Epoch 18/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.5601 - acc: 0.7810 - val_loss: 0.6266 - val_acc: 0.7731\n",
      "Epoch 19/301\n",
      "3456/3456 [==============================] - 0s 77us/step - loss: 0.5560 - acc: 0.7830 - val_loss: 0.6250 - val_acc: 0.7650\n",
      "Epoch 20/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.5500 - acc: 0.7789 - val_loss: 0.6281 - val_acc: 0.7604\n",
      "Epoch 21/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.5461 - acc: 0.7827 - val_loss: 0.6184 - val_acc: 0.7801\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'carter', 'Pred:': 'edrsecaaaaaab'}\n",
      "{'Orig': 'lynch', 'Pred:': 'lxlebaaaaaaac'}\n",
      "{'Orig': 'stutsman', 'Pred:': 'qtstthdbaaaaf'}\n",
      "{'Orig': 'lunde', 'Pred:': 'lulecaaaaaaac'}\n",
      "{'Orig': 'emery', 'Pred:': 'flfqcbaaaaaab'}\n",
      "Epoch 22/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.5451 - acc: 0.7772 - val_loss: 0.6185 - val_acc: 0.7905\n",
      "Epoch 23/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.5426 - acc: 0.7642 - val_loss: 0.6171 - val_acc: 0.7384\n",
      "Epoch 24/301\n",
      "3456/3456 [==============================] - 0s 85us/step - loss: 0.5324 - acc: 0.7891 - val_loss: 0.6266 - val_acc: 0.7593\n",
      "Epoch 25/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.5367 - acc: 0.7755 - val_loss: 0.6150 - val_acc: 0.7512\n",
      "Epoch 26/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.5329 - acc: 0.7807 - val_loss: 0.6079 - val_acc: 0.7569\n",
      "Epoch 27/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.5267 - acc: 0.7824 - val_loss: 0.6293 - val_acc: 0.6701\n",
      "Epoch 28/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.5285 - acc: 0.7720 - val_loss: 0.6075 - val_acc: 0.7731\n",
      "Epoch 29/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.5230 - acc: 0.7795 - val_loss: 0.6054 - val_acc: 0.7801\n",
      "Epoch 30/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.5243 - acc: 0.7818 - val_loss: 0.5979 - val_acc: 0.7222\n",
      "Epoch 31/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.5169 - acc: 0.7749 - val_loss: 0.6023 - val_acc: 0.7269\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'caviness', 'Pred:': 'hdvlgnldcaaae'}\n",
      "{'Orig': 'belding', 'Pred:': 'cekekmaaaaaac'}\n",
      "{'Orig': 'stepanek', 'Pred:': 'prenggiecbaag'}\n",
      "{'Orig': 'hunt', 'Pred:': 'hrnccbaaaaaab'}\n",
      "{'Orig': 'loving', 'Pred:': 'mmvhncaaaaaab'}\n",
      "Epoch 32/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.5180 - acc: 0.7749 - val_loss: 0.5925 - val_acc: 0.7766\n",
      "Epoch 33/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.5094 - acc: 0.7917 - val_loss: 0.5914 - val_acc: 0.7604\n",
      "Epoch 34/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.5117 - acc: 0.7853 - val_loss: 0.6099 - val_acc: 0.7384\n",
      "Epoch 35/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.5115 - acc: 0.7830 - val_loss: 0.5975 - val_acc: 0.7245\n",
      "Epoch 36/301\n",
      "3456/3456 [==============================] - 0s 75us/step - loss: 0.5091 - acc: 0.7691 - val_loss: 0.5854 - val_acc: 0.7674\n",
      "Epoch 37/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.5076 - acc: 0.7769 - val_loss: 0.5897 - val_acc: 0.7859\n",
      "Epoch 38/301\n",
      "3456/3456 [==============================] - 0s 76us/step - loss: 0.5030 - acc: 0.7862 - val_loss: 0.5792 - val_acc: 0.7535\n",
      "Epoch 39/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.5039 - acc: 0.7786 - val_loss: 0.5825 - val_acc: 0.7141\n",
      "Epoch 40/301\n",
      "3456/3456 [==============================] - 0s 69us/step - loss: 0.4960 - acc: 0.7844 - val_loss: 0.5893 - val_acc: 0.7512\n",
      "Epoch 41/301\n",
      "3456/3456 [==============================] - 0s 68us/step - loss: 0.5001 - acc: 0.7856 - val_loss: 0.5699 - val_acc: 0.7708\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'jensen', 'Pred:': 'ienrebaaaaa'}\n",
      "{'Orig': 'dougherty', 'Pred:': 'jpshckqheaaae'}\n",
      "{'Orig': 'mackey', 'Pred:': 'lceiebaaaaaab'}\n",
      "{'Orig': 'duff', 'Pred:': 'euycbaaaa'}\n",
      "{'Orig': 'lingard', 'Pred:': 'hhlfejebaaaac'}\n",
      "Epoch 42/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.4938 - acc: 0.7818 - val_loss: 0.5788 - val_acc: 0.7292\n",
      "Epoch 43/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.4996 - acc: 0.7891 - val_loss: 0.5748 - val_acc: 0.7488\n",
      "Epoch 44/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.4946 - acc: 0.7865 - val_loss: 0.5636 - val_acc: 0.7407\n",
      "Epoch 45/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.4908 - acc: 0.7836 - val_loss: 0.5667 - val_acc: 0.7627\n",
      "Epoch 46/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.4957 - acc: 0.7801 - val_loss: 0.5823 - val_acc: 0.7454\n",
      "Epoch 47/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.4854 - acc: 0.7905 - val_loss: 0.5626 - val_acc: 0.7847\n",
      "Epoch 48/301\n",
      "3456/3456 [==============================] - 0s 76us/step - loss: 0.4873 - acc: 0.7969 - val_loss: 0.5681 - val_acc: 0.7222\n",
      "Epoch 49/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.4872 - acc: 0.7841 - val_loss: 0.5803 - val_acc: 0.7512\n",
      "Epoch 50/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.4855 - acc: 0.7844 - val_loss: 0.5691 - val_acc: 0.7269\n",
      "Epoch 51/301\n",
      "3456/3456 [==============================] - 0s 76us/step - loss: 0.4893 - acc: 0.7792 - val_loss: 0.5615 - val_acc: 0.7627\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'boals', 'Pred:': 'dmdicbaaaaab'}\n",
      "{'Orig': 'clark', 'Pred:': 'dkdocbaaaaa'}\n",
      "{'Orig': 'meyer', 'Pred:': 'lfxdbaaaa'}\n",
      "{'Orig': 'rivers', 'Pred:': 'rhvdnbaaaaab'}\n",
      "{'Orig': 'dailey', 'Pred:': 'eciiebaaa'}\n",
      "Epoch 52/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.4793 - acc: 0.7972 - val_loss: 0.5657 - val_acc: 0.7280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/301\n",
      "3456/3456 [==============================] - 0s 74us/step - loss: 0.4803 - acc: 0.7839 - val_loss: 0.5683 - val_acc: 0.7072\n",
      "Epoch 54/301\n",
      "3456/3456 [==============================] - 0s 73us/step - loss: 0.4759 - acc: 0.7957 - val_loss: 0.5565 - val_acc: 0.7512\n",
      "Epoch 55/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.4854 - acc: 0.7847 - val_loss: 0.5765 - val_acc: 0.7083\n",
      "Epoch 56/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.4773 - acc: 0.7758 - val_loss: 0.5649 - val_acc: 0.7569\n",
      "Epoch 57/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.4762 - acc: 0.7867 - val_loss: 0.5489 - val_acc: 0.7546\n",
      "Epoch 58/301\n",
      "3456/3456 [==============================] - 0s 71us/step - loss: 0.4778 - acc: 0.7810 - val_loss: 0.5617 - val_acc: 0.7812\n",
      "Epoch 59/301\n",
      "3456/3456 [==============================] - 0s 70us/step - loss: 0.4732 - acc: 0.7882 - val_loss: 0.5500 - val_acc: 0.7593\n",
      "Epoch 60/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.4696 - acc: 0.7920 - val_loss: 0.5515 - val_acc: 0.7558\n",
      "Epoch 61/301\n",
      "3456/3456 [==============================] - 0s 72us/step - loss: 0.4723 - acc: 0.7815 - val_loss: 0.5704 - val_acc: 0.7037\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'murphy', 'Pred:': 'lrtngaaaaab'}\n",
      "{'Orig': 'menkel', 'Pred:': 'ldnidaaaa'}\n",
      "{'Orig': 'stubbs', 'Pred:': 'rruxdaaaaaab'}\n",
      "{'Orig': 'dodd', 'Pred:': 'djybbaaaa'}\n",
      "{'Orig': 'cunningham', 'Pred:': 'erzlhodbaaaac'}\n",
      "Epoch 62/301\n",
      "3456/3456 [==============================] - 0s 78us/step - loss: 0.4739 - acc: 0.7763 - val_loss: 0.5512 - val_acc: 0.7535\n",
      "Saved encoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/dense_shingle_24_union_first/encoder.h5\n",
      "Saved decoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/dense_shingle_24_union_first/decoder.h5\n"
     ]
    }
   ],
   "source": [
    "ORIG_LENGTH = 12\n",
    "BATCH_SIZE = 32\n",
    "ENCODE_DIM = [128, 128] \n",
    "DECODE_DIM = [128, 128]\n",
    "LR = 5e-4\n",
    "EPOCHS=301\n",
    "EMBED_TYPE = 'shingles'\n",
    "# Embed letters \n",
    "namesA = preprocess.embed(union_matches['first1'],\n",
    "                         max_length=ORIG_LENGTH, \n",
    "                         embed_type=EMBED_TYPE, \n",
    "                         normalize=True)\n",
    "namesB = preprocess.embed(union_matches['first2'],\n",
    "                         max_length=ORIG_LENGTH, \n",
    "                         embed_type=EMBED_TYPE, \n",
    "                         normalize=True)\n",
    "\n",
    "LATENT_DIM = [2,4,8,16,24]\n",
    "for latent_dim in LATENT_DIM: \n",
    "    save_path = '/Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/dense_shingle_{}_union_first/'.format(latent_dim)\n",
    "    run_id = 'dense_{}'.format(latent_dim)\n",
    "    vae = recordlinker.model.VAE(batch_size=BATCH_SIZE,\n",
    "                                 orig_dim=ORIG_LENGTH, \n",
    "                                 latent_dim=latent_dim,\n",
    "                                 encode_dim=ENCODE_DIM,\n",
    "                                 decode_dim=DECODE_DIM,\n",
    "                                 lr=LR)\n",
    "\n",
    "    model, encoder, decoder = vae.train(namesA, namesB, \n",
    "                                        epochs=EPOCHS, \n",
    "                                        run_id=run_id,\n",
    "                                        save_path=save_path,\n",
    "                                        optimizer='adam', \n",
    "                                        tensorboard=True, \n",
    "                                        earlystop=True,\n",
    "                                        earlystop_patience=15,\n",
    "                                        reconstruct=True, \n",
    "                                        reconstruct_type='s',\n",
    "                                        reconstruct_display=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 12, 28)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_0 (LSTM)                    (None, 12, 64)       23808       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "enc_1 (LSTM)                    (None, 12, 64)       33024       enc_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 768)          0           enc_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 96)           73824       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "log_sigma (Dense)               (None, 96)           73824       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 96)           0           mu[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 96)           0           log_sigma[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z (Lambda)                      (32, 96)             0           leaky_re_lu_1[0][0]              \n",
      "                                                                 leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (32, 12, 96)         0           z[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "dec_0 (LSTM)                    (32, 12, 64)         41216       repeat_vector_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dec_1 (LSTM)                    (32, 12, 64)         33024       dec_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (32, 12, 28)         1820        dec_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 280,540\n",
      "Trainable params: 280,540\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 3456 samples, validate on 864 samples\n",
      "Epoch 1/350\n",
      "3456/3456 [==============================] - 5s 1ms/step - loss: 24.2436 - acc: 0.4820 - val_loss: 20.0538 - val_acc: 0.5232\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'jackson', 'Pred:': 'eeeeee'}\n",
      "{'Orig': 'may', 'Pred:': 'eee'}\n",
      "{'Orig': 'luce', 'Pred:': 'eeee'}\n",
      "{'Orig': 'taylor', 'Pred:': 'eeeee'}\n",
      "{'Orig': 'ebert', 'Pred:': 'eeee'}\n",
      "Epoch 2/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 19.6807 - acc: 0.5267 - val_loss: 19.2722 - val_acc: 0.5347\n",
      "Epoch 3/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 18.9367 - acc: 0.5395 - val_loss: 18.5531 - val_acc: 0.5508\n",
      "Epoch 4/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 18.2459 - acc: 0.5529 - val_loss: 18.0377 - val_acc: 0.5586\n",
      "Epoch 5/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 17.5950 - acc: 0.5677 - val_loss: 17.2962 - val_acc: 0.5737\n",
      "Epoch 6/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 16.7547 - acc: 0.5863 - val_loss: 16.5316 - val_acc: 0.5935\n",
      "Epoch 7/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 15.9830 - acc: 0.6078 - val_loss: 15.7372 - val_acc: 0.6156\n",
      "Epoch 8/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 15.2924 - acc: 0.6260 - val_loss: 15.0995 - val_acc: 0.6354\n",
      "Epoch 9/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 14.7251 - acc: 0.6407 - val_loss: 14.8737 - val_acc: 0.6403\n",
      "Epoch 10/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 14.0793 - acc: 0.6554 - val_loss: 14.1141 - val_acc: 0.6624\n",
      "Epoch 11/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 13.5387 - acc: 0.6671 - val_loss: 13.5196 - val_acc: 0.6683\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'umstead', 'Pred:': 'meeeaaa'}\n",
      "{'Orig': 'struve', 'Pred:': 'mertee'}\n",
      "{'Orig': 'cass', 'Pred:': 'mass'}\n",
      "{'Orig': 'geerdes', 'Pred:': 'eeeiee'}\n",
      "{'Orig': 'lewis', 'Pred:': 'meiss'}\n",
      "Epoch 12/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 12.8876 - acc: 0.6825 - val_loss: 13.2576 - val_acc: 0.6720\n",
      "Epoch 13/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 12.5379 - acc: 0.6888 - val_loss: 12.8039 - val_acc: 0.6823\n",
      "Epoch 14/350\n",
      "3456/3456 [==============================] - 5s 1ms/step - loss: 11.9594 - acc: 0.7045 - val_loss: 12.1952 - val_acc: 0.7033\n",
      "Epoch 15/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 11.3998 - acc: 0.7188 - val_loss: 11.7940 - val_acc: 0.7179\n",
      "Epoch 16/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 11.0638 - acc: 0.7282 - val_loss: 11.4846 - val_acc: 0.7269\n",
      "Epoch 17/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 10.6126 - acc: 0.7378 - val_loss: 11.0358 - val_acc: 0.7343\n",
      "Epoch 18/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 10.1023 - acc: 0.7524 - val_loss: 10.7614 - val_acc: 0.7422\n",
      "Epoch 19/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 9.7159 - acc: 0.7642 - val_loss: 10.3006 - val_acc: 0.7590\n",
      "Epoch 20/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 9.2210 - acc: 0.7783 - val_loss: 9.8509 - val_acc: 0.7754\n",
      "Epoch 21/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 8.8326 - acc: 0.7906 - val_loss: 9.8019 - val_acc: 0.7771\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'daniels', 'Pred:': 'danills'}\n",
      "{'Orig': 'feay', 'Pred:': 'deady'}\n",
      "{'Orig': 'stalmaster', 'Pred:': 'storaaaeer'}\n",
      "{'Orig': 'duin', 'Pred:': 'dein'}\n",
      "{'Orig': 'evans', 'Pred:': 'denns'}\n",
      "Epoch 22/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 8.4174 - acc: 0.8039 - val_loss: 9.2405 - val_acc: 0.7957\n",
      "Epoch 23/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 7.9276 - acc: 0.8186 - val_loss: 8.8404 - val_acc: 0.8062\n",
      "Epoch 24/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 7.5496 - acc: 0.8268 - val_loss: 8.5619 - val_acc: 0.8193\n",
      "Epoch 25/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 7.2355 - acc: 0.8367 - val_loss: 8.4300 - val_acc: 0.8237\n",
      "Epoch 26/350\n",
      "3456/3456 [==============================] - 5s 1ms/step - loss: 6.9584 - acc: 0.8440 - val_loss: 8.0953 - val_acc: 0.8250\n",
      "Epoch 27/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 6.5395 - acc: 0.8548 - val_loss: 7.8804 - val_acc: 0.8364\n",
      "Epoch 28/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 6.3761 - acc: 0.8595 - val_loss: 7.8573 - val_acc: 0.8359\n",
      "Epoch 29/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 6.0521 - acc: 0.8692 - val_loss: 7.6097 - val_acc: 0.8416\n",
      "Epoch 30/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 5.8215 - acc: 0.8746 - val_loss: 7.3251 - val_acc: 0.8510\n",
      "Epoch 31/350\n",
      "3456/3456 [==============================] - 5s 1ms/step - loss: 5.5744 - acc: 0.8804 - val_loss: 7.3607 - val_acc: 0.8497\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'barnes', 'Pred:': 'barnes'}\n",
      "{'Orig': 'kern', 'Pred:': 'keen'}\n",
      "{'Orig': 'best', 'Pred:': 'bett'}\n",
      "{'Orig': 'newcomb', 'Pred:': 'de comb'}\n",
      "{'Orig': 'munger', 'Pred:': 'munger'}\n",
      "Epoch 32/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3456/3456 [==============================] - 4s 1ms/step - loss: 5.4424 - acc: 0.8838 - val_loss: 7.0742 - val_acc: 0.8596\n",
      "Epoch 33/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 5.1268 - acc: 0.8939 - val_loss: 6.9184 - val_acc: 0.8648\n",
      "Epoch 34/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 4.9191 - acc: 0.8984 - val_loss: 6.9062 - val_acc: 0.8642\n",
      "Epoch 35/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 4.7587 - acc: 0.9020 - val_loss: 6.7798 - val_acc: 0.8649\n",
      "Epoch 36/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 4.6679 - acc: 0.9049 - val_loss: 6.7456 - val_acc: 0.8683\n",
      "Epoch 37/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 4.5286 - acc: 0.9061 - val_loss: 6.6342 - val_acc: 0.8745\n",
      "Epoch 38/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 4.2478 - acc: 0.9147 - val_loss: 6.9449 - val_acc: 0.8628\n",
      "Epoch 39/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 4.3267 - acc: 0.9113 - val_loss: 6.5111 - val_acc: 0.8777\n",
      "Epoch 40/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 4.0240 - acc: 0.9205 - val_loss: 6.5201 - val_acc: 0.8778\n",
      "Epoch 41/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 3.9346 - acc: 0.9217 - val_loss: 6.4365 - val_acc: 0.8799\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'rix', 'Pred:': 'rix'}\n",
      "{'Orig': 'malik', 'Pred:': 'malik'}\n",
      "{'Orig': 'underwood', 'Pred:': 'unneroood'}\n",
      "{'Orig': 'eickhoff', 'Pred:': 'eickhoff'}\n",
      "{'Orig': 'dunning', 'Pred:': 'dunning'}\n",
      "Epoch 42/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 3.8984 - acc: 0.9230 - val_loss: 6.4521 - val_acc: 0.8771\n",
      "Epoch 43/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 3.7720 - acc: 0.9255 - val_loss: 6.3812 - val_acc: 0.8811\n",
      "Epoch 44/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 3.6253 - acc: 0.9289 - val_loss: 6.3347 - val_acc: 0.8800\n",
      "Epoch 45/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 3.4568 - acc: 0.9338 - val_loss: 6.3476 - val_acc: 0.8825\n",
      "Epoch 46/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 3.3737 - acc: 0.9354 - val_loss: 6.2985 - val_acc: 0.8873\n",
      "Epoch 47/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 3.2954 - acc: 0.9365 - val_loss: 6.1952 - val_acc: 0.8870\n",
      "Epoch 48/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 3.2197 - acc: 0.9389 - val_loss: 6.3123 - val_acc: 0.8863\n",
      "Epoch 49/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 3.1089 - acc: 0.9414 - val_loss: 6.2340 - val_acc: 0.8873\n",
      "Epoch 50/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 3.0617 - acc: 0.9416 - val_loss: 6.0579 - val_acc: 0.8923\n",
      "Epoch 51/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 2.9498 - acc: 0.9439 - val_loss: 6.4122 - val_acc: 0.8875\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'lutes', 'Pred:': 'lutes'}\n",
      "{'Orig': 'bell', 'Pred:': 'bell'}\n",
      "{'Orig': 'dege', 'Pred:': 'dege'}\n",
      "{'Orig': 'muhlbauer', 'Pred:': 'muhlbuaer'}\n",
      "{'Orig': 'fitzgerald', 'Pred:': 'fitzzfral'}\n",
      "Epoch 52/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 3.0082 - acc: 0.9415 - val_loss: 6.1936 - val_acc: 0.8882\n",
      "Epoch 53/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 2.9189 - acc: 0.9438 - val_loss: 6.1795 - val_acc: 0.8899\n",
      "Epoch 54/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 2.7138 - acc: 0.9494 - val_loss: 6.1539 - val_acc: 0.8887\n",
      "Epoch 55/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 2.7229 - acc: 0.9484 - val_loss: 6.4106 - val_acc: 0.8886\n",
      "Saved encoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/lstm_letter_96_iowa_last/encoder.h5\n",
      "Saved decoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/lstm_letter_96_iowa_last/decoder.h5\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 12, 28)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_0 (LSTM)                    (None, 12, 64)       23808       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "enc_1 (LSTM)                    (None, 12, 64)       33024       enc_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 768)          0           enc_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 192)          147648      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "log_sigma (Dense)               (None, 192)          147648      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 192)          0           mu[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 192)          0           log_sigma[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z (Lambda)                      (32, 192)            0           leaky_re_lu_1[0][0]              \n",
      "                                                                 leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (32, 12, 192)        0           z[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "dec_0 (LSTM)                    (32, 12, 64)         65792       repeat_vector_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dec_1 (LSTM)                    (32, 12, 64)         33024       dec_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (32, 12, 28)         1820        dec_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 452,764\n",
      "Trainable params: 452,764\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 3456 samples, validate on 864 samples\n",
      "Epoch 1/350\n",
      "3456/3456 [==============================] - 5s 2ms/step - loss: 24.2920 - acc: 0.4879 - val_loss: 20.0641 - val_acc: 0.5217\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'stepanek', 'Pred:': 'eeeeeeee'}\n",
      "{'Orig': 'koile', 'Pred:': 'eeee'}\n",
      "{'Orig': 'mcdowell', 'Pred:': 'eeeeeeee'}\n",
      "{'Orig': 'clemens', 'Pred:': 'eeeeeee'}\n",
      "{'Orig': 'falk', 'Pred:': 'eee'}\n",
      "Epoch 2/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 19.3965 - acc: 0.5325 - val_loss: 18.8283 - val_acc: 0.5426\n",
      "Epoch 3/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 18.3067 - acc: 0.5527 - val_loss: 18.1059 - val_acc: 0.5590\n",
      "Epoch 4/350\n",
      "3456/3456 [==============================] - 5s 1ms/step - loss: 17.4982 - acc: 0.5695 - val_loss: 17.1478 - val_acc: 0.5827\n",
      "Epoch 5/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 16.7742 - acc: 0.5861 - val_loss: 16.5492 - val_acc: 0.5969\n",
      "Epoch 6/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 16.1297 - acc: 0.5986 - val_loss: 16.2369 - val_acc: 0.5917\n",
      "Epoch 7/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3456/3456 [==============================] - 4s 1ms/step - loss: 15.3422 - acc: 0.6206 - val_loss: 15.0229 - val_acc: 0.6315\n",
      "Epoch 8/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 14.4439 - acc: 0.6422 - val_loss: 14.1916 - val_acc: 0.6592\n",
      "Epoch 9/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 13.6969 - acc: 0.6623 - val_loss: 13.4984 - val_acc: 0.6715\n",
      "Epoch 10/350\n",
      "3456/3456 [==============================] - 5s 1ms/step - loss: 12.9873 - acc: 0.6772 - val_loss: 12.9910 - val_acc: 0.6799\n",
      "Epoch 11/350\n",
      "3456/3456 [==============================] - 5s 2ms/step - loss: 12.3171 - acc: 0.6943 - val_loss: 12.3037 - val_acc: 0.6942\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'fuller', 'Pred:': 'mlller'}\n",
      "{'Orig': 'koepke', 'Pred:': 'moppee'}\n",
      "{'Orig': 'hill', 'Pred:': 'llll'}\n",
      "{'Orig': 'innes', 'Pred:': 'innes'}\n",
      "{'Orig': 'koenig', 'Pred:': 'munnng'}\n",
      "Epoch 12/350\n",
      "3456/3456 [==============================] - 5s 1ms/step - loss: 11.5995 - acc: 0.7119 - val_loss: 11.7810 - val_acc: 0.7057\n",
      "Epoch 13/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 11.0339 - acc: 0.7270 - val_loss: 11.2347 - val_acc: 0.7231\n",
      "Epoch 14/350\n",
      "3456/3456 [==============================] - 3s 977us/step - loss: 10.3893 - acc: 0.7445 - val_loss: 10.8129 - val_acc: 0.7364\n",
      "Epoch 15/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 9.8408 - acc: 0.7605 - val_loss: 10.4090 - val_acc: 0.7502\n",
      "Epoch 16/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 9.2335 - acc: 0.7803 - val_loss: 9.6895 - val_acc: 0.7719\n",
      "Epoch 17/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 8.6945 - acc: 0.7927 - val_loss: 9.5257 - val_acc: 0.7707\n",
      "Epoch 18/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 8.3347 - acc: 0.8016 - val_loss: 9.1979 - val_acc: 0.7894\n",
      "Epoch 19/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 8.0091 - acc: 0.8096 - val_loss: 8.7697 - val_acc: 0.8029\n",
      "Epoch 20/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 7.6550 - acc: 0.8224 - val_loss: 8.5534 - val_acc: 0.8067\n",
      "Epoch 21/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 7.1647 - acc: 0.8383 - val_loss: 8.2387 - val_acc: 0.8191\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'lohman', 'Pred:': 'lohman'}\n",
      "{'Orig': 'mcclemrock', 'Pred:': 'mcceeraccc'}\n",
      "{'Orig': 'darby', 'Pred:': 'darby'}\n",
      "{'Orig': 'kloppenberg', 'Pred:': 'ccopeebbbee'}\n",
      "{'Orig': 'eckstein', 'Pred:': 'kecseenn'}\n",
      "Epoch 22/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 6.8101 - acc: 0.8482 - val_loss: 8.1441 - val_acc: 0.8181\n",
      "Epoch 23/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 6.4848 - acc: 0.8560 - val_loss: 7.6522 - val_acc: 0.8320\n",
      "Epoch 24/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 6.1803 - acc: 0.8651 - val_loss: 7.6015 - val_acc: 0.8340\n",
      "Epoch 25/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 5.9512 - acc: 0.8713 - val_loss: 7.6514 - val_acc: 0.8348\n",
      "Epoch 26/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 5.7248 - acc: 0.8783 - val_loss: 7.3573 - val_acc: 0.8436\n",
      "Epoch 27/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 5.5387 - acc: 0.8832 - val_loss: 7.1991 - val_acc: 0.8486\n",
      "Epoch 28/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 5.2715 - acc: 0.8897 - val_loss: 7.0027 - val_acc: 0.8570\n",
      "Epoch 29/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 5.0698 - acc: 0.8949 - val_loss: 6.8696 - val_acc: 0.8602\n",
      "Epoch 30/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 4.9552 - acc: 0.8970 - val_loss: 6.9458 - val_acc: 0.8578\n",
      "Epoch 31/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 4.7373 - acc: 0.9044 - val_loss: 6.5866 - val_acc: 0.8716\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'manship', 'Pred:': 'manshan'}\n",
      "{'Orig': 'denham', 'Pred:': 'denham'}\n",
      "{'Orig': 'boatwright', 'Pred:': 'borrrrict'}\n",
      "{'Orig': 'olson', 'Pred:': 'olson'}\n",
      "{'Orig': 'kunkel', 'Pred:': 'kunkel'}\n",
      "Epoch 32/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 4.5806 - acc: 0.9058 - val_loss: 6.6079 - val_acc: 0.8691\n",
      "Epoch 33/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 4.4583 - acc: 0.9082 - val_loss: 6.5345 - val_acc: 0.8727\n",
      "Epoch 34/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 4.1841 - acc: 0.9171 - val_loss: 6.4519 - val_acc: 0.8744\n",
      "Epoch 35/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 4.0497 - acc: 0.9200 - val_loss: 6.9434 - val_acc: 0.8612\n",
      "Epoch 36/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 3.9614 - acc: 0.9233 - val_loss: 6.4548 - val_acc: 0.8783\n",
      "Epoch 37/350\n",
      "3456/3456 [==============================] - 5s 1ms/step - loss: 3.8343 - acc: 0.9239 - val_loss: 6.2581 - val_acc: 0.8815\n",
      "Epoch 38/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 3.8117 - acc: 0.9261 - val_loss: 6.2540 - val_acc: 0.8845\n",
      "Epoch 39/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 3.6047 - acc: 0.9309 - val_loss: 6.5000 - val_acc: 0.8744\n",
      "Epoch 40/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 3.6306 - acc: 0.9301 - val_loss: 6.1674 - val_acc: 0.8862\n",
      "Epoch 41/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 3.4141 - acc: 0.9357 - val_loss: 6.0473 - val_acc: 0.8928\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'doane', 'Pred:': 'doane'}\n",
      "{'Orig': 'spantz', 'Pred:': 'spautz'}\n",
      "{'Orig': 'kruse', 'Pred:': 'kruse'}\n",
      "{'Orig': 'elliott', 'Pred:': 'elliott'}\n",
      "{'Orig': 'delaney', 'Pred:': 'delaney'}\n",
      "Epoch 42/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 3.2936 - acc: 0.9380 - val_loss: 6.1932 - val_acc: 0.8883\n",
      "Epoch 43/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 3.3094 - acc: 0.9365 - val_loss: 6.2786 - val_acc: 0.8820\n",
      "Epoch 44/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 3.2369 - acc: 0.9386 - val_loss: 6.0801 - val_acc: 0.8921\n",
      "Epoch 45/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 3.1651 - acc: 0.9393 - val_loss: 5.9522 - val_acc: 0.8942\n",
      "Epoch 46/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 2.9691 - acc: 0.9455 - val_loss: 6.0776 - val_acc: 0.8937\n",
      "Epoch 47/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 3.0522 - acc: 0.9413 - val_loss: 6.2760 - val_acc: 0.8837\n",
      "Epoch 48/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 2.9936 - acc: 0.9428 - val_loss: 6.2057 - val_acc: 0.8899\n",
      "Epoch 49/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 2.8145 - acc: 0.9488 - val_loss: 6.0463 - val_acc: 0.8913\n",
      "Epoch 50/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 2.7459 - acc: 0.9488 - val_loss: 6.1256 - val_acc: 0.8907\n",
      "Saved encoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/lstm_letter_192_iowa_last/encoder.h5\n",
      "Saved decoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/lstm_letter_192_iowa_last/decoder.h5\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 12, 28)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_0 (LSTM)                    (None, 12, 64)       23808       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "enc_1 (LSTM)                    (None, 12, 64)       33024       enc_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 768)          0           enc_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 384)          295296      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "log_sigma (Dense)               (None, 384)          295296      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 384)          0           mu[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 384)          0           log_sigma[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z (Lambda)                      (32, 384)            0           leaky_re_lu_1[0][0]              \n",
      "                                                                 leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (32, 12, 384)        0           z[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "dec_0 (LSTM)                    (32, 12, 64)         114944      repeat_vector_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dec_1 (LSTM)                    (32, 12, 64)         33024       dec_0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (32, 12, 28)         1820        dec_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 797,212\n",
      "Trainable params: 797,212\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3456 samples, validate on 864 samples\n",
      "Epoch 1/350\n",
      "3456/3456 [==============================] - 6s 2ms/step - loss: 24.6410 - acc: 0.4874 - val_loss: 20.5443 - val_acc: 0.5203\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'stahley', 'Pred:': 'eeeeenn'}\n",
      "{'Orig': 'hilf', 'Pred:': 'eeee'}\n",
      "{'Orig': 'nigg', 'Pred:': 'eeee'}\n",
      "{'Orig': 'peoppe', 'Pred:': 'eeeeen'}\n",
      "{'Orig': 'mcgraw', 'Pred:': 'eeeeenn'}\n",
      "Epoch 2/350\n",
      "3456/3456 [==============================] - 5s 1ms/step - loss: 19.3109 - acc: 0.5353 - val_loss: 18.6825 - val_acc: 0.5507\n",
      "Epoch 3/350\n",
      "3456/3456 [==============================] - 5s 1ms/step - loss: 18.1067 - acc: 0.5575 - val_loss: 17.6537 - val_acc: 0.5660\n",
      "Epoch 4/350\n",
      "3456/3456 [==============================] - 5s 1ms/step - loss: 16.9827 - acc: 0.5771 - val_loss: 16.6869 - val_acc: 0.5819\n",
      "Epoch 5/350\n",
      "3456/3456 [==============================] - 5s 1ms/step - loss: 16.1437 - acc: 0.5918 - val_loss: 15.9201 - val_acc: 0.6024\n",
      "Epoch 6/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 15.3868 - acc: 0.6117 - val_loss: 15.1705 - val_acc: 0.6183\n",
      "Epoch 7/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 14.4651 - acc: 0.6383 - val_loss: 14.3632 - val_acc: 0.6394\n",
      "Epoch 8/350\n",
      "3456/3456 [==============================] - 5s 1ms/step - loss: 13.7937 - acc: 0.6535 - val_loss: 13.5445 - val_acc: 0.6598\n",
      "Epoch 9/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 13.0291 - acc: 0.6734 - val_loss: 13.1122 - val_acc: 0.6749\n",
      "Epoch 10/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 12.4651 - acc: 0.6868 - val_loss: 12.6085 - val_acc: 0.6810\n",
      "Epoch 11/350\n",
      "3456/3456 [==============================] - 5s 1ms/step - loss: 11.7740 - acc: 0.7053 - val_loss: 12.0708 - val_acc: 0.6981\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'jones', 'Pred:': 'oones'}\n",
      "{'Orig': 'dutro', 'Pred:': 'moroo'}\n",
      "{'Orig': 'newcomb', 'Pred:': 'eeooooh'}\n",
      "{'Orig': 'howie', 'Pred:': 'oooee'}\n",
      "{'Orig': 'potthoff', 'Pred:': 'hotttoff'}\n",
      "Epoch 12/350\n",
      "3456/3456 [==============================] - 5s 2ms/step - loss: 11.2108 - acc: 0.7178 - val_loss: 11.4903 - val_acc: 0.7185\n",
      "Epoch 13/350\n",
      "3456/3456 [==============================] - 5s 2ms/step - loss: 10.5941 - acc: 0.7376 - val_loss: 10.9106 - val_acc: 0.7325\n",
      "Epoch 14/350\n",
      "3456/3456 [==============================] - 5s 1ms/step - loss: 10.0859 - acc: 0.7545 - val_loss: 10.5595 - val_acc: 0.7429\n",
      "Epoch 15/350\n",
      "3456/3456 [==============================] - 5s 1ms/step - loss: 9.5384 - acc: 0.7694 - val_loss: 9.9728 - val_acc: 0.7654\n",
      "Epoch 16/350\n",
      "3456/3456 [==============================] - 6s 2ms/step - loss: 8.9889 - acc: 0.7840 - val_loss: 9.7737 - val_acc: 0.7728\n",
      "Epoch 17/350\n",
      "3456/3456 [==============================] - 5s 1ms/step - loss: 8.7223 - acc: 0.7932 - val_loss: 9.5342 - val_acc: 0.7779\n",
      "Epoch 18/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 8.1646 - acc: 0.8087 - val_loss: 8.8464 - val_acc: 0.7973\n",
      "Epoch 19/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 7.8165 - acc: 0.8183 - val_loss: 8.8256 - val_acc: 0.8021\n",
      "Epoch 20/350\n",
      "3456/3456 [==============================] - 5s 1ms/step - loss: 7.4828 - acc: 0.8285 - val_loss: 8.5762 - val_acc: 0.8067\n",
      "Epoch 21/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 7.0123 - acc: 0.8421 - val_loss: 8.1715 - val_acc: 0.8208\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'coleman', 'Pred:': 'coleman'}\n",
      "{'Orig': 'eben', 'Pred:': 'beenn'}\n",
      "{'Orig': 'houseman', 'Pred:': 'hosssman'}\n",
      "{'Orig': 'dunn', 'Pred:': 'dunnn'}\n",
      "{'Orig': 'plummer', 'Pred:': 'lllmmer'}\n",
      "Epoch 22/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 6.6643 - acc: 0.8536 - val_loss: 7.8726 - val_acc: 0.8300\n",
      "Epoch 23/350\n",
      "3456/3456 [==============================] - 5s 1ms/step - loss: 6.3377 - acc: 0.8604 - val_loss: 7.6298 - val_acc: 0.8391\n",
      "Epoch 24/350\n",
      "3456/3456 [==============================] - 5s 1ms/step - loss: 6.1514 - acc: 0.8645 - val_loss: 7.4396 - val_acc: 0.8442\n",
      "Epoch 25/350\n",
      "3456/3456 [==============================] - 5s 1ms/step - loss: 5.7741 - acc: 0.8769 - val_loss: 7.3088 - val_acc: 0.8472\n",
      "Epoch 26/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 5.7551 - acc: 0.8750 - val_loss: 7.3268 - val_acc: 0.8500\n",
      "Epoch 27/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 5.4238 - acc: 0.8840 - val_loss: 7.1128 - val_acc: 0.8553\n",
      "Epoch 28/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 5.2232 - acc: 0.8923 - val_loss: 7.1379 - val_acc: 0.8566\n",
      "Epoch 29/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 5.0527 - acc: 0.8955 - val_loss: 6.8889 - val_acc: 0.8642\n",
      "Epoch 30/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 5.0284 - acc: 0.8943 - val_loss: 7.0816 - val_acc: 0.8568\n",
      "Epoch 31/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 4.8889 - acc: 0.8976 - val_loss: 6.8385 - val_acc: 0.8650\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'corbin', 'Pred:': 'corbin'}\n",
      "{'Orig': 'mcclellan', 'Pred:': 'mccllllln'}\n",
      "{'Orig': 'munzenmaier', 'Pred:': 'munnenaiir'}\n",
      "{'Orig': 'macke', 'Pred:': 'macke'}\n",
      "{'Orig': 'cassidy', 'Pred:': 'cassidy'}\n",
      "Epoch 32/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 4.6550 - acc: 0.9041 - val_loss: 6.8880 - val_acc: 0.8632\n",
      "Epoch 33/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 4.5245 - acc: 0.9077 - val_loss: 6.8031 - val_acc: 0.8701\n",
      "Epoch 34/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 4.3812 - acc: 0.9119 - val_loss: 6.7788 - val_acc: 0.8683\n",
      "Epoch 35/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 4.2591 - acc: 0.9144 - val_loss: 6.6752 - val_acc: 0.8736\n",
      "Epoch 36/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 4.0919 - acc: 0.9189 - val_loss: 6.5857 - val_acc: 0.8730\n",
      "Epoch 37/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 4.0299 - acc: 0.9200 - val_loss: 6.6497 - val_acc: 0.8742\n",
      "Epoch 38/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 3.8415 - acc: 0.9263 - val_loss: 6.5715 - val_acc: 0.8774\n",
      "Epoch 39/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 3.7325 - acc: 0.9284 - val_loss: 6.5304 - val_acc: 0.8780\n",
      "Epoch 40/350\n",
      "3456/3456 [==============================] - 5s 1ms/step - loss: 3.8023 - acc: 0.9263 - val_loss: 6.8134 - val_acc: 0.8738\n",
      "Epoch 41/350\n",
      "3456/3456 [==============================] - 5s 1ms/step - loss: 3.6352 - acc: 0.9291 - val_loss: 6.6876 - val_acc: 0.8737\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'harms', 'Pred:': 'harms'}\n",
      "{'Orig': 'rossow', 'Pred:': 'rossow'}\n",
      "{'Orig': 'ricke', 'Pred:': 'ricke'}\n",
      "{'Orig': 'kinney', 'Pred:': 'kinney'}\n",
      "{'Orig': 'vandenberg', 'Pred:': 'kanneenberrg'}\n",
      "Epoch 42/350\n",
      "3456/3456 [==============================] - 5s 2ms/step - loss: 3.5270 - acc: 0.9324 - val_loss: 6.5572 - val_acc: 0.8829\n",
      "Epoch 43/350\n",
      "3456/3456 [==============================] - 5s 1ms/step - loss: 3.3077 - acc: 0.9376 - val_loss: 6.3476 - val_acc: 0.8877\n",
      "Epoch 44/350\n",
      "3456/3456 [==============================] - 4s 1ms/step - loss: 3.2802 - acc: 0.9370 - val_loss: 6.5240 - val_acc: 0.8844\n",
      "Epoch 45/350\n",
      "3456/3456 [==============================] - 5s 1ms/step - loss: 3.2684 - acc: 0.9384 - val_loss: 6.5625 - val_acc: 0.8846\n",
      "Epoch 46/350\n",
      "3456/3456 [==============================] - 6s 2ms/step - loss: 3.1643 - acc: 0.9410 - val_loss: 6.3351 - val_acc: 0.8893\n",
      "Epoch 47/350\n",
      "3456/3456 [==============================] - 5s 1ms/step - loss: 3.0403 - acc: 0.9437 - val_loss: 6.5042 - val_acc: 0.8874\n",
      "Epoch 48/350\n",
      "3456/3456 [==============================] - 5s 2ms/step - loss: 3.1201 - acc: 0.9417 - val_loss: 6.4765 - val_acc: 0.8877\n",
      "Epoch 49/350\n",
      "3456/3456 [==============================] - 5s 1ms/step - loss: 3.0585 - acc: 0.9421 - val_loss: 6.5972 - val_acc: 0.8828\n",
      "Epoch 50/350\n",
      "3456/3456 [==============================] - 5s 2ms/step - loss: 2.8942 - acc: 0.9469 - val_loss: 6.3775 - val_acc: 0.8911\n",
      "Epoch 51/350\n",
      "3456/3456 [==============================] - 5s 2ms/step - loss: 2.8131 - acc: 0.9471 - val_loss: 6.5500 - val_acc: 0.8905\n",
      "Sample Reconstructions:\n",
      "{'Orig': 'bredeaux', 'Pred:': 'bieeaux'}\n",
      "{'Orig': 'kielly', 'Pred:': 'kielly'}\n",
      "{'Orig': 'fitzgerald', 'Pred:': 'fitzeerald'}\n",
      "{'Orig': 'garter', 'Pred:': 'garte'}\n",
      "{'Orig': 'dostart', 'Pred:': 'dostart'}\n",
      "Saved encoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/lstm_letter_384_iowa_last/encoder.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved decoder in: /Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/lstm_letter_384_iowa_last/decoder.h5\n"
     ]
    }
   ],
   "source": [
    "# Train \n",
    "# One hot encoding of names\n",
    "ORIG_LENGTH = 12\n",
    "LR = 5e-4\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 350\n",
    "namesA = preprocess.embed(iowa_matches['lname1915'],\n",
    "                         max_length=ORIG_LENGTH, \n",
    "                         embed_type='letters', \n",
    "                         normalize=False, \n",
    "                         categorical=True)\n",
    "\n",
    "namesB = preprocess.embed(iowa_matches['lname1940'],\n",
    "                         max_length=ORIG_LENGTH, \n",
    "                         embed_type='letters',\n",
    "                         normalize=False, \n",
    "                         categorical=True)\n",
    "\n",
    "\n",
    "LATENT_DIM = [96,192,384]\n",
    "for latent_dim in LATENT_DIM: \n",
    "    save_path = '/Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/lstm_letter_{}_iowa_last/'.format(latent_dim)\n",
    "    run_id = 'lstm_{}'.format(latent_dim)\n",
    "    lstm_vae = recordlinker.model.LSTMVAE(batch_size=BATCH_SIZE, \n",
    "                                          timesteps=ORIG_LENGTH, \n",
    "                                          orig_dim=classes,\n",
    "                                          latent_dim=latent_dim,\n",
    "                                          encode_dim=[64,64], \n",
    "                                          decode_dim=[64,64],\n",
    "                                          lr=LR) \n",
    "    model_lstm, model_encoder, model_decoder = lstm_vae.train(namesA, namesB, \n",
    "                                                              epochs=EPOCHS, \n",
    "                                                              run_id=run_id, \n",
    "                                                              save_path=save_path, \n",
    "                                                              earlystop=True,\n",
    "                                                              earlystop_patience=10,\n",
    "                                                              tensorboard=True, \n",
    "                                                              reconstruct=True, \n",
    "                                                              reconstruct_display=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
