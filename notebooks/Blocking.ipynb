{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import recordlinker\n",
    "\n",
    "from recordlinker.preprocess import create_training_set\n",
    "from recordlinker.blocking import BinaryEncoder\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and mark matches and nonmatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total matches: 4320\n"
     ]
    }
   ],
   "source": [
    "iowa_matches = pd.read_csv('/Users/kailinlu/Desktop/QMSSWork/RecordLinking/recordlinker/recordlinker/data/iowa_matches.csv')\n",
    "iowa_nonmatches = pd.read_csv('/Users/kailinlu/Desktop/QMSSWork/RecordLinking/recordlinker/recordlinker/data/iowa_nonmatches.csv')\n",
    "\n",
    "iowa_matches['match'] = 1\n",
    "iowa_nonmatches['match'] = 0\n",
    "\n",
    "iowa = pd.concat([iowa_matches, iowa_nonmatches])\n",
    "total_matches = len(iowa_matches['uid-hhid'])\n",
    "print('Number of total matches: {}'.format(total_matches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract unique IDs for 1915 names and unique IDs for 1940 names. \n",
    "\n",
    "There are 6881 unique 1915 people and 65939 unique 1940 people. We want to match the correct uid-hhid pairs as denoted in the iowa dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_1915 = iowa[['lname1915', 'uid1915']]\n",
    "names_1915.drop_duplicates(inplace=True)\n",
    "names_1940 = iowa[['lname1940', 'hhid']]\n",
    "names_1940.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6881 entries, 0 to 74895\n",
      "Data columns (total 2 columns):\n",
      "lname1915    6881 non-null object\n",
      "uid1915      6881 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 161.3+ KB\n"
     ]
    }
   ],
   "source": [
    "names_1915.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 65939 entries, 0 to 75022\n",
      "Data columns (total 2 columns):\n",
      "lname1940    65939 non-null object\n",
      "hhid         65939 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "names_1940.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocking\n",
    "\n",
    "We will test the quality of the blocks from the LSTM model with 2, 4, 8, and 16 latent variables.\n",
    "\n",
    "Metrics: \n",
    "\n",
    "1. Number of blocks \n",
    "2. Average size, max size, and min size of each block \n",
    "3. % of all matches found within the same block "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _block_autoencoder(dfA, dfB, \n",
    "                       autoencoder_model_path,\n",
    "                       autoencoder_col,\n",
    "                       autoencoder_colB=None,\n",
    "                       embed_type='letters'):\n",
    "    \n",
    "    if autoencoder_colB is None: \n",
    "        autoencoder_colB = autoencoder_col\n",
    "    assert all(isinstance(name, str) for name in dfA[autoencoder_col])\n",
    "    assert all(isinstance(name, str) for name in dfB[autoencoder_colB])\n",
    "\n",
    "    encoder = BinaryEncoder(autoencoder_model_path)\n",
    "    input_dim = encoder.input_dim\n",
    "    if len(input_dim) == 3:\n",
    "        train_data = create_training_set(dfA,\n",
    "                                               autoencoder_col,\n",
    "                                               max_length=input_dim[1],\n",
    "                                               embed_type='letters',\n",
    "                                               normalize=False,\n",
    "                                               categorical=True)\n",
    "        match_data = create_training_set(dfB,\n",
    "                                               autoencoder_colB,\n",
    "                                               max_length=input_dim[1],\n",
    "                                               embed_type='letters',\n",
    "                                               normalize=False,\n",
    "                                               categorical=True)\n",
    "    else:\n",
    "        train_data = create_training_set(dfA,\n",
    "                                               autoencoder_col,\n",
    "                                               max_length=input_dim[1],\n",
    "                                               embed_type=embed_type,\n",
    "                                               normalize=True,\n",
    "                                               categorical=False)\n",
    "        match_data = create_training_set(dfB,\n",
    "                                               autoencoder_colB,\n",
    "                                               max_length=input_dim[1],\n",
    "                                               embed_type=embed_type,\n",
    "                                               normalize=True,\n",
    "                                               categorical=False)\n",
    "\n",
    "    train_encoded = encoder.calculate_and_encode(train_data, split=True)\n",
    "    match_encoded = encoder.binary_encode(match_data, split=True)\n",
    "\n",
    "    unique_blocks =  [self.stringify(vec) for vec in np.unique(train_encoded, axis=0)]\n",
    "    blocks = dict.fromkeys(unique_blocks)\n",
    "    for k, v in blocks.items():\n",
    "        blocks[k] = {'A':[], 'B':[]}\n",
    "\n",
    "    for i, vec in enumerate(train_encoded):\n",
    "        key = self.stringify(vec)\n",
    "        blocks[key]['A'].append(i)\n",
    "\n",
    "    for i, vec in enumerate(match_encoded):\n",
    "        key = self.stringify(vec)\n",
    "        if key in blocks.keys():\n",
    "            blocks[key]['B'].append(i)\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BinaryEncoder' object has no attribute 'calculate_and_encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-188-3beb4c3e5449>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                             \u001b[0mautoencoder_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lname1915'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                             \u001b[0mautoencoder_colB\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lname1940'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                             embed_type='letters')\n\u001b[0m",
      "\u001b[0;32m<ipython-input-187-14401d27949b>\u001b[0m in \u001b[0;36m_block_autoencoder\u001b[0;34m(dfA, dfB, autoencoder_model_path, autoencoder_col, autoencoder_colB, embed_type)\u001b[0m\n\u001b[1;32m     39\u001b[0m                                                categorical=False)\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mtrain_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_and_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mmatch_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BinaryEncoder' object has no attribute 'calculate_and_encode'"
     ]
    }
   ],
   "source": [
    "model_path = '/Users/kailinlu/Desktop/QMSSWork/RecordLinking/models/lstm_letter_2_iowa_last/encoder.h5'\n",
    "\n",
    "blocks = _block_autoencoder(dfA=names_1915, dfB=names_1940,\n",
    "                            autoencoder_model_path=model_path,\n",
    "                            autoencoder_col='lname1915',\n",
    "                            autoencoder_colB='lname1940',\n",
    "                            embed_type='letters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'binary_encode']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(BinaryEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
